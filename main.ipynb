{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67bb0a3d",
   "metadata": {},
   "source": [
    "# **Kaggle Challenge: Pirate Pain Dataset üè¥‚Äç‚ò†Ô∏è (v4: ColumnTransformer)**\n",
    "\n",
    "This notebook implements a robust K-Fold Cross-Validation and Ensembling strategy. This version includes a key fix: **Selective Scaling using `ColumnTransformer`**.\n",
    "\n",
    "**Strategy:**\n",
    "1.  **Feature Engineering:** \n",
    "    * Create an `is_pirate` binary feature (1 if pirate, 0 otherwise).\n",
    "    * Include the `time` column as a feature.\n",
    "    * This results in **37 total features**.\n",
    "2.  **Selective Scaling:** Use `ColumnTransformer` to apply different scaling rules to our 37 features. This logic is applied consistently in HPO, K-Fold, and Final Prediction loops.\n",
    "    * `StandardScaler` for the 31 `joint_` features.\n",
    "    * `MinMaxScaler` for the 4 `pain_survey_` features.\n",
    "    * `MinMaxScaler` for the 1 `time` feature.\n",
    "    * `passthrough` for the 1 `is_pirate` feature.\n",
    "3.  **Hyperparameter Search:** Use Ray Tune & Optuna on a single 80/20 stratified split to find a good set of hyperparameters (`FINAL_CONFIG`). This is much faster than the previous K-Fold HPO approach.\n",
    "4.  **K-Fold Training:** Train `K=5` models on 5 different folds, using the `FINAL_CONFIG`. Each model is trained with early stopping and saved to disk.\n",
    "5.  **Ensemble Prediction:** Load all 5 models, average their (softmax) probabilities on the test set, and aggregate these probabilities for a final, robust submission."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b03291d",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è 1. Setup & Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ba22088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Using GPU ---\n",
      "PyTorch version: 2.5.1\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set seed for reproducibility\n",
    "SEED = 123\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "import logging\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import copy\n",
    "from itertools import product\n",
    "import time\n",
    "\n",
    "# Set environment variables before importing modules\n",
    "os.environ['MPLCONFIGDIR'] = os.getcwd() + '/configs/'\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "# --- PyTorch Imports ---\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# --- Sklearn Imports ---\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "# --- Ray[tune] & Optuna Imports ---\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.search.optuna import OptunaSearch\n",
    "from functools import partial\n",
    "\n",
    "# --- Setup Directories & Device ---\n",
    "logs_dir = \"tensorboard\"\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "os.makedirs(\"submissions\", exist_ok=True)\n",
    "os.makedirs(logs_dir, exist_ok=True)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    print(\"\\n--- Using GPU ---\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"\\n--- Using CPU ---\")\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Configure plot display settings\n",
    "sns.set_theme(font_scale=1.4)\n",
    "sns.set_style('white')\n",
    "plt.rc('font', size=14)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8582ef",
   "metadata": {},
   "source": [
    "## üîÑ 2. Data Loading & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44203b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Loading Data ---\n",
      "Loaded X_train_full (shape: (661, 160, 36)) and y_train_full (shape: (661,))\n",
      "Loaded X_test_full (shape: (1324, 160, 36))\n",
      "\n",
      "--- 2. Engineering 'is_pirate' Feature ---\n",
      "Created X_train_full_engineered (shape: (661, 160, 37))\n",
      "Created X_test_full_engineered (shape: (1324, 160, 37))\n",
      "N_FEATURES is now: 37\n",
      "\n",
      "--- 3. Calculating Class Weights ---\n",
      "Class counts (0, 1, 2): [511  94  56]\n",
      "Calculated class weights: tensor([0.0643, 0.3493, 0.5864], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"--- 1. Loading Data ---\")\n",
    "\n",
    "# --- Define File Paths and Features ---\n",
    "DATA_DIR = \"data\"\n",
    "X_TRAIN_PATH = os.path.join(DATA_DIR, \"pirate_pain_train.csv\")\n",
    "Y_TRAIN_PATH = os.path.join(DATA_DIR, \"pirate_pain_train_labels.csv\")\n",
    "X_TEST_PATH = os.path.join(DATA_DIR, \"pirate_pain_test.csv\")\n",
    "SUBMISSION_PATH = os.path.join(DATA_DIR, \"sample_submission.csv\")\n",
    "\n",
    "try:\n",
    "    # Load features and labels\n",
    "    features_long_df = pd.read_csv(X_TRAIN_PATH)\n",
    "    labels_df = pd.read_csv(Y_TRAIN_PATH)\n",
    "    X_test_long_df = pd.read_csv(X_TEST_PATH)\n",
    "    \n",
    "    # --- Define constants ---\n",
    "    N_TIMESTEPS = 160\n",
    "    JOINT_FEATURES = [f\"joint_{i:02d}\" for i in range(31)]\n",
    "    PAIN_FEATURES = [f\"pain_survey_{i}\" for i in range(1, 5)]\n",
    "    TIME_FEATURE = ['time'] # <-- MODIFICATION: Add 'time' as a feature\n",
    "    \n",
    "    FEATURES = JOINT_FEATURES + PAIN_FEATURES + TIME_FEATURE\n",
    "    N_FEATURES_ORIGINAL = len(FEATURES) # This is 31 + 4 + 1 = 36\n",
    "    LABEL_MAPPING = {'no_pain': 0, 'low_pain': 1, 'high_pain': 2}\n",
    "    N_CLASSES = len(LABEL_MAPPING)\n",
    "\n",
    "    # --- Reshape function ---\n",
    "    def reshape_data(df, features_list, n_timesteps):\n",
    "        df_pivot = df.pivot(index='sample_index', columns='time', values=features_list)\n",
    "        data_2d = df_pivot.values\n",
    "        n_samples = data_2d.shape[0]\n",
    "        data_3d = data_2d.reshape(n_samples, len(features_list), n_timesteps)\n",
    "        return data_3d.transpose(0, 2, 1)\n",
    "\n",
    "    # --- Load and reshape X_train_full (36 features) ---\n",
    "    X_train_full = reshape_data(\n",
    "        features_long_df[features_long_df['sample_index'].isin(labels_df['sample_index'].unique())], \n",
    "        FEATURES, \n",
    "        N_TIMESTEPS\n",
    "    )\n",
    "    \n",
    "    # --- Load and reshape X_test (36 features) ---\n",
    "    X_test_full = reshape_data(\n",
    "        X_test_long_df, FEATURES, N_TIMESTEPS\n",
    "    )\n",
    "\n",
    "    # --- Load and prepare y_train_full ---\n",
    "    y_train_full_df = labels_df.sort_values(by='sample_index')\n",
    "    le = LabelEncoder()\n",
    "    le.fit(list(LABEL_MAPPING.keys()))\n",
    "    y_train_full = le.transform(y_train_full_df['label'])\n",
    "    \n",
    "    print(f\"Loaded X_train_full (shape: {X_train_full.shape}) and y_train_full (shape: {y_train_full.shape})\")\n",
    "    print(f\"Loaded X_test_full (shape: {X_test_full.shape})\")\n",
    "\n",
    "    # --- 2. Engineer 'is_pirate' Feature (for Train) ---\n",
    "    print(\"\\n--- 2. Engineering 'is_pirate' Feature ---\")\n",
    "    static_cols = ['sample_index', 'n_legs', 'n_hands', 'n_eyes']\n",
    "    static_df = features_long_df[static_cols].drop_duplicates().set_index('sample_index')\n",
    "    \n",
    "    pirate_filter = (\n",
    "        (static_df['n_legs'] == 'one+peg_leg') |\n",
    "        (static_df['n_hands'] == 'one+hook_hand') |\n",
    "        (static_df['n_eyes'] == 'one+eye_patch')\n",
    "    )\n",
    "    pirate_indices = static_df[pirate_filter].index\n",
    "    sample_indices_ordered = sorted(features_long_df[features_long_df['sample_index'].isin(labels_df['sample_index'].unique())]['sample_index'].unique())\n",
    "    is_pirate_map = np.array([1 if idx in pirate_indices else 0 for idx in sample_indices_ordered])\n",
    "    pirate_feature_broadcast = np.tile(is_pirate_map.reshape(-1, 1, 1), (1, N_TIMESTEPS, 1))\n",
    "    \n",
    "    # Concatenate with X_train_full\n",
    "    X_train_full_engineered = np.concatenate([X_train_full, pirate_feature_broadcast], axis=2)\n",
    "    \n",
    "    # --- 3. Engineer 'is_pirate' Feature (for Test) ---\n",
    "    static_df_test = X_test_long_df[static_cols].drop_duplicates().set_index('sample_index')\n",
    "    pirate_filter_test = (\n",
    "        (static_df_test['n_legs'] == 'one+peg_leg') |\n",
    "        (static_df_test['n_hands'] == 'one+hook_hand') |\n",
    "        (static_df_test['n_eyes'] == 'one+eye_patch')\n",
    "    )\n",
    "    pirate_indices_test = static_df_test[pirate_filter_test].index\n",
    "    sample_indices_test_ordered = sorted(X_test_long_df['sample_index'].unique())\n",
    "    is_pirate_map_test = np.array([1 if idx in pirate_indices_test else 0 for idx in sample_indices_test_ordered])\n",
    "    pirate_feature_broadcast_test = np.tile(is_pirate_map_test.reshape(-1, 1, 1), (1, N_TIMESTEPS, 1))\n",
    "    \n",
    "    # Concatenate with X_test_full\n",
    "    X_test_full_engineered = np.concatenate([X_test_full, pirate_feature_broadcast_test], axis=2)\n",
    "    \n",
    "    N_FEATURES_NEW = X_train_full_engineered.shape[2] # This will be 36 + 1 = 37\n",
    "    print(f\"Created X_train_full_engineered (shape: {X_train_full_engineered.shape})\")\n",
    "    print(f\"Created X_test_full_engineered (shape: {X_test_full_engineered.shape})\")\n",
    "    print(f\"N_FEATURES is now: {N_FEATURES_NEW}\")\n",
    "\n",
    "    # --- 4. Calculate Class Weights ---\n",
    "    print(\"\\n--- 3. Calculating Class Weights ---\")\n",
    "    class_counts_series = labels_df['label'].value_counts()\n",
    "    counts_ordered = class_counts_series.reindex(LABEL_MAPPING.keys()).values\n",
    "    class_weights_tensor = 1.0 / torch.tensor(counts_ordered, dtype=torch.float)\n",
    "    class_weights_tensor = class_weights_tensor / class_weights_tensor.sum() # Normalize weights\n",
    "    class_weights_tensor = class_weights_tensor.to(device)\n",
    "    \n",
    "    print(f\"Class counts (0, 1, 2): {counts_ordered}\")\n",
    "    print(f\"Calculated class weights: {class_weights_tensor}\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: Could not find a required file. {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6f8bc4",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è 3. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a7c2d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sliding_windows(X_3d, y=None, window_size=100, stride=20):\n",
    "    \"\"\"\n",
    "    Takes 3D data (n_samples, n_timesteps, n_features)\n",
    "    and creates overlapping windows.\n",
    "    \"\"\"\n",
    "    new_X = []\n",
    "    new_y = []\n",
    "    # This new array tracks which original sample each window came from.\n",
    "    window_indices = [] \n",
    "    \n",
    "    n_samples, n_timesteps, n_features = X_3d.shape\n",
    "    \n",
    "    # Iterate over each original sample\n",
    "    for i in range(n_samples):\n",
    "        sample = X_3d[i]\n",
    "        \n",
    "        # Slide a window over this sample\n",
    "        idx = 0\n",
    "        while (idx + window_size) <= n_timesteps:\n",
    "            window = sample[idx : idx + window_size]\n",
    "            new_X.append(window)\n",
    "            window_indices.append(i) # Track the original sample index (0, 1, 2...)\n",
    "            \n",
    "            if y is not None:\n",
    "                new_y.append(y[i]) # The label is the same for all windows\n",
    "                \n",
    "            idx += stride\n",
    "            \n",
    "    if y is not None:\n",
    "        # Return new X, new y, and the index mapping\n",
    "        return np.array(new_X), np.array(new_y), np.array(window_indices)\n",
    "    else:\n",
    "        # Return new X and the index mapping\n",
    "        return np.array(new_X), np.array(window_indices)\n",
    "    \n",
    "def make_loader(ds, batch_size, shuffle, drop_last):\n",
    "    \"\"\"Creates a PyTorch DataLoader with optimized settings.\"\"\"\n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size=int(batch_size), # Ensure batch_size is an int\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "        pin_memory_device=\"cuda\" if torch.cuda.is_available() else \"\",\n",
    "        prefetch_factor=None,\n",
    "    )\n",
    "\n",
    "def recurrent_summary(model, input_size):\n",
    "    \"\"\"Custom summary function that correctly counts parameters for RNN/GRU/LSTM layers.\"\"\"\n",
    "    output_shapes = {}\n",
    "    hooks = []\n",
    "\n",
    "    def get_hook(name):\n",
    "        def hook(module, input, output):\n",
    "            if isinstance(output, tuple):\n",
    "                shape1 = list(output[0].shape)\n",
    "                shape1[0] = -1  # Replace batch dimension with -1\n",
    "\n",
    "                if isinstance(output[1], tuple):  # LSTM case: (h_n, c_n)\n",
    "                    shape2 = list(output[1][0].shape)\n",
    "                else:  # RNN/GRU case: h_n only\n",
    "                    shape2 = list(output[1].shape)\n",
    "                shape2[1] = -1\n",
    "                output_shapes[name] = f\"[{shape1}, {shape2}]\"\n",
    "            else:\n",
    "                shape = list(output.shape)\n",
    "                shape[0] = -1\n",
    "                output_shapes[name] = f\"{shape}\"\n",
    "        return hook\n",
    "\n",
    "    try:\n",
    "        device_summary = next(model.parameters()).device\n",
    "    except StopIteration:\n",
    "        device_summary = torch.device(\"cpu\")\n",
    "\n",
    "    dummy_input = torch.randn(1, *input_size).to(device_summary)\n",
    "\n",
    "    for name, module in model.named_children():\n",
    "        if isinstance(module, (nn.Linear, nn.RNN, nn.GRU, nn.LSTM)):\n",
    "            hook_handle = module.register_forward_hook(get_hook(name))\n",
    "            hooks.append(hook_handle)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        try:\n",
    "            model(dummy_input)\n",
    "        except Exception as e:\n",
    "            print(f\"Error during dummy forward pass: {e}\")\n",
    "            for h in hooks:\n",
    "                h.remove()\n",
    "            return\n",
    "\n",
    "    for h in hooks:\n",
    "        h.remove()\n",
    "\n",
    "    print(\"-\" * 79)\n",
    "    print(f\"{'Layer (type)':<25} {'Output Shape':<28} {'Param #':<18}\")\n",
    "    print(\"=\" * 79)\n",
    "\n",
    "    total_params = 0\n",
    "    total_trainable_params = 0\n",
    "\n",
    "    for name, module in model.named_children():\n",
    "        if name in output_shapes:\n",
    "            module_params = sum(p.numel() for p in module.parameters())\n",
    "            trainable_params = sum(p.numel() for p in module.parameters() if p.requires_grad)\n",
    "\n",
    "            total_params += module_params\n",
    "            total_trainable_params += trainable_params\n",
    "\n",
    "            layer_name = f\"{name} ({type(module).__name__})\"\n",
    "            output_shape_str = str(output_shapes[name])\n",
    "            params_str = f\"{trainable_params:,}\"\n",
    "\n",
    "            print(f\"{layer_name:<25} {output_shape_str:<28} {params_str:<15}\")\n",
    "\n",
    "    print(\"=\" * 79)\n",
    "    print(f\"Total params: {total_params:,}\")\n",
    "    print(f\"Trainable params: {total_trainable_params:,}\")\n",
    "    print(f\"Non-trainable params: {total_params - total_trainable_params:,}\")\n",
    "    print(\"-\" * 79)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faed930",
   "metadata": {},
   "source": [
    "## üß† 4. Model & Training Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd3cadd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Generic RNN classifier (RNN, LSTM, GRU).\n",
    "    Uses the last hidden state for classification.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_size,\n",
    "            hidden_size,\n",
    "            num_layers,\n",
    "            num_classes,\n",
    "            rnn_type='GRU',\n",
    "            bidirectional=False,\n",
    "            dropout_rate=0.2\n",
    "            ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.rnn_type = rnn_type\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "        rnn_map = {\n",
    "            'RNN': nn.RNN,\n",
    "            'LSTM': nn.LSTM,\n",
    "            'GRU': nn.GRU\n",
    "        }\n",
    "        rnn_module = rnn_map[rnn_type]\n",
    "\n",
    "        # Dropout is only applied between layers (if num_layers > 1)\n",
    "        dropout_val = dropout_rate if num_layers > 1 else 0\n",
    "\n",
    "        self.rnn = rnn_module(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,       # Input shape: (batch, seq_len, features)\n",
    "            bidirectional=bidirectional,\n",
    "            dropout=dropout_val\n",
    "        )\n",
    "\n",
    "        if self.bidirectional:\n",
    "            classifier_input_size = hidden_size * 2 # Concat fwd + bwd\n",
    "        else:\n",
    "            classifier_input_size = hidden_size\n",
    "\n",
    "        self.classifier = nn.Linear(classifier_input_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\" x shape: (batch_size, seq_length, input_size) \"\"\"\n",
    "        rnn_out, hidden = self.rnn(x)\n",
    "\n",
    "        if self.rnn_type == 'LSTM':\n",
    "            hidden = hidden[0] # Use only the hidden state, not the cell state\n",
    "\n",
    "        # Get the last layer's hidden state\n",
    "        if self.bidirectional:\n",
    "            # Reshape to (num_layers, num_directions, batch, hidden_size)\n",
    "            hidden = hidden.view(self.num_layers, 2, -1, self.hidden_size)\n",
    "            # Concat the last fwd and bwd hidden states\n",
    "            hidden_to_classify = torch.cat([hidden[-1, 0, :, :], hidden[-1, 1, :, :]], dim=1)\n",
    "        else:\n",
    "            # Just take the last layer's hidden state\n",
    "            hidden_to_classify = hidden[-1]\n",
    "\n",
    "        logits = self.classifier(hidden_to_classify)\n",
    "        return logits\n",
    "\n",
    "def train_one_epoch(model, train_loader, criterion, optimizer, scaler, device, l1_lambda=0, l2_lambda=0):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n",
    "            logits = model(inputs)\n",
    "            loss = criterion(logits, targets)\n",
    "            \n",
    "            # Add L1/L2 regularization if provided\n",
    "            if l1_lambda > 0 or l2_lambda > 0:\n",
    "                l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
    "                l2_norm = sum(p.pow(2).sum() for p in model.parameters())\n",
    "                loss = loss + l1_lambda * l1_norm + l2_lambda * l2_norm\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        # Unscale gradients before clipping\n",
    "        scaler.unscale_(optimizer) \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5) \n",
    "\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        if torch.isnan(loss):\n",
    "            print(f\"Warning: NaN loss detected in batch {batch_idx}. Skipping batch.\")\n",
    "            continue\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        predictions = logits.argmax(dim=1)\n",
    "        all_predictions.append(predictions.cpu().numpy())\n",
    "        all_targets.append(targets.cpu().numpy())\n",
    "\n",
    "    if not all_targets:\n",
    "        return 0.0, 0.0 # Return 0 if all batches were nan\n",
    "\n",
    "    epoch_loss = running_loss / len(np.concatenate(all_targets))\n",
    "    epoch_f1 = f1_score(\n",
    "        np.concatenate(all_targets),\n",
    "        np.concatenate(all_predictions),\n",
    "        average='weighted'\n",
    "    )\n",
    "    return epoch_loss, epoch_f1\n",
    "\n",
    "def validate_one_epoch(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n",
    "                logits = model(inputs)\n",
    "                loss = criterion(logits, targets)\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            predictions = logits.argmax(dim=1)\n",
    "            all_predictions.append(predictions.cpu().numpy())\n",
    "            all_targets.append(targets.cpu().numpy())\n",
    "\n",
    "    epoch_loss = running_loss / len(val_loader.dataset.tensors[1])\n",
    "    epoch_f1 = f1_score(\n",
    "        np.concatenate(all_targets),\n",
    "        np.concatenate(all_predictions),\n",
    "        average='weighted'\n",
    "    )\n",
    "    return epoch_loss, epoch_f1\n",
    "\n",
    "def log_metrics_to_tensorboard(writer, epoch, train_loss, train_f1, val_loss, val_f1, model):\n",
    "    writer.add_scalar('Loss/Training', train_loss, epoch)\n",
    "    writer.add_scalar('Loss/Validation', val_loss, epoch)\n",
    "    writer.add_scalar('F1/Training', train_f1, epoch)\n",
    "    writer.add_scalar('F1/Validation', val_f1, epoch)\n",
    "\n",
    "\n",
    "def objective_function(config, X_train, y_train, X_val, y_val, class_weights_tensor):\n",
    "    \"\"\"\n",
    "    Objective function for Ray Tune using a single train/validation split.\n",
    "    This is much faster than the K-Fold CV approach.\n",
    "    \"\"\"\n",
    "    # 1. --- Selective Scaling using ColumnTransformer (inside the objective) ---\n",
    "    joint_indices = list(range(31))\n",
    "    pain_indices = list(range(31, 35))\n",
    "    time_index = [35]\n",
    "    pirate_index = [36]\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('joint_scaler', StandardScaler(), joint_indices),\n",
    "            ('pain_scaler', MinMaxScaler(), pain_indices),\n",
    "            ('time_scaler', MinMaxScaler(), time_index),\n",
    "            ('pirate_passthrough', 'passthrough', pirate_index)\n",
    "        ],\n",
    "        remainder='drop'\n",
    "    )\n",
    "\n",
    "    # Reshape to 2D for fitting/transforming\n",
    "    ns, ts, f = X_train.shape\n",
    "    X_train_2d = X_train.reshape(ns * ts, f)\n",
    "    ns_val, ts_val, f_val = X_val.shape\n",
    "    X_val_2d = X_val.reshape(ns_val * ts_val, f_val)\n",
    "\n",
    "    # Fit on 2D train data\n",
    "    preprocessor.fit(X_train_2d)\n",
    "\n",
    "    # Transform 2D train and val data\n",
    "    X_train_scaled_2d = preprocessor.transform(X_train_2d)\n",
    "    X_val_scaled_2d = preprocessor.transform(X_val_2d)\n",
    "\n",
    "    # Reshape back to 3D\n",
    "    X_train_final = X_train_scaled_2d.reshape(ns, ts, -1)\n",
    "    X_val_final = X_val_scaled_2d.reshape(ns_val, ts_val, -1)\n",
    "\n",
    "    # 2. --- Windowing ---\n",
    "    X_train_w, y_train_w, _ = create_sliding_windows(\n",
    "        X_train_final, y_train, config[\"window_size\"], config[\"stride\"]\n",
    "    )\n",
    "    X_val_w, y_val_w, _ = create_sliding_windows(\n",
    "        X_val_final, y_val, config[\"window_size\"], config[\"stride\"]\n",
    "    )\n",
    "\n",
    "    # 3. --- DataLoaders ---\n",
    "    train_ds = TensorDataset(torch.from_numpy(X_train_w).float(), torch.from_numpy(y_train_w).long())\n",
    "    val_ds = TensorDataset(torch.from_numpy(X_val_w).float(), torch.from_numpy(y_val_w).long())\n",
    "\n",
    "    train_loader = make_loader(train_ds, config[\"batch_size\"], shuffle=True, drop_last=True)\n",
    "    val_loader = make_loader(val_ds, config[\"batch_size\"], shuffle=False, drop_last=False)\n",
    "\n",
    "    # 4. --- Model, Optimizer, Criterion, Scaler ---\n",
    "    INPUT_SIZE = X_train.shape[2]  # This is 37\n",
    "\n",
    "    model = RecurrentClassifier(\n",
    "        input_size=INPUT_SIZE,\n",
    "        hidden_size=config[\"hidden_size\"],\n",
    "        num_layers=config[\"num_layers\"],\n",
    "        num_classes=3,\n",
    "        dropout_rate=config[\"dropout_rate\"],\n",
    "        bidirectional=config[\"bidirectional\"],\n",
    "        rnn_type=config[\"rnn_type\"]\n",
    "    ).to(device)\n",
    "\n",
    "    if torch.__version__[0] >= \"2\": model = torch.compile(model)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config[\"lr\"], weight_decay=config[\"l2_lambda\"])\n",
    "    scaler = torch.amp.GradScaler(enabled=(device.type == 'cuda'))\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "\n",
    "    # 5. --- Training & Reporting Loop ---\n",
    "    # ASHA scheduler will stop unpromising trials early\n",
    "    EPOCHS = 150\n",
    "\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        train_loss, train_f1 = train_one_epoch(model, train_loader, criterion, optimizer, scaler, device)\n",
    "        val_loss, val_f1 = validate_one_epoch(model, val_loader, criterion, device)\n",
    "\n",
    "        # Report metrics to Ray Tune\n",
    "        tune.report({\n",
    "            \"val_f1\": val_f1,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_f1\": train_f1\n",
    "        })\n",
    "\n",
    "def fit(model, train_loader, val_loader, epochs, criterion, optimizer, scaler, device,\n",
    "        l1_lambda=0, l2_lambda=0, patience=0, evaluation_metric=\"val_f1\", mode='max',\n",
    "        restore_best_weights=True, writer=None, verbose=10, experiment_name=\"\"):\n",
    "    \"\"\"\n",
    "    Full training loop with early stopping, model checkpointing, and logging.\n",
    "    \"\"\"\n",
    "    training_history = {\n",
    "        'train_loss': [], 'val_loss': [],\n",
    "        'train_f1': [], 'val_f1': []\n",
    "    }\n",
    "    \n",
    "    model_path = f\"models/{experiment_name}_best_model.pt\"\n",
    "\n",
    "    if patience > 0:\n",
    "        patience_counter = 0\n",
    "        best_metric = float('-inf') if mode == 'max' else float('inf')\n",
    "        best_epoch = 0\n",
    "\n",
    "    print(f\"--- Starting Training: {experiment_name} ---\")\n",
    "    print(f\"Will train for {epochs} epochs with patience={patience} monitoring {evaluation_metric}\")\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_loss, train_f1 = train_one_epoch(\n",
    "            model, train_loader, criterion, optimizer, scaler, device, l1_lambda, l2_lambda\n",
    "        )\n",
    "\n",
    "        val_loss, val_f1 = validate_one_epoch(\n",
    "            model, val_loader, criterion, device\n",
    "        )\n",
    "\n",
    "        training_history['train_loss'].append(train_loss)\n",
    "        training_history['val_loss'].append(val_loss)\n",
    "        training_history['train_f1'].append(train_f1)\n",
    "        training_history['val_f1'].append(val_f1)\n",
    "\n",
    "        if writer is not None:\n",
    "            log_metrics_to_tensorboard(\n",
    "                writer, epoch, train_loss, train_f1, val_loss, val_f1, model\n",
    "            )\n",
    "\n",
    "        if verbose > 0 and (epoch % verbose == 0 or epoch == 1):\n",
    "            print(f\"Epoch {epoch:3d}/{epochs} | \"\n",
    "                  f\"Train: Loss={train_loss:.4f}, F1={train_f1:.4f} | \"\n",
    "                  f\"Val: Loss={val_loss:.4f}, F1={val_f1:.4f}\")\n",
    "\n",
    "        if patience > 0:\n",
    "            current_metric = training_history[evaluation_metric][-1]\n",
    "            is_improvement = (current_metric > best_metric) if mode == 'max' else (current_metric < best_metric)\n",
    "\n",
    "            if is_improvement:\n",
    "                best_metric = current_metric\n",
    "                best_epoch = epoch\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= patience:\n",
    "                    print(f\"\\nEarly stopping triggered after {epoch} epochs.\")\n",
    "                    break\n",
    "\n",
    "    if restore_best_weights and patience > 0:\n",
    "        print(f\"Restoring best model from epoch {best_epoch} with {evaluation_metric} {best_metric:.4f}\")\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    if patience == 0:\n",
    "        print(\"Training complete. Saving final model.\")\n",
    "        torch.save(model.state_dict(), model_path.replace(\"_best_model.pt\", \"_final_model.pt\"))\n",
    "\n",
    "    if writer is not None:\n",
    "        writer.close()\n",
    "    \n",
    "    print(f\"--- Finished Training: {experiment_name} ---\")\n",
    "    return model, training_history, best_epoch if 'best_epoch' in locals() else epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9f911c",
   "metadata": {},
   "source": [
    "## üß™ 5. Phase 1: Hyperparameter Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa548a9",
   "metadata": {},
   "source": [
    "### 5.1. Preprocessing for HPO (Single Split)\n",
    "\n",
    "This section prepares a single, stratified 80/20 split of the data. This split is then passed to the hyperparameter optimization function (`objective_function`).\n",
    "\n",
    "To prevent data leakage, we pass the raw, unscaled splits to the objective function. The function is then responsible for:\n",
    "1.  Fitting the `ColumnTransformer` on the **training set** only.\n",
    "2.  Transforming both the training and validation sets.\n",
    "3.  Applying sliding windows based on the hyperparameters for that specific trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d09a835f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Splitting NON-WINDOWED data for HPO ---\n",
      "  X_train_split_full: (528, 160, 37)\n",
      "  X_val_split_full:   (133, 160, 37)\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Split Data (NON-WINDOWED) ---\n",
    "# This single 80/20 split is used for the entire HPO search.\n",
    "print(\"--- Splitting NON-WINDOWED data for HPO ---\")\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED)\n",
    "\n",
    "for train_idx, val_idx in sss.split(X_train_full_engineered, y_train_full):\n",
    "    X_train_split_full = X_train_full_engineered[train_idx]\n",
    "    y_train_split_full = y_train_full[train_idx]\n",
    "    X_val_split_full = X_train_full_engineered[val_idx]\n",
    "    y_val_split_full = y_train_full[val_idx]\n",
    "\n",
    "print(f\"  X_train_split_full: {X_train_split_full.shape}\")\n",
    "print(f\"  X_val_split_full:   {X_val_split_full.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a526ea0b",
   "metadata": {},
   "source": [
    "### 5.2. HPO Search Execution (Ray Tune + Optuna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b42797c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2025-11-13 08:41:21</td></tr>\n",
       "<tr><td>Running for: </td><td>00:39:34.95        </td></tr>\n",
       "<tr><td>Memory:      </td><td>9.5/13.9 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=20<br>Bracket: Iter 80.000: 0.9262556893370395 | Iter 40.000: 0.9181913795229679 | Iter 20.000: 0.9139723863511926<br>Logical resource usage: 4.0/16 CPUs, 0.5/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th>bidirectional  </th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  hidden_size</th><th style=\"text-align: right;\">  l2_lambda</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  num_layers</th><th>rnn_type  </th><th style=\"text-align: right;\">  stride</th><th style=\"text-align: right;\">  window_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  val_f1</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  train_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>objective_function_acbe2988</td><td>TERMINATED</td><td>127.0.0.1:20148</td><td style=\"text-align: right;\">         256</td><td>True           </td><td style=\"text-align: right;\">      0.203649</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">1.91941e-06</td><td style=\"text-align: right;\">0.000250113</td><td style=\"text-align: right;\">           2</td><td>GRU       </td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">           20</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         78.4263</td><td style=\"text-align: right;\">0.889838</td><td style=\"text-align: right;\">  0.477616</td><td style=\"text-align: right;\"> 0.00159246 </td></tr>\n",
       "<tr><td>objective_function_ced7c683</td><td>TERMINATED</td><td>127.0.0.1:38128</td><td style=\"text-align: right;\">         256</td><td>False          </td><td style=\"text-align: right;\">      0.388222</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">5.94501e-06</td><td style=\"text-align: right;\">5.83277e-05</td><td style=\"text-align: right;\">           2</td><td>GRU       </td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">           20</td><td style=\"text-align: right;\">    80</td><td style=\"text-align: right;\">        247.759 </td><td style=\"text-align: right;\">0.912171</td><td style=\"text-align: right;\">  0.500218</td><td style=\"text-align: right;\"> 0.000790502</td></tr>\n",
       "<tr><td>objective_function_96b368b0</td><td>TERMINATED</td><td>127.0.0.1:30996</td><td style=\"text-align: right;\">         256</td><td>False          </td><td style=\"text-align: right;\">      0.360927</td><td style=\"text-align: right;\">          384</td><td style=\"text-align: right;\">1.40044e-07</td><td style=\"text-align: right;\">0.00101938 </td><td style=\"text-align: right;\">           2</td><td>GRU       </td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         84.5165</td><td style=\"text-align: right;\">0.937381</td><td style=\"text-align: right;\">  0.25534 </td><td style=\"text-align: right;\"> 0.00060964 </td></tr>\n",
       "<tr><td>objective_function_f97f624d</td><td>TERMINATED</td><td>127.0.0.1:38788</td><td style=\"text-align: right;\">         128</td><td>False          </td><td style=\"text-align: right;\">      0.461492</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">7.40601e-06</td><td style=\"text-align: right;\">0.00307077 </td><td style=\"text-align: right;\">           3</td><td>GRU       </td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">            5</td><td style=\"text-align: right;\">    80</td><td style=\"text-align: right;\">        513.137 </td><td style=\"text-align: right;\">0.923008</td><td style=\"text-align: right;\">  0.478516</td><td style=\"text-align: right;\"> 0.00528039 </td></tr>\n",
       "<tr><td>objective_function_c372737d</td><td>TERMINATED</td><td>127.0.0.1:13892</td><td style=\"text-align: right;\">         256</td><td>False          </td><td style=\"text-align: right;\">      0.347436</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">1.39885e-05</td><td style=\"text-align: right;\">1.27981e-05</td><td style=\"text-align: right;\">           2</td><td>GRU       </td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         18.3196</td><td style=\"text-align: right;\">0.726458</td><td style=\"text-align: right;\">  0.303256</td><td style=\"text-align: right;\"> 0.25111    </td></tr>\n",
       "<tr><td>objective_function_9dea4be1</td><td>TERMINATED</td><td>127.0.0.1:38160</td><td style=\"text-align: right;\">         128</td><td>False          </td><td style=\"text-align: right;\">      0.58703 </td><td style=\"text-align: right;\">          384</td><td style=\"text-align: right;\">1.51725e-05</td><td style=\"text-align: right;\">0.00166133 </td><td style=\"text-align: right;\">           3</td><td>GRU       </td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">           20</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">        205.544 </td><td style=\"text-align: right;\">0.92246 </td><td style=\"text-align: right;\">  0.331772</td><td style=\"text-align: right;\"> 0.00127914 </td></tr>\n",
       "<tr><td>objective_function_11722d8c</td><td>TERMINATED</td><td>127.0.0.1:25776</td><td style=\"text-align: right;\">          64</td><td>True           </td><td style=\"text-align: right;\">      0.278181</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">4.29607e-06</td><td style=\"text-align: right;\">0.00357449 </td><td style=\"text-align: right;\">           2</td><td>GRU       </td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">        256.277 </td><td style=\"text-align: right;\">0.9067  </td><td style=\"text-align: right;\">  0.762454</td><td style=\"text-align: right;\"> 0.00534154 </td></tr>\n",
       "<tr><td>objective_function_7aca5e16</td><td>TERMINATED</td><td>127.0.0.1:16764</td><td style=\"text-align: right;\">          64</td><td>False          </td><td style=\"text-align: right;\">      0.225171</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">5.00642e-07</td><td style=\"text-align: right;\">0.000277961</td><td style=\"text-align: right;\">           2</td><td>GRU       </td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">        448.196 </td><td style=\"text-align: right;\">0.91115 </td><td style=\"text-align: right;\">  0.70839 </td><td style=\"text-align: right;\"> 0.000513496</td></tr>\n",
       "<tr><td>objective_function_21bc37fa</td><td>TERMINATED</td><td>127.0.0.1:38696</td><td style=\"text-align: right;\">         128</td><td>False          </td><td style=\"text-align: right;\">      0.552064</td><td style=\"text-align: right;\">          384</td><td style=\"text-align: right;\">0.000340872</td><td style=\"text-align: right;\">8.92558e-05</td><td style=\"text-align: right;\">           3</td><td>GRU       </td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">           20</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">        386.845 </td><td style=\"text-align: right;\">0.911977</td><td style=\"text-align: right;\">  0.551795</td><td style=\"text-align: right;\"> 0.00241239 </td></tr>\n",
       "<tr><td>objective_function_a44f2d1f</td><td>TERMINATED</td><td>127.0.0.1:17692</td><td style=\"text-align: right;\">          64</td><td>False          </td><td style=\"text-align: right;\">      0.58122 </td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">0.000133963</td><td style=\"text-align: right;\">4.99552e-05</td><td style=\"text-align: right;\">           3</td><td>GRU       </td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">            5</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">        234.797 </td><td style=\"text-align: right;\">0.894271</td><td style=\"text-align: right;\">  0.437723</td><td style=\"text-align: right;\"> 0.0331566  </td></tr>\n",
       "<tr><td>objective_function_268401f5</td><td>TERMINATED</td><td>127.0.0.1:38016</td><td style=\"text-align: right;\">         128</td><td>True           </td><td style=\"text-align: right;\">      0.274539</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">0.000261892</td><td style=\"text-align: right;\">0.000524035</td><td style=\"text-align: right;\">           2</td><td>GRU       </td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         36.1234</td><td style=\"text-align: right;\">0.909376</td><td style=\"text-align: right;\">  0.298095</td><td style=\"text-align: right;\"> 0.00817617 </td></tr>\n",
       "<tr><td>objective_function_7b40244a</td><td>TERMINATED</td><td>127.0.0.1:21436</td><td style=\"text-align: right;\">          64</td><td>False          </td><td style=\"text-align: right;\">      0.243009</td><td style=\"text-align: right;\">          384</td><td style=\"text-align: right;\">2.93087e-05</td><td style=\"text-align: right;\">0.000337927</td><td style=\"text-align: right;\">           2</td><td>GRU       </td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         52.1951</td><td style=\"text-align: right;\">0.909292</td><td style=\"text-align: right;\">  0.354353</td><td style=\"text-align: right;\"> 0.00723529 </td></tr>\n",
       "<tr><td>objective_function_8bc8bef3</td><td>TERMINATED</td><td>127.0.0.1:37988</td><td style=\"text-align: right;\">         256</td><td>True           </td><td style=\"text-align: right;\">      0.115342</td><td style=\"text-align: right;\">          384</td><td style=\"text-align: right;\">1.53411e-07</td><td style=\"text-align: right;\">0.000858906</td><td style=\"text-align: right;\">           3</td><td>GRU       </td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">            5</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">        319.522 </td><td style=\"text-align: right;\">0.928936</td><td style=\"text-align: right;\">  0.302115</td><td style=\"text-align: right;\"> 0.00220398 </td></tr>\n",
       "<tr><td>objective_function_046d24a2</td><td>TERMINATED</td><td>127.0.0.1:35624</td><td style=\"text-align: right;\">         128</td><td>False          </td><td style=\"text-align: right;\">      0.450205</td><td style=\"text-align: right;\">          384</td><td style=\"text-align: right;\">1.08527e-07</td><td style=\"text-align: right;\">0.00138921 </td><td style=\"text-align: right;\">           3</td><td>GRU       </td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">            5</td><td style=\"text-align: right;\">    80</td><td style=\"text-align: right;\">        316.764 </td><td style=\"text-align: right;\">0.919633</td><td style=\"text-align: right;\">  0.383613</td><td style=\"text-align: right;\"> 0.00329165 </td></tr>\n",
       "<tr><td>objective_function_8e96d4d7</td><td>TERMINATED</td><td>127.0.0.1:14644</td><td style=\"text-align: right;\">         256</td><td>False          </td><td style=\"text-align: right;\">      0.445336</td><td style=\"text-align: right;\">          384</td><td style=\"text-align: right;\">1.27366e-07</td><td style=\"text-align: right;\">0.00121521 </td><td style=\"text-align: right;\">           3</td><td>GRU       </td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">            5</td><td style=\"text-align: right;\">    80</td><td style=\"text-align: right;\">        181.328 </td><td style=\"text-align: right;\">0.92029 </td><td style=\"text-align: right;\">  0.247805</td><td style=\"text-align: right;\"> 0.00440827 </td></tr>\n",
       "<tr><td>objective_function_e279d66a</td><td>TERMINATED</td><td>127.0.0.1:21260</td><td style=\"text-align: right;\">         256</td><td>True           </td><td style=\"text-align: right;\">      0.133042</td><td style=\"text-align: right;\">          384</td><td style=\"text-align: right;\">1.21136e-07</td><td style=\"text-align: right;\">0.000980492</td><td style=\"text-align: right;\">           3</td><td>GRU       </td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">            5</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">        361.122 </td><td style=\"text-align: right;\">0.932423</td><td style=\"text-align: right;\">  0.237051</td><td style=\"text-align: right;\"> 0.00307607 </td></tr>\n",
       "<tr><td>objective_function_b7614168</td><td>TERMINATED</td><td>127.0.0.1:22360</td><td style=\"text-align: right;\">         256</td><td>True           </td><td style=\"text-align: right;\">      0.113396</td><td style=\"text-align: right;\">          384</td><td style=\"text-align: right;\">1.09072e-07</td><td style=\"text-align: right;\">0.000576004</td><td style=\"text-align: right;\">           3</td><td>GRU       </td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">            5</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">        369.771 </td><td style=\"text-align: right;\">0.928071</td><td style=\"text-align: right;\">  0.274731</td><td style=\"text-align: right;\"> 0.00013091 </td></tr>\n",
       "<tr><td>objective_function_bc267765</td><td>TERMINATED</td><td>127.0.0.1:13960</td><td style=\"text-align: right;\">         256</td><td>True           </td><td style=\"text-align: right;\">      0.352855</td><td style=\"text-align: right;\">          384</td><td style=\"text-align: right;\">5.81457e-07</td><td style=\"text-align: right;\">0.000711892</td><td style=\"text-align: right;\">           3</td><td>GRU       </td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">            5</td><td style=\"text-align: right;\">    80</td><td style=\"text-align: right;\">        248.049 </td><td style=\"text-align: right;\">0.925482</td><td style=\"text-align: right;\">  0.300619</td><td style=\"text-align: right;\"> 0.000801291</td></tr>\n",
       "<tr><td>objective_function_f805cc00</td><td>TERMINATED</td><td>127.0.0.1:30336</td><td style=\"text-align: right;\">         256</td><td>True           </td><td style=\"text-align: right;\">      0.1094  </td><td style=\"text-align: right;\">          384</td><td style=\"text-align: right;\">8.20773e-07</td><td style=\"text-align: right;\">0.000667882</td><td style=\"text-align: right;\">           3</td><td>GRU       </td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">            5</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         33.6197</td><td style=\"text-align: right;\">0.900155</td><td style=\"text-align: right;\">  0.274166</td><td style=\"text-align: right;\"> 0.0117103  </td></tr>\n",
       "<tr><td>objective_function_adaf6852</td><td>TERMINATED</td><td>127.0.0.1:37264</td><td style=\"text-align: right;\">         256</td><td>True           </td><td style=\"text-align: right;\">      0.347085</td><td style=\"text-align: right;\">          384</td><td style=\"text-align: right;\">5.98675e-07</td><td style=\"text-align: right;\">0.000110129</td><td style=\"text-align: right;\">           2</td><td>GRU       </td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         29.5367</td><td style=\"text-align: right;\">0.899208</td><td style=\"text-align: right;\">  0.298984</td><td style=\"text-align: right;\"> 0.0183511  </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-13 08:41:21,330\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to 'C:/Users/Karim Negm/ray_results/pirate_pain_split_search_v4' in 0.0337s.\n",
      "2025-11-13 08:41:21,345\tINFO tune.py:1041 -- Total run time: 2375.02 seconds (2374.91 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Search Complete ---\n",
      "\n",
      "Getting best trial from analysis...\n",
      "Best validation F1 score: 0.9289\n",
      "Best hyperparameters found:\n",
      "{'window_size': 5, 'stride': 2, 'rnn_type': 'GRU', 'lr': 0.000858905541206469, 'batch_size': 256, 'hidden_size': 384, 'num_layers': 3, 'dropout_rate': 0.11534212866495874, 'bidirectional': True, 'l2_lambda': 1.534108118032524e-07}\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Define the Search Space for Optuna --\n",
    "search_space = {\n",
    "    # Windowing params\n",
    "    \"window_size\": tune.choice([5, 10, 20]),\n",
    "    \"stride\": tune.choice([1, 2, 5]),\n",
    "    \n",
    "    # Model params\n",
    "    \"rnn_type\": tune.choice(['GRU']),\n",
    "    \"lr\": tune.loguniform(1e-5, 5e-3),\n",
    "    \"batch_size\": tune.choice([64, 128, 256]),  \n",
    "    \"hidden_size\": tune.choice([128, 256, 384]),\n",
    "    \"num_layers\": tune.choice([2, 3]),\n",
    "    \"dropout_rate\": tune.uniform(0.1, 0.6),\n",
    "    \"bidirectional\": tune.choice([True, False]),\n",
    "    \"l2_lambda\": tune.loguniform(1e-7, 1e-3) # This is weight_decay in AdamW\n",
    "}\n",
    "# --- 2. Define the Optimizer (Optuna) and Scheduler (ASHA) ---\n",
    "optuna_search = OptunaSearch(\n",
    "    metric=\"val_f1\",\n",
    "    mode=\"max\"\n",
    ")\n",
    "\n",
    "scheduler = ASHAScheduler(\n",
    "    metric=\"val_f1\",\n",
    "    mode=\"max\",\n",
    "    grace_period=20,  # Min epochs a trial must run\n",
    "    reduction_factor=2  # How aggressively to stop trials\n",
    ")\n",
    "\n",
    "# --- 3. Initialize Ray ---\n",
    "# Shutdown previous sessions if any (helps in notebooks)\n",
    "if ray.is_initialized():\n",
    "    ray.shutdown()\n",
    "\n",
    "ray_logs_path = os.path.abspath(\"./ray_results\")\n",
    "os.makedirs(ray_logs_path, exist_ok=True)\n",
    "os.environ[\"RAY_TEMP_DIR\"] = ray_logs_path\n",
    "\n",
    "ray.init(\n",
    "    num_cpus=16, \n",
    "    num_gpus=1, \n",
    "    ignore_reinit_error=True,\n",
    "    log_to_driver=False # Suppress logs in notebook\n",
    ")\n",
    "\n",
    "def short_trial_name(trial):\n",
    "    \"\"\"Creates a short, unique name for each trial folder.\"\"\"\n",
    "    return f\"{trial.trainable_name}_{trial.trial_id}\"\n",
    "\n",
    "\n",
    "# --- 4. Run the Tuner --\n",
    "print(\"Starting hyperparameter search...\")\n",
    "\n",
    "# Use tune.with_parameters to pass our NON-WINDOWED, *UNSCALED* train/val splits\n",
    "# and the class weights to the objective function.\n",
    "objective_with_data = tune.with_parameters(\n",
    "    objective_function, \n",
    "    X_train=X_train_split_full,\n",
    "    y_train=y_train_split_full,\n",
    "    X_val=X_val_split_full,\n",
    "    y_val=y_val_split_full,\n",
    "    class_weights_tensor=class_weights_tensor\n",
    ")\n",
    "\n",
    "analysis = tune.run(\n",
    "    objective_with_data,\n",
    "    resources_per_trial={\"cpu\": 4, \"gpu\": 0.25}, \n",
    "    config=search_space,\n",
    "    num_samples=20, \n",
    "    search_alg=optuna_search,\n",
    "    scheduler=scheduler,\n",
    "    name=\"pirate_pain_split_search_v4\",\n",
    "    trial_dirname_creator=short_trial_name,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n--- Search Complete ---\\n\")\n",
    "\n",
    "# --- 5. Get Best Results ---\n",
    "print(\"Getting best trial from analysis...\")\n",
    "best_trial = analysis.get_best_trial(metric=\"val_f1\", mode=\"max\", scope=\"all\")\n",
    "if best_trial:\n",
    "    FINAL_CONFIG = best_trial.config\n",
    "    FINAL_BEST_VAL_F1 = best_trial.last_result[\"val_f1\"]\n",
    "    \n",
    "    print(f\"Best validation F1 score: {FINAL_BEST_VAL_F1:.4f}\")\n",
    "    print(\"Best hyperparameters found:\")\n",
    "    print(FINAL_CONFIG)\n",
    "else:\n",
    "    print(\"ERROR: No trials completed successfully. Using a default config.\")\n",
    "    # Fallback config in case HPO fails\n",
    "    FINAL_CONFIG = {\n",
    "        'window_size': 10, 'stride': 10, 'rnn_type': 'GRU', 'lr': 0.0005,\n",
    "        'batch_size': 64, 'hidden_size': 256, 'num_layers': 3,\n",
    "        'dropout_rate': 0.5, 'bidirectional': True, 'l2_lambda': 1e-06\n",
    "    }\n",
    "    FINAL_BEST_VAL_F1 = 0.0\n",
    "\n",
    "# Clean up HPO data\n",
    "del X_train_split_full, y_train_split_full, X_val_split_full, y_val_split_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102c0bb8",
   "metadata": {},
   "source": [
    "## üèÜ 6. Phase 2: K-Fold Ensemble Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13308e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- üèÜ Final Configuration Set --- \n",
      "Best Val F1 from HPO search: 0.9289\n",
      "{'window_size': 5, 'stride': 2, 'rnn_type': 'GRU', 'lr': 0.000858905541206469, 'batch_size': 256, 'hidden_size': 384, 'num_layers': 3, 'dropout_rate': 0.11534212866495874, 'bidirectional': True, 'l2_lambda': 1.534108118032524e-07}\n",
      "Submission name will be: submission_GRU_H384_L3_BTrue_Optuna_KFold_Ensemble_v4_w5_s2.csv\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# --- üèÜ FINAL MODEL CONFIGURATION üèÜ ---\n",
    "# ===================================================================\n",
    "print(\"--- üèÜ Final Configuration Set --- \")\n",
    "print(f\"Best Val F1 from HPO search: {FINAL_BEST_VAL_F1:.4f}\")\n",
    "print(FINAL_CONFIG)\n",
    "\n",
    "# --- Set variables for the K-Fold & submission cells ---\n",
    "FINAL_MODEL_TYPE = FINAL_CONFIG[\"rnn_type\"]\n",
    "FINAL_HIDDEN_SIZE = FINAL_CONFIG[\"hidden_size\"]\n",
    "FINAL_HIDDEN_LAYERS = FINAL_CONFIG[\"num_layers\"]\n",
    "FINAL_BIDIRECTIONAL = FINAL_CONFIG[\"bidirectional\"]\n",
    "FINAL_DROPOUT_RATE = FINAL_CONFIG[\"dropout_rate\"]\n",
    "FINAL_LEARNING_RATE = FINAL_CONFIG[\"lr\"]\n",
    "FINAL_L2_LAMBDA = FINAL_CONFIG[\"l2_lambda\"]\n",
    "FINAL_BATCH_SIZE = FINAL_CONFIG[\"batch_size\"]\n",
    "FINAL_WINDOW_SIZE = FINAL_CONFIG[\"window_size\"]\n",
    "FINAL_STRIDE = FINAL_CONFIG[\"stride\"]\n",
    "N_SPLITS = 5 # Number of folds\n",
    "\n",
    "FINAL_EXPERIMENT_NAME = f\"{FINAL_MODEL_TYPE}_H{FINAL_HIDDEN_SIZE}_L{FINAL_HIDDEN_LAYERS}_B{FINAL_BIDIRECTIONAL}_Optuna_KFold_Ensemble_v4\"\n",
    "submission_filename_base = f\"submission_{FINAL_EXPERIMENT_NAME}_w{FINAL_WINDOW_SIZE}_s{FINAL_STRIDE}.csv\"\n",
    "print(f\"Submission name will be: {submission_filename_base}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bda55dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting 5-Fold CV Training ---\n",
      "Splitting original engineered data: (661, 160, 37)\n",
      "Using Class Weights: [0.06426252 0.34934196 0.5863955 ]\n",
      "\n",
      "--- Fold 1/5 --- (kfold_fold_1) ---\n",
      "  Fold Train Windows: (41184, 5, 37), Fold Val Windows: (10374, 5, 37)\n",
      "--- Starting Training: kfold_fold_1 ---\n",
      "Will train for 300 epochs with patience=30 monitoring val_f1\n",
      "Epoch   1/300 | Train: Loss=0.1645, F1=0.8612 | Val: Loss=0.2416, F1=0.8689\n",
      "Epoch  25/300 | Train: Loss=0.0038, F1=0.9966 | Val: Loss=0.3272, F1=0.9022\n",
      "Epoch  50/300 | Train: Loss=0.0007, F1=0.9988 | Val: Loss=0.4268, F1=0.8970\n",
      "\n",
      "Early stopping triggered after 55 epochs.\n",
      "Restoring best model from epoch 25 with val_f1 0.9022\n",
      "--- Finished Training: kfold_fold_1 ---\n",
      "Fold 1 Best Model Val F1: 0.9022\n",
      "\n",
      "--- Fold 2/5 --- (kfold_fold_2) ---\n",
      "  Fold Train Windows: (41262, 5, 37), Fold Val Windows: (10296, 5, 37)\n",
      "--- Starting Training: kfold_fold_2 ---\n",
      "Will train for 300 epochs with patience=30 monitoring val_f1\n",
      "Epoch   1/300 | Train: Loss=0.1637, F1=0.8510 | Val: Loss=0.1778, F1=0.9009\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 88\u001b[0m\n\u001b[0;32m     85\u001b[0m criterion_fold \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(weight\u001b[38;5;241m=\u001b[39mclass_weights_tensor)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# --- Train this fold with early stopping ---\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m model_fold, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader_fold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_fold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaler_fold_amp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwriter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfold_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\n\u001b[0;32m     95\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m val_loss, val_f1 \u001b[38;5;241m=\u001b[39m validate_one_epoch(model_fold, val_loader_fold, criterion_fold, device)\n\u001b[0;32m     98\u001b[0m fold_val_f1_list\u001b[38;5;241m.\u001b[39mappend(val_f1)\n",
      "Cell \u001b[1;32mIn[4], line 266\u001b[0m, in \u001b[0;36mfit\u001b[1;34m(model, train_loader, val_loader, epochs, criterion, optimizer, scaler, device, l1_lambda, l2_lambda, patience, evaluation_metric, mode, restore_best_weights, writer, verbose, experiment_name)\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    262\u001b[0m     train_loss, train_f1 \u001b[38;5;241m=\u001b[39m train_one_epoch(\n\u001b[0;32m    263\u001b[0m         model, train_loader, criterion, optimizer, scaler, device, l1_lambda, l2_lambda\n\u001b[0;32m    264\u001b[0m     )\n\u001b[1;32m--> 266\u001b[0m     val_loss, val_f1 \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_one_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    270\u001b[0m     training_history[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(train_loss)\n\u001b[0;32m    271\u001b[0m     training_history[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(val_loss)\n",
      "Cell \u001b[1;32mIn[4], line 129\u001b[0m, in \u001b[0;36mvalidate_one_epoch\u001b[1;34m(model, val_loader, criterion, device)\u001b[0m\n\u001b[0;32m    126\u001b[0m inputs, targets \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast(device_type\u001b[38;5;241m=\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype, enabled\u001b[38;5;241m=\u001b[39m(device\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[1;32m--> 129\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(logits, targets)\n\u001b[0;32m    132\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32me:\\miniconda3\\envs\\an2dl-kaggle\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\miniconda3\\envs\\an2dl-kaggle\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32me:\\miniconda3\\envs\\an2dl-kaggle\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:465\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    460\u001b[0m saved_dynamic_layer_stack_depth \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    461\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_functorch\u001b[38;5;241m.\u001b[39mget_dynamic_layer_stack_depth()\n\u001b[0;32m    462\u001b[0m )\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 465\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;66;03m# Restore the dynamic layer stack depth if necessary.\u001b[39;00m\n\u001b[0;32m    468\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_functorch\u001b[38;5;241m.\u001b[39mpop_dynamic_layer_stack_and_undo_to_depth(\n\u001b[0;32m    469\u001b[0m         saved_dynamic_layer_stack_depth\n\u001b[0;32m    470\u001b[0m     )\n",
      "File \u001b[1;32me:\\miniconda3\\envs\\an2dl-kaggle\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\miniconda3\\envs\\an2dl-kaggle\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[4], line 51\u001b[0m, in \u001b[0;36mRecurrentClassifier.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     50\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" x shape: (batch_size, seq_length, input_size) \"\"\"\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m     rnn_out, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrnn_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLSTM\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     54\u001b[0m         hidden \u001b[38;5;241m=\u001b[39m hidden[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;66;03m# Use only the hidden state, not the cell state\u001b[39;00m\n",
      "File \u001b[1;32me:\\miniconda3\\envs\\an2dl-kaggle\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\miniconda3\\envs\\an2dl-kaggle\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32me:\\miniconda3\\envs\\an2dl-kaggle\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1392\u001b[0m, in \u001b[0;36mGRU.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[0;32m   1391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1392\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgru\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1393\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1394\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1395\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1396\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1397\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1398\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1399\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1400\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1401\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1402\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1403\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1404\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mgru(\n\u001b[0;32m   1405\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   1406\u001b[0m         batch_sizes,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1413\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional,\n\u001b[0;32m   1414\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED) \n",
    "print(f\"--- Starting {N_SPLITS}-Fold CV Training ---\")\n",
    "print(f\"Splitting original engineered data: {X_train_full_engineered.shape}\")\n",
    "print(f\"Using Class Weights: {class_weights_tensor.cpu().numpy()}\")\n",
    "\n",
    "fold_val_f1_list = []\n",
    "\n",
    "# --- MODIFICATION: Define feature indices based on our 37 features ---\n",
    "joint_indices = list(range(31))\n",
    "pain_indices = list(range(31, 35))\n",
    "time_index = [35]\n",
    "pirate_index = [36]\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train_full_engineered, y_train_full)):\n",
    "    fold_name = f\"kfold_fold_{fold+1}\"\n",
    "    print(f\"\\n--- Fold {fold+1}/{N_SPLITS} --- ({fold_name}) ---\")\n",
    "    \n",
    "    X_train_fold_full = X_train_full_engineered[train_idx]\n",
    "    y_train_fold_full = y_train_full[train_idx]\n",
    "    X_val_fold_full = X_train_full_engineered[val_idx]\n",
    "    y_val_fold_full = y_train_full[val_idx]\n",
    "\n",
    "    # --- MODIFICATION: Scale INSIDE the fold (SELECTIVELY) ---\n",
    "    preprocessor_fold = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('joint_scaler', StandardScaler(), joint_indices),\n",
    "            ('pain_scaler', MinMaxScaler(), pain_indices),\n",
    "            ('time_scaler', MinMaxScaler(), time_index),\n",
    "            ('pirate_passthrough', 'passthrough', pirate_index)\n",
    "        ],\n",
    "        remainder='drop' \n",
    "    )\n",
    "    \n",
    "    # 1. Reshape to 2D for fitting/transforming\n",
    "    ns, ts, f = X_train_fold_full.shape\n",
    "    X_train_2d = X_train_fold_full.reshape(ns * ts, f)\n",
    "    ns_val, ts_val, f_val = X_val_fold_full.shape\n",
    "    X_val_2d = X_val_fold_full.reshape(ns_val * ts_val, f_val)\n",
    "\n",
    "    # 2. Fit preprocessor ONLY on 2D-reshaped training data\n",
    "    preprocessor_fold.fit(X_train_2d)\n",
    "\n",
    "    # 3. Transform 2D data for train and val\n",
    "    X_train_scaled_2d = preprocessor_fold.transform(X_train_2d)\n",
    "    X_val_scaled_2d = preprocessor_fold.transform(X_val_2d)\n",
    "\n",
    "    # 4. Reshape back to 3D\n",
    "    X_train_fold_scaled = X_train_scaled_2d.reshape(ns, ts, -1)\n",
    "    X_val_fold_scaled = X_val_scaled_2d.reshape(ns_val, ts_val, -1)\n",
    "    # --- End of Scaling Modification ---\n",
    "\n",
    "    # --- Create Sliding Windows (POST-SPLIT) ---\n",
    "    X_train_w, y_train_w, _ = create_sliding_windows(\n",
    "        X_train_fold_scaled, y_train_fold_full, \n",
    "        window_size=FINAL_WINDOW_SIZE, stride=FINAL_STRIDE\n",
    "    )\n",
    "    X_val_w, y_val_w, _ = create_sliding_windows(\n",
    "        X_val_fold_scaled, y_val_fold_full, \n",
    "        window_size=FINAL_WINDOW_SIZE, stride=FINAL_STRIDE\n",
    "    )\n",
    "    print(f\"  Fold Train Windows: {X_train_w.shape}, Fold Val Windows: {X_val_w.shape}\")\n",
    "\n",
    "    # --- Create Tensors, datasets and dataloaders --\n",
    "    X_train_fold = torch.from_numpy(X_train_w).float()\n",
    "    y_train_fold = torch.from_numpy(y_train_w).long()\n",
    "    X_val_fold = torch.from_numpy(X_val_w).float()\n",
    "    y_val_fold = torch.from_numpy(y_val_w).long()\n",
    "    train_ds_fold = TensorDataset(X_train_fold, y_train_fold)\n",
    "    val_ds_fold = TensorDataset(X_val_fold, y_val_fold)\n",
    "    \n",
    "    train_loader_fold = make_loader(train_ds_fold, batch_size=FINAL_BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "    val_loader_fold = make_loader(val_ds_fold, batch_size=FINAL_BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "    \n",
    "    # --- Create a fresh model (using FINAL_CONFIG) ---\n",
    "    model_fold = RecurrentClassifier(\n",
    "        input_size=N_FEATURES_NEW, # This is 37\n",
    "        hidden_size=FINAL_HIDDEN_SIZE, num_layers=FINAL_HIDDEN_LAYERS,\n",
    "        num_classes=N_CLASSES, dropout_rate=FINAL_DROPOUT_RATE,\n",
    "        bidirectional=FINAL_BIDIRECTIONAL, rnn_type=FINAL_MODEL_TYPE\n",
    "    ).to(device)\n",
    "    \n",
    "    if torch.__version__[0] >= \"2\": model_fold = torch.compile(model_fold)\n",
    "    optimizer_fold = torch.optim.AdamW(model_fold.parameters(), lr=FINAL_LEARNING_RATE, weight_decay=FINAL_L2_LAMBDA)\n",
    "    scaler_fold_amp = torch.amp.GradScaler(enabled=(device.type == 'cuda'))\n",
    "    criterion_fold = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "    \n",
    "    # --- Train this fold with early stopping ---\n",
    "    model_fold, _, _ = fit(\n",
    "        model=model_fold, train_loader=train_loader_fold,\n",
    "        val_loader=val_loader_fold, epochs=300,\n",
    "        criterion=criterion_fold, optimizer=optimizer_fold,\n",
    "        scaler=scaler_fold_amp, device=device,\n",
    "        writer=None, verbose=25,\n",
    "        experiment_name=fold_name, patience=30\n",
    "    )\n",
    "    \n",
    "    val_loss, val_f1 = validate_one_epoch(model_fold, val_loader_fold, criterion_fold, device)\n",
    "    fold_val_f1_list.append(val_f1)\n",
    "    print(f\"Fold {fold+1} Best Model Val F1: {val_f1:.4f}\")\n",
    "\n",
    "print(f\"\\n--- üèÜ K-Fold Training Complete ---\")\n",
    "print(f\"Fold F1 scores: {[round(f, 4) for f in fold_val_f1_list]}\")\n",
    "print(f\"Average F1 across folds: {np.mean(fold_val_f1_list):.4f}\")\n",
    "\n",
    "# Clean up\n",
    "del X_train_fold, y_train_fold, X_val_fold, y_val_fold\n",
    "del X_train_w, y_train_w, X_val_w, y_val_w\n",
    "del X_train_fold_full, y_train_fold_full, X_val_fold_full, y_val_fold_full\n",
    "del X_train_2d, X_train_scaled_2d, X_val_2d, X_val_scaled_2d\n",
    "del X_train_fold_scaled, X_val_fold_scaled, preprocessor_fold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f9d380",
   "metadata": {},
   "source": [
    "## üì¨ 7. Phase 3: Ensemble Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31871e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Preparing full dataset for FINAL PREPROCESSOR ---\")\n",
    "\n",
    "# --- 1. Prepare Final Preprocessor (Fit on ALL training data) ---\n",
    "\n",
    "# --- MODIFICATION: Define feature indices based on our 37 features ---\n",
    "joint_indices = list(range(31))\n",
    "pain_indices = list(range(31, 35))\n",
    "time_index = [35]\n",
    "pirate_index = [36]\n",
    "\n",
    "preprocessor_final = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('joint_scaler', StandardScaler(), joint_indices),\n",
    "        ('pain_scaler', MinMaxScaler(), pain_indices),\n",
    "        ('time_scaler', MinMaxScaler(), time_index),\n",
    "        ('pirate_passthrough', 'passthrough', pirate_index)\n",
    "    ],\n",
    "    remainder='drop' \n",
    ")\n",
    "\n",
    "# 2. Fit preprocessor ONLY on 2D-reshaped ALL training data\n",
    "ns, ts, f = X_train_full_engineered.shape\n",
    "X_train_full_2d = X_train_full_engineered.reshape(ns * ts, f)\n",
    "preprocessor_final.fit(X_train_full_2d)\n",
    "print(f\"Fitted FINAL preprocessor on all training data shape: {X_train_full_2d.shape}\")\n",
    "\n",
    "# --- 2. Prepare, Scale (Selectively), and Window the TEST data ---\n",
    "print(\"\\n--- Preparing Test Set (Selective Scaling) ---\")\n",
    "\n",
    "# 1. Reshape test data to 2D\n",
    "ns_test, ts_test, f_test = X_test_full_engineered.shape\n",
    "X_test_2d = X_test_full_engineered.reshape(ns_test * ts_test, f_test)\n",
    "\n",
    "# 2. Transform 2D test data\n",
    "X_test_scaled_2d = preprocessor_final.transform(X_test_2d)\n",
    "\n",
    "# 3. Reshape back to 3D\n",
    "X_test_final_scaled = X_test_scaled_2d.reshape(ns_test, ts_test, -1)\n",
    "print(f\"Created final scaled test set (shape: {X_test_final_scaled.shape})\")\n",
    "\n",
    "# --- 3. Apply Sliding Windows ---\n",
    "print(\"--- Applying sliding windows to final test set ---\")\n",
    "X_test_final_windowed, test_window_indices = create_sliding_windows(\n",
    "    X_test_final_scaled, y=None, \n",
    "    window_size=FINAL_WINDOW_SIZE, stride=FINAL_STRIDE\n",
    ")\n",
    "print(f\"Test windowed shape: {X_test_final_windowed.shape}\")\n",
    "\n",
    "# --- 4. Create Final TestLoader ---\n",
    "final_test_features = torch.from_numpy(X_test_final_windowed).float()\n",
    "final_test_ds = TensorDataset(final_test_features)\n",
    "test_loader = make_loader(final_test_ds, batch_size=FINAL_BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "print(\"Final TestLoader created.\")\n",
    "\n",
    "# --- 5. Get Predictions from all K-Fold Models ---\n",
    "all_fold_probabilities = []\n",
    "print(f\"\\n--- Generating predictions from {N_SPLITS} fold models ---\")\n",
    "\n",
    "for fold in range(N_SPLITS):\n",
    "    fold_name = f\"kfold_fold_{fold+1}\"\n",
    "    model_path = f\"models/{fold_name}_best_model.pt\"\n",
    "    print(f\"Loading model {fold+1}/{N_SPLITS} from {model_path}...\")\n",
    "\n",
    "    # Create a fresh model shell\n",
    "    model_fold = RecurrentClassifier(\n",
    "        input_size=N_FEATURES_NEW, # This is 37\n",
    "        hidden_size=FINAL_HIDDEN_SIZE, num_layers=FINAL_HIDDEN_LAYERS,\n",
    "        num_classes=N_CLASSES, dropout_rate=FINAL_DROPOUT_RATE,\n",
    "        bidirectional=FINAL_BIDIRECTIONAL, rnn_type=FINAL_MODEL_TYPE\n",
    "    ).to(device)\n",
    "    \n",
    "    # Load the saved weights (with compile-fix)\n",
    "    state_dict = torch.load(model_path, map_location=device)\n",
    "    # Remove the '_orig_mod.' prefix if model was compiled\n",
    "    new_state_dict = {k.replace('_orig_mod.', ''): v for k, v in state_dict.items()}\n",
    "    model_fold.load_state_dict(new_state_dict)\n",
    "    model_fold.eval()\n",
    "\n",
    "    # Get Softmax probabilities\n",
    "    fold_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for (inputs,) in test_loader: \n",
    "            inputs = inputs.to(device)\n",
    "            with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n",
    "                logits = model_fold(inputs)\n",
    "                probs = torch.softmax(logits, dim=1)\n",
    "                fold_predictions.append(probs.cpu().numpy())\n",
    "    all_fold_probabilities.append(np.concatenate(fold_predictions))\n",
    "\n",
    "# --- 6. Average the Probabilities ---\n",
    "print(f\"\\n--- Averaging {len(all_fold_probabilities)} sets of probabilities... ---\")\n",
    "mean_probabilities = np.mean(all_fold_probabilities, axis=0)\n",
    "print(f\"Mean probability matrix shape: {mean_probabilities.shape}\")\n",
    "\n",
    "# --- 7. Aggregate Mean Probabilities (MEAN) ---\n",
    "print(\"Aggregating window probabilities to sample predictions (using MEAN)...\")\n",
    "prob_cols = [f\"prob_{i}\" for i in range(N_CLASSES)]\n",
    "df_probs = pd.DataFrame(mean_probabilities, columns=prob_cols)\n",
    "df_probs['original_index'] = test_window_indices \n",
    "agg_probs = df_probs.groupby('original_index')[prob_cols].mean().values\n",
    "print(f\"Aggregated to {len(agg_probs)} final probability vectors.\")\n",
    "\n",
    "# --- 8. Get Final Predictions and Save ---\n",
    "final_predictions_numeric = np.argmax(agg_probs, axis=1)\n",
    "predicted_labels = le.inverse_transform(final_predictions_numeric)\n",
    "\n",
    "print(\"Loading sample submission file for correct formatting...\")\n",
    "test_sample_indices = sorted(X_test_long_df['sample_index'].unique())\n",
    "\n",
    "if len(predicted_labels) != len(test_sample_indices):\n",
    "    print(f\"ERROR: Prediction count mismatch!\")\n",
    "else:\n",
    "    print(\"Prediction count matches. Creating submission.\")\n",
    "    final_submission_df = pd.DataFrame({\n",
    "        'sample_index': test_sample_indices,\n",
    "        'label': predicted_labels \n",
    "    })\n",
    "    final_submission_df['sample_index'] = final_submission_df['sample_index'].apply(lambda x: f\"{x:03d}\")\n",
    "\n",
    "    submission_filepath = os.path.join(\"submissions\", submission_filename_base)\n",
    "    final_submission_df.to_csv(submission_filepath, index=False)\n",
    "\n",
    "    print(f\"\\nSuccessfully saved to {submission_filepath}!\")\n",
    "    print(\"This file is correctly formatted for Kaggle:\")\n",
    "    print(final_submission_df.head())\n",
    "\n",
    "# Clean up\n",
    "del all_fold_probabilities, final_test_features, final_test_ds, test_loader\n",
    "del X_test_full_engineered, X_test_final_scaled, X_test_final_windowed\n",
    "del X_train_full_2d, preprocessor_final\n",
    "del X_test_2d, X_test_scaled_2d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "an2dl-kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
