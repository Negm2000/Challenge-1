{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67bb0a3d",
   "metadata": {},
   "source": [
    "# **Kaggle Challenge: Pirate Pain Dataset üè¥‚Äç‚ò†Ô∏è (v7: Conv1d + LR Scheduler)**\n",
    "\n",
    "This notebook introduces a powerful Conv1d-GRU architecture to break through performance plateaus. It combines 1D convolutions for low-level feature extraction with a GRU for high-level sequence modeling.\n",
    "\n",
    "**Strategy:**\n",
    "1.  **Hybrid Feature Input:**\n",
    "    * **Continuous Features:** 31 `joint_` features + 1 `time` feature are scaled.\n",
    "    * **Categorical Features:** 4 `pain_survey_` features + 1 `is_pirate` feature are passed to `nn.Embedding` layers.\n",
    "2.  **Conv1d-GRU Architecture:**\n",
    "    *   A **`nn.Conv1d`** layer first processes the full sequence of combined features to identify local, time-invariant patterns.\n",
    "    *   The output sequence from the Conv1d layer is then fed into the **`nn.GRU`** to model longer-term temporal dependencies.\n",
    "3.  **Advanced Training:**\n",
    "    *   A **`CosineAnnealingLR`** learning rate scheduler is used to improve convergence and find better minima.\n",
    "    *   Heavy regularization via two separate `Dropout` layers (one for features, one for the GRU) is used to prevent overfitting.\n",
    "4.  **Hyperparameter Search:** Ray Tune & Optuna are used to find optimal parameters for the entire Conv1d-GRU stack, including the LR scheduler.\n",
    "5.  **K-Fold Ensemble:** The best configuration is trained on 5 folds for a robust final prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b03291d",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è 1. Setup & Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ba22088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Using GPU ---\n",
      "PyTorch version: 2.5.1\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set seed for reproducibility\n",
    "SEED = 123\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "import logging\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import copy\n",
    "from itertools import product\n",
    "import time\n",
    "\n",
    "# Set environment variables before importing modules\n",
    "os.environ['MPLCONFIGDIR'] = os.getcwd() + '/configs/'\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "# --- PyTorch Imports ---\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# --- Sklearn Imports ---\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "# --- Ray[tune] & Optuna Imports ---\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.search.optuna import OptunaSearch\n",
    "from functools import partial\n",
    "\n",
    "# --- Setup Directories & Device ---\n",
    "logs_dir = \"tensorboard\"\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "os.makedirs(\"submissions\", exist_ok=True)\n",
    "os.makedirs(logs_dir, exist_ok=True)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    print(\"\\n--- Using GPU ---\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"\\n--- Using CPU ---\")\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Configure plot display settings\n",
    "sns.set_theme(font_scale=1.4)\n",
    "sns.set_style('white')\n",
    "plt.rc('font', size=14)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8582ef",
   "metadata": {},
   "source": [
    "## üîÑ 2. Data Loading & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "44203b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Loading Data ---\n",
      "Loaded X_train_full (shape: (661, 160, 36)) and y_train_full (shape: (661,))\n",
      "Loaded X_test_full (shape: (1324, 160, 36))\n",
      "\n",
      "--- 2. Engineering 'is_pirate' Feature ---\n",
      "Created X_train_full_engineered (shape: (661, 160, 37))\n",
      "Created X_test_full_engineered (shape: (1324, 160, 37))\n",
      "N_FEATURES is now: 37\n",
      "\n",
      "--- 3. Calculating Class Weights ---\n",
      "Class counts (0, 1, 2): [511  94  56]\n",
      "Calculated class weights: tensor([0.0643, 0.3493, 0.5864], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"--- 1. Loading Data ---\")\n",
    "\n",
    "# --- Define File Paths and Features ---\n",
    "DATA_DIR = \"data\"\n",
    "X_TRAIN_PATH = os.path.join(DATA_DIR, \"pirate_pain_train.csv\")\n",
    "Y_TRAIN_PATH = os.path.join(DATA_DIR, \"pirate_pain_train_labels.csv\")\n",
    "X_TEST_PATH = os.path.join(DATA_DIR, \"pirate_pain_test.csv\")\n",
    "SUBMISSION_PATH = os.path.join(DATA_DIR, \"sample_submission.csv\")\n",
    "\n",
    "try:\n",
    "    features_long_df = pd.read_csv(X_TRAIN_PATH)\n",
    "    labels_df = pd.read_csv(Y_TRAIN_PATH)\n",
    "    X_test_long_df = pd.read_csv(X_TEST_PATH)\n",
    "    \n",
    "    N_TIMESTEPS = 160\n",
    "    JOINT_FEATURES = [f\"joint_{i:02d}\" for i in range(31)]\n",
    "    PAIN_FEATURES = [f\"pain_survey_{i}\" for i in range(1, 5)]\n",
    "    TIME_FEATURE = ['time']\n",
    "    FEATURES = JOINT_FEATURES + PAIN_FEATURES + TIME_FEATURE\n",
    "    LABEL_MAPPING = {'no_pain': 0, 'low_pain': 1, 'high_pain': 2}\n",
    "    N_CLASSES = len(LABEL_MAPPING)\n",
    "\n",
    "    def reshape_data(df, features_list, n_timesteps):\n",
    "        df_pivot = df.pivot(index='sample_index', columns='time', values=features_list)\n",
    "        data_2d = df_pivot.values\n",
    "        n_samples = data_2d.shape[0]\n",
    "        data_3d = data_2d.reshape(n_samples, len(features_list), n_timesteps)\n",
    "        return data_3d.transpose(0, 2, 1)\n",
    "\n",
    "    X_train_full = reshape_data(features_long_df[features_long_df['sample_index'].isin(labels_df['sample_index'].unique())], FEATURES, N_TIMESTEPS)\n",
    "    X_test_full = reshape_data(X_test_long_df, FEATURES, N_TIMESTEPS)\n",
    "    y_train_full_df = labels_df.sort_values(by='sample_index')\n",
    "    le = LabelEncoder().fit(list(LABEL_MAPPING.keys()))\n",
    "    y_train_full = le.transform(y_train_full_df['label'])\n",
    "    print(f\"Loaded X_train_full (shape: {X_train_full.shape}) and y_train_full (shape: {y_train_full.shape})\")\n",
    "    print(f\"Loaded X_test_full (shape: {X_test_full.shape})\")\n",
    "\n",
    "    print(\"\\n--- 2. Engineering 'is_pirate' Feature ---\")\n",
    "    static_cols = ['sample_index', 'n_legs', 'n_hands', 'n_eyes']\n",
    "    static_df = features_long_df[static_cols].drop_duplicates().set_index('sample_index')\n",
    "    pirate_filter = (static_df['n_legs'] == 'one+peg_leg') | (static_df['n_hands'] == 'one+hook_hand') | (static_df['n_eyes'] == 'one+eye_patch')\n",
    "    pirate_indices = static_df[pirate_filter].index\n",
    "    sample_indices_ordered = sorted(features_long_df[features_long_df['sample_index'].isin(labels_df['sample_index'].unique())]['sample_index'].unique())\n",
    "    is_pirate_map = np.array([1 if idx in pirate_indices else 0 for idx in sample_indices_ordered])\n",
    "    pirate_feature_broadcast = np.tile(is_pirate_map.reshape(-1, 1, 1), (1, N_TIMESTEPS, 1))\n",
    "    X_train_full_engineered = np.concatenate([X_train_full, pirate_feature_broadcast], axis=2)\n",
    "\n",
    "    static_df_test = X_test_long_df[static_cols].drop_duplicates().set_index('sample_index')\n",
    "    pirate_filter_test = (static_df_test['n_legs'] == 'one+peg_leg') | (static_df_test['n_hands'] == 'one+hook_hand') | (static_df_test['n_eyes'] == 'one+eye_patch')\n",
    "    pirate_indices_test = static_df_test[pirate_filter_test].index\n",
    "    sample_indices_test_ordered = sorted(X_test_long_df['sample_index'].unique())\n",
    "    is_pirate_map_test = np.array([1 if idx in pirate_indices_test else 0 for idx in sample_indices_test_ordered])\n",
    "    pirate_feature_broadcast_test = np.tile(is_pirate_map_test.reshape(-1, 1, 1), (1, N_TIMESTEPS, 1))\n",
    "    X_test_full_engineered = np.concatenate([X_test_full, pirate_feature_broadcast_test], axis=2)\n",
    "    \n",
    "    N_FEATURES_NEW = X_train_full_engineered.shape[2]\n",
    "    print(f\"Created X_train_full_engineered (shape: {X_train_full_engineered.shape})\")\n",
    "    print(f\"Created X_test_full_engineered (shape: {X_test_full_engineered.shape})\")\n",
    "    print(f\"N_FEATURES is now: {N_FEATURES_NEW}\")\n",
    "\n",
    "    print(\"\\n--- 3. Calculating Class Weights ---\")\n",
    "    class_counts_series = labels_df['label'].value_counts()\n",
    "    counts_ordered = class_counts_series.reindex(LABEL_MAPPING.keys()).values\n",
    "    class_weights_tensor = 1.0 / torch.tensor(counts_ordered, dtype=torch.float)\n",
    "    class_weights_tensor = (class_weights_tensor / class_weights_tensor.sum()).to(device)\n",
    "    print(f\"Class counts (0, 1, 2): {counts_ordered}\")\n",
    "    print(f\"Calculated class weights: {class_weights_tensor}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6f8bc4",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è 3. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a7c2d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sliding_windows(X_3d, y=None, window_size=100, stride=20):\n",
    "    new_X, new_y, window_indices = [], [], []\n",
    "    n_samples, n_timesteps, _ = X_3d.shape\n",
    "    for i in range(n_samples):\n",
    "        idx = 0\n",
    "        while (idx + window_size) <= n_timesteps:\n",
    "            new_X.append(X_3d[i, idx:idx+window_size, :])\n",
    "            window_indices.append(i)\n",
    "            if y is not None: new_y.append(y[i])\n",
    "            idx += stride\n",
    "    if y is not None:\n",
    "        return np.array(new_X), np.array(new_y), np.array(window_indices)\n",
    "    return np.array(new_X), np.array(window_indices)\n",
    "\n",
    "def make_loader(ds, batch_size, shuffle, drop_last):\n",
    "    return DataLoader(ds, batch_size=int(batch_size), shuffle=shuffle, drop_last=drop_last, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faed930",
   "metadata": {},
   "source": [
    "## üß† 4. Model & Training Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cd3cadd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentClassifier(nn.Module):\n",
    "    def __init__(self, hidden_size, num_layers, num_classes,\n",
    "                 conv_out_channels, conv_kernel_size, bidirectional,\n",
    "                 dropout_rate, feature_dropout_rate, rnn_type='GRU'):\n",
    "        super().__init__()\n",
    "        self.rnn_type, self.num_layers, self.hidden_size, self.bidirectional = \\\n",
    "            rnn_type, num_layers, hidden_size, bidirectional\n",
    "\n",
    "        # --- Feature Engineering Layers ---\n",
    "        self.pain_embed_dim, self.pirate_embed_dim = 4, 4\n",
    "        self.pain_embeddings = nn.ModuleList([nn.Embedding(3, self.pain_embed_dim) for _ in range(4)])\n",
    "        self.pirate_embedding = nn.Embedding(2, self.pirate_embed_dim)\n",
    "        \n",
    "        num_continuous_features = 32 # 31 joints + 1 time\n",
    "        total_embedding_dim = (4 * self.pain_embed_dim) + self.pirate_embed_dim\n",
    "        conv_input_size = num_continuous_features + total_embedding_dim\n",
    "\n",
    "        # --- Conv1d Layer for Feature Extraction ---\n",
    "        self.conv1d = nn.Conv1d(in_channels=conv_input_size, out_channels=conv_out_channels,\n",
    "                                kernel_size=conv_kernel_size, padding='same')\n",
    "        self.conv_activation = nn.ReLU()\n",
    "        self.feature_dropout = nn.Dropout(feature_dropout_rate)\n",
    "\n",
    "        # --- RNN Layer for Sequence Modeling ---\n",
    "        self.rnn = nn.GRU(\n",
    "            input_size=conv_out_channels, hidden_size=hidden_size,\n",
    "            num_layers=num_layers, batch_first=True, bidirectional=bidirectional,\n",
    "            dropout=dropout_rate if num_layers > 1 else 0)\n",
    "        \n",
    "        # --- Classifier Head ---\n",
    "        self.classifier = nn.Linear(hidden_size * 2 if bidirectional else hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_continuous = x[:, :, :32]\n",
    "        x_categorical = x[:, :, 32:].long()\n",
    "        embedded_cats = [self.pain_embeddings[i](x_categorical[:, :, i]) for i in range(4)] \\\n",
    "                      + [self.pirate_embedding(x_categorical[:, :, 4])]\n",
    "        x_combined = torch.cat([x_continuous] + embedded_cats, dim=2)\n",
    "        x_permuted = x_combined.permute(0, 2, 1)\n",
    "        x_conv = self.conv_activation(self.conv1d(x_permuted))\n",
    "        x_conv_permuted = x_conv.permute(0, 2, 1)\n",
    "        x_dropped = self.feature_dropout(x_conv_permuted)\n",
    "        _, hidden = self.rnn(x_dropped)\n",
    "        if self.bidirectional:\n",
    "            hidden = hidden.view(self.num_layers, 2, -1, self.hidden_size)\n",
    "            hidden = torch.cat([hidden[-1, 0, :, :], hidden[-1, 1, :, :]], dim=1)\n",
    "        else:\n",
    "            hidden = hidden[-1]\n",
    "        return self.classifier(hidden)\n",
    "\n",
    "def train_one_epoch(model, loader, criterion, optimizer, scaler, device):\n",
    "    model.train()\n",
    "    total_loss, all_preds, all_targets = 0, [], []\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "        all_preds.append(logits.argmax(dim=1).cpu().numpy())\n",
    "        all_targets.append(y.cpu().numpy())\n",
    "    return total_loss / len(loader.dataset.tensors[0]), f1_score(np.concatenate(all_targets), np.concatenate(all_preds), average='weighted')\n",
    "\n",
    "def validate_one_epoch(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss, all_preds, all_targets = 0, [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n",
    "                logits = model(x)\n",
    "                loss = criterion(logits, y)\n",
    "            total_loss += loss.item() * x.size(0)\n",
    "            all_preds.append(logits.argmax(dim=1).cpu().numpy())\n",
    "            all_targets.append(y.cpu().numpy())\n",
    "    return total_loss / len(loader.dataset.tensors[0]), f1_score(np.concatenate(all_targets), np.concatenate(all_preds), average='weighted')\n",
    "\n",
    "def objective_function(config, X_train, y_train, X_val, y_val, class_weights):\n",
    "    continuous_indices = list(range(32))\n",
    "    preprocessor = ColumnTransformer([('scaler', StandardScaler(), continuous_indices)], remainder='passthrough')\n",
    "    ns, ts, f = X_train.shape\n",
    "    X_train_final = preprocessor.fit_transform(X_train.reshape(ns * ts, f)).reshape(ns, ts, -1)\n",
    "    ns_val, ts_val, f_val = X_val.shape\n",
    "    X_val_final = preprocessor.transform(X_val.reshape(ns_val * ts_val, f_val)).reshape(ns_val, ts_val, -1)\n",
    "\n",
    "    X_train_w, y_train_w, _ = create_sliding_windows(X_train_final, y_train, config[\"window_size\"], config[\"stride\"])\n",
    "    X_val_w, y_val_w, _ = create_sliding_windows(X_val_final, y_val, config[\"window_size\"], config[\"stride\"])\n",
    "    train_loader = make_loader(TensorDataset(torch.from_numpy(X_train_w).float(), torch.from_numpy(y_train_w).long()), config[\"batch_size\"], True, True)\n",
    "    val_loader = make_loader(TensorDataset(torch.from_numpy(X_val_w).float(), torch.from_numpy(y_val_w).long()), config[\"batch_size\"], False, False)\n",
    "\n",
    "    model_config = {\n",
    "        'hidden_size': config['hidden_size'], 'num_layers': config['num_layers'],\n",
    "        'conv_out_channels': config['conv_out_channels'], 'conv_kernel_size': config['conv_kernel_size'],\n",
    "        'bidirectional': config['bidirectional'], 'dropout_rate': config['dropout_rate'],\n",
    "        'feature_dropout_rate': config['feature_dropout_rate']\n",
    "    }\n",
    "    model = RecurrentClassifier(**model_config, num_classes=N_CLASSES, rnn_type='GRU').to(device)\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config[\"lr\"], weight_decay=config[\"l2_lambda\"])\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=150)\n",
    "    scaler = torch.amp.GradScaler(enabled=(device.type == 'cuda'))\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "    best_val_f1 = -1.0\n",
    "    patience_counter = 0\n",
    "    # Set a fixed patience for all HPO trials\n",
    "    hpo_patience = 20  \n",
    "    \n",
    "    for epoch in range(1, 151):\n",
    "        train_loss, _ = train_one_epoch(model, train_loader, criterion, optimizer, scaler, device)\n",
    "        _, val_f1 = validate_one_epoch(model, val_loader, criterion, device)\n",
    "        tune.report({\"val_f1\": val_f1, \"train_loss\": train_loss})\n",
    "        scheduler.step()\n",
    "\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= hpo_patience:\n",
    "                print(f\"Trial early stopping at epoch {epoch}\")\n",
    "                break # Stop training\n",
    "\n",
    "def fit(model, train_loader, val_loader, epochs, criterion, optimizer, scheduler, scaler, device, patience, experiment_name):\n",
    "    model_path = f\"models/{experiment_name}_best_model.pt\"\n",
    "    best_f1 = -1\n",
    "    patience_counter = 0\n",
    "    print(f\"--- Starting Training: {experiment_name} ---\")\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_loss, train_f1 = train_one_epoch(model, train_loader, criterion, optimizer, scaler, device)\n",
    "        val_loss, val_f1 = validate_one_epoch(model, val_loader, criterion, device)\n",
    "        scheduler.step()\n",
    "\n",
    "        if epoch % 25 == 0: print(f\"Epoch {epoch:3d}/{epochs} | Val F1: {val_f1:.4f} | LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "\n",
    "        if val_f1 > best_f1:\n",
    "            best_f1, patience_counter = val_f1, 0\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch}. Best F1: {best_f1:.4f}\")\n",
    "                break\n",
    "    print(f\"--- Finished Training --- Best F1: {best_f1:.4f}\")\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9f911c",
   "metadata": {},
   "source": [
    "## üß™ 5. Phase 1: Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d09a835f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-ordered X_train_full shape: (661, 160, 37)\n",
      "\n",
      "--- Splitting re-ordered, unscaled data for HPO ---\n",
      "  X_train_split: (528, 160, 37)\n",
      "  X_val_split:   (133, 160, 37)\n"
     ]
    }
   ],
   "source": [
    "# Re-order columns: 32 continuous (joints+time), then 5 categorical (pain+pirate)\n",
    "continuous_indices_orig = list(range(31)) + [35]\n",
    "categorical_indices_orig = list(range(31, 35)) + [36]\n",
    "X_train_full_reordered = np.concatenate([\n",
    "    X_train_full_engineered[:, :, continuous_indices_orig],\n",
    "    X_train_full_engineered[:, :, categorical_indices_orig]\n",
    "], axis=2)\n",
    "print(f\"Re-ordered X_train_full shape: {X_train_full_reordered.shape}\")\n",
    "\n",
    "# --- Split the re-ordered data ---\n",
    "print(\"\\n--- Splitting re-ordered, unscaled data for HPO ---\")\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED)\n",
    "for train_idx, val_idx in sss.split(X_train_full_reordered, y_train_full):\n",
    "    X_train_split, y_train_split = X_train_full_reordered[train_idx], y_train_full[train_idx]\n",
    "    X_val_split, y_val_split = X_train_full_reordered[val_idx], y_train_full[val_idx]\n",
    "print(f\"  X_train_split: {X_train_split.shape}\\n  X_val_split:   {X_val_split.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42797c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2025-11-13 13:55:08</td></tr>\n",
       "<tr><td>Running for: </td><td>01:32:06.04        </td></tr>\n",
       "<tr><td>Memory:      </td><td>8.4/13.9 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=30<br>Bracket: Iter 100.000: 0.9264052383524888 | Iter 50.000: 0.9233304876526616 | Iter 25.000: 0.9158548941908977<br>Logical resource usage: 4.0/16 CPUs, 0.25/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th>bidirectional  </th><th style=\"text-align: right;\">  conv_kernel_size</th><th style=\"text-align: right;\">  conv_out_channels</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  feature_dropout_rate</th><th style=\"text-align: right;\">  hidden_size</th><th style=\"text-align: right;\">  l2_lambda</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  num_layers</th><th style=\"text-align: right;\">  stride</th><th style=\"text-align: right;\">  window_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  val_f1</th><th style=\"text-align: right;\">  val_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>objective_function_56e3c4cb</td><td>TERMINATED</td><td>127.0.0.1:34056</td><td style=\"text-align: right;\">          64</td><td>True           </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.175474</td><td style=\"text-align: right;\">              0.236743</td><td style=\"text-align: right;\">          384</td><td style=\"text-align: right;\">5.6326e-06 </td><td style=\"text-align: right;\">0.00261819 </td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         456.531</td><td style=\"text-align: right;\">0.900907</td><td style=\"text-align: right;\">  0.709033</td></tr>\n",
       "<tr><td>objective_function_0114e8de</td><td>TERMINATED</td><td>127.0.0.1:2468 </td><td style=\"text-align: right;\">         128</td><td>True           </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.426372</td><td style=\"text-align: right;\">              0.444383</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">1.60923e-07</td><td style=\"text-align: right;\">0.00218217 </td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         967.473</td><td style=\"text-align: right;\">0.939522</td><td style=\"text-align: right;\">  0.367894</td></tr>\n",
       "<tr><td>objective_function_157353eb</td><td>TERMINATED</td><td>127.0.0.1:13720</td><td style=\"text-align: right;\">         128</td><td>False          </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                 64</td><td style=\"text-align: right;\">      0.241345</td><td style=\"text-align: right;\">              0.268222</td><td style=\"text-align: right;\">          384</td><td style=\"text-align: right;\">2.21765e-06</td><td style=\"text-align: right;\">0.000113209</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         735.088</td><td style=\"text-align: right;\">0.910966</td><td style=\"text-align: right;\">  0.61634 </td></tr>\n",
       "<tr><td>objective_function_ebc904f4</td><td>TERMINATED</td><td>127.0.0.1:22020</td><td style=\"text-align: right;\">         128</td><td>True           </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                 64</td><td style=\"text-align: right;\">      0.277957</td><td style=\"text-align: right;\">              0.461164</td><td style=\"text-align: right;\">          384</td><td style=\"text-align: right;\">2.92564e-06</td><td style=\"text-align: right;\">0.00245462 </td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         335.092</td><td style=\"text-align: right;\">0.888099</td><td style=\"text-align: right;\">  0.434215</td></tr>\n",
       "<tr><td>objective_function_8f7406c6</td><td>TERMINATED</td><td>127.0.0.1:36252</td><td style=\"text-align: right;\">         128</td><td>True           </td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.27791 </td><td style=\"text-align: right;\">              0.359588</td><td style=\"text-align: right;\">          384</td><td style=\"text-align: right;\">2.09787e-07</td><td style=\"text-align: right;\">0.000219033</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         473.882</td><td style=\"text-align: right;\">0.912075</td><td style=\"text-align: right;\">  0.395935</td></tr>\n",
       "<tr><td>objective_function_d5e492ef</td><td>TERMINATED</td><td>127.0.0.1:4968 </td><td style=\"text-align: right;\">          64</td><td>False          </td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">                 64</td><td style=\"text-align: right;\">      0.441283</td><td style=\"text-align: right;\">              0.212717</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">5.14675e-07</td><td style=\"text-align: right;\">0.000113936</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         418.598</td><td style=\"text-align: right;\">0.905957</td><td style=\"text-align: right;\">  0.548129</td></tr>\n",
       "<tr><td>objective_function_852c3d23</td><td>TERMINATED</td><td>127.0.0.1:3376 </td><td style=\"text-align: right;\">         128</td><td>True           </td><td style=\"text-align: right;\">                 7</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.391865</td><td style=\"text-align: right;\">              0.486706</td><td style=\"text-align: right;\">          384</td><td style=\"text-align: right;\">9.35463e-06</td><td style=\"text-align: right;\">0.00015649 </td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         985.054</td><td style=\"text-align: right;\">0.924307</td><td style=\"text-align: right;\">  0.446337</td></tr>\n",
       "<tr><td>objective_function_3a07201a</td><td>TERMINATED</td><td>127.0.0.1:11188</td><td style=\"text-align: right;\">         128</td><td>True           </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                 64</td><td style=\"text-align: right;\">      0.135691</td><td style=\"text-align: right;\">              0.371211</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">1.33904e-07</td><td style=\"text-align: right;\">0.000515261</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         239.862</td><td style=\"text-align: right;\">0.902697</td><td style=\"text-align: right;\">  0.37231 </td></tr>\n",
       "<tr><td>objective_function_30a5c92c</td><td>TERMINATED</td><td>127.0.0.1:28140</td><td style=\"text-align: right;\">         128</td><td>False          </td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">                 64</td><td style=\"text-align: right;\">      0.346796</td><td style=\"text-align: right;\">              0.284239</td><td style=\"text-align: right;\">          384</td><td style=\"text-align: right;\">5.55062e-07</td><td style=\"text-align: right;\">0.00285635 </td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         763.612</td><td style=\"text-align: right;\">0.92575 </td><td style=\"text-align: right;\">  0.391817</td></tr>\n",
       "<tr><td>objective_function_7a1c2879</td><td>TERMINATED</td><td>127.0.0.1:30460</td><td style=\"text-align: right;\">          64</td><td>True           </td><td style=\"text-align: right;\">                 7</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.494826</td><td style=\"text-align: right;\">              0.372097</td><td style=\"text-align: right;\">          384</td><td style=\"text-align: right;\">2.1274e-05 </td><td style=\"text-align: right;\">0.000119174</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         987.879</td><td style=\"text-align: right;\">0.909048</td><td style=\"text-align: right;\">  0.601995</td></tr>\n",
       "<tr><td>objective_function_a707e2ed</td><td>TERMINATED</td><td>127.0.0.1:31916</td><td style=\"text-align: right;\">          64</td><td>False          </td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">                 64</td><td style=\"text-align: right;\">      0.240097</td><td style=\"text-align: right;\">              0.305991</td><td style=\"text-align: right;\">          384</td><td style=\"text-align: right;\">2.55681e-05</td><td style=\"text-align: right;\">0.000128469</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">        1590.3  </td><td style=\"text-align: right;\">0.926902</td><td style=\"text-align: right;\">  0.558609</td></tr>\n",
       "<tr><td>objective_function_09421e6d</td><td>TERMINATED</td><td>127.0.0.1:38132</td><td style=\"text-align: right;\">         128</td><td>True           </td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">                 64</td><td style=\"text-align: right;\">      0.234532</td><td style=\"text-align: right;\">              0.225177</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">3.00455e-06</td><td style=\"text-align: right;\">0.00205964 </td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">        1141.01 </td><td style=\"text-align: right;\">0.93062 </td><td style=\"text-align: right;\">  0.393101</td></tr>\n",
       "<tr><td>objective_function_45a86f16</td><td>TERMINATED</td><td>127.0.0.1:25416</td><td style=\"text-align: right;\">         128</td><td>True           </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                 64</td><td style=\"text-align: right;\">      0.396544</td><td style=\"text-align: right;\">              0.319418</td><td style=\"text-align: right;\">          384</td><td style=\"text-align: right;\">2.34997e-06</td><td style=\"text-align: right;\">0.00159441 </td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         233.784</td><td style=\"text-align: right;\">0.913384</td><td style=\"text-align: right;\">  0.396986</td></tr>\n",
       "<tr><td>objective_function_ee03ca7e</td><td>TERMINATED</td><td>127.0.0.1:32672</td><td style=\"text-align: right;\">          64</td><td>True           </td><td style=\"text-align: right;\">                 7</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.279798</td><td style=\"text-align: right;\">              0.224535</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">1.46491e-05</td><td style=\"text-align: right;\">0.00025611 </td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         565.887</td><td style=\"text-align: right;\">0.909673</td><td style=\"text-align: right;\">  0.499646</td></tr>\n",
       "<tr><td>objective_function_d7e7d0fd</td><td>TERMINATED</td><td>127.0.0.1:34536</td><td style=\"text-align: right;\">          64</td><td>False          </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.386381</td><td style=\"text-align: right;\">              0.431251</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">9.13704e-05</td><td style=\"text-align: right;\">0.00108342 </td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         392.966</td><td style=\"text-align: right;\">0.913935</td><td style=\"text-align: right;\">  0.467404</td></tr>\n",
       "<tr><td>objective_function_d658c481</td><td>TERMINATED</td><td>127.0.0.1:35340</td><td style=\"text-align: right;\">         128</td><td>False          </td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.367902</td><td style=\"text-align: right;\">              0.435727</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">5.94878e-07</td><td style=\"text-align: right;\">0.00430694 </td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         204.394</td><td style=\"text-align: right;\">0.881991</td><td style=\"text-align: right;\">  0.34863 </td></tr>\n",
       "<tr><td>objective_function_534a8f83</td><td>TERMINATED</td><td>127.0.0.1:26188</td><td style=\"text-align: right;\">         128</td><td>False          </td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">                 64</td><td style=\"text-align: right;\">      0.349209</td><td style=\"text-align: right;\">              0.300632</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">6.68801e-07</td><td style=\"text-align: right;\">0.00432013 </td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         180.622</td><td style=\"text-align: right;\">0.895551</td><td style=\"text-align: right;\">  0.32232 </td></tr>\n",
       "<tr><td>objective_function_bc7254c7</td><td>TERMINATED</td><td>127.0.0.1:7404 </td><td style=\"text-align: right;\">         128</td><td>False          </td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">                 64</td><td style=\"text-align: right;\">      0.348285</td><td style=\"text-align: right;\">              0.308566</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">6.5141e-07 </td><td style=\"text-align: right;\">0.00457901 </td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         164.102</td><td style=\"text-align: right;\">0.910597</td><td style=\"text-align: right;\">  0.259335</td></tr>\n",
       "<tr><td>objective_function_812694b8</td><td>TERMINATED</td><td>127.0.0.1:25684</td><td style=\"text-align: right;\">         128</td><td>False          </td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">                 64</td><td style=\"text-align: right;\">      0.348124</td><td style=\"text-align: right;\">              0.30336 </td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">5.88104e-07</td><td style=\"text-align: right;\">0.00479398 </td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         324.61 </td><td style=\"text-align: right;\">0.912333</td><td style=\"text-align: right;\">  0.274035</td></tr>\n",
       "<tr><td>objective_function_8fedff72</td><td>TERMINATED</td><td>127.0.0.1:16128</td><td style=\"text-align: right;\">          64</td><td>False          </td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">                 64</td><td style=\"text-align: right;\">      0.206622</td><td style=\"text-align: right;\">              0.322059</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">4.58759e-05</td><td style=\"text-align: right;\">0.000509744</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">        1520.46 </td><td style=\"text-align: right;\">0.929386</td><td style=\"text-align: right;\">  0.510213</td></tr>\n",
       "<tr><td>objective_function_bb523b6f</td><td>TERMINATED</td><td>127.0.0.1:20236</td><td style=\"text-align: right;\">          64</td><td>False          </td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.208979</td><td style=\"text-align: right;\">              0.401299</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">6.09553e-05</td><td style=\"text-align: right;\">0.000511575</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">        1470.96 </td><td style=\"text-align: right;\">0.922648</td><td style=\"text-align: right;\">  0.590719</td></tr>\n",
       "<tr><td>objective_function_d7b0be2b</td><td>TERMINATED</td><td>127.0.0.1:25368</td><td style=\"text-align: right;\">         128</td><td>True           </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.49977 </td><td style=\"text-align: right;\">              0.411402</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">6.84026e-05</td><td style=\"text-align: right;\">0.00078633 </td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">        1147.24 </td><td style=\"text-align: right;\">0.929913</td><td style=\"text-align: right;\">  0.45488 </td></tr>\n",
       "<tr><td>objective_function_90795b21</td><td>TERMINATED</td><td>127.0.0.1:36088</td><td style=\"text-align: right;\">         128</td><td>True           </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.204752</td><td style=\"text-align: right;\">              0.406666</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">5.46867e-05</td><td style=\"text-align: right;\">0.000707972</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">        1163.9  </td><td style=\"text-align: right;\">0.926491</td><td style=\"text-align: right;\">  0.420492</td></tr>\n",
       "<tr><td>objective_function_bc4b7f23</td><td>TERMINATED</td><td>127.0.0.1:33436</td><td style=\"text-align: right;\">         128</td><td>True           </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.18727 </td><td style=\"text-align: right;\">              0.403716</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">5.30708e-05</td><td style=\"text-align: right;\">0.00076794 </td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         288.632</td><td style=\"text-align: right;\">0.913631</td><td style=\"text-align: right;\">  0.328973</td></tr>\n",
       "<tr><td>objective_function_358f799b</td><td>TERMINATED</td><td>127.0.0.1:34720</td><td style=\"text-align: right;\">         128</td><td>True           </td><td style=\"text-align: right;\">                 7</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.189746</td><td style=\"text-align: right;\">              0.498416</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">1.30857e-06</td><td style=\"text-align: right;\">0.00150559 </td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         584.227</td><td style=\"text-align: right;\">0.919364</td><td style=\"text-align: right;\">  0.364573</td></tr>\n",
       "<tr><td>objective_function_9cee3d72</td><td>TERMINATED</td><td>127.0.0.1:21220</td><td style=\"text-align: right;\">         128</td><td>True           </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.472552</td><td style=\"text-align: right;\">              0.397538</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">1.44089e-06</td><td style=\"text-align: right;\">0.00145535 </td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         595.007</td><td style=\"text-align: right;\">0.913611</td><td style=\"text-align: right;\">  0.467898</td></tr>\n",
       "<tr><td>objective_function_42d49b9e</td><td>TERMINATED</td><td>127.0.0.1:12188</td><td style=\"text-align: right;\">         128</td><td>True           </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.489608</td><td style=\"text-align: right;\">              0.489988</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">1.35043e-06</td><td style=\"text-align: right;\">0.00145949 </td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">        1009.13 </td><td style=\"text-align: right;\">0.92632 </td><td style=\"text-align: right;\">  0.386379</td></tr>\n",
       "<tr><td>objective_function_f710ec25</td><td>TERMINATED</td><td>127.0.0.1:23404</td><td style=\"text-align: right;\">         128</td><td>True           </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.498433</td><td style=\"text-align: right;\">              0.478297</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">1.31542e-06</td><td style=\"text-align: right;\">0.00150919 </td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         316.003</td><td style=\"text-align: right;\">0.909535</td><td style=\"text-align: right;\">  0.369002</td></tr>\n",
       "<tr><td>objective_function_89e4a3f0</td><td>TERMINATED</td><td>127.0.0.1:20156</td><td style=\"text-align: right;\">         128</td><td>True           </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.485182</td><td style=\"text-align: right;\">              0.482275</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">4.99974e-06</td><td style=\"text-align: right;\">0.00156049 </td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         830.218</td><td style=\"text-align: right;\">0.920146</td><td style=\"text-align: right;\">  0.50511 </td></tr>\n",
       "<tr><td>objective_function_124d5dec</td><td>TERMINATED</td><td>127.0.0.1:24552</td><td style=\"text-align: right;\">         128</td><td>True           </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.442004</td><td style=\"text-align: right;\">              0.443634</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">5.13969e-06</td><td style=\"text-align: right;\">0.00179358 </td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         251.476</td><td style=\"text-align: right;\">0.911613</td><td style=\"text-align: right;\">  0.259597</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-13 13:55:08,424\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to 'C:/Users/Karim Negm/ray_results/pirate_pain_conv1d_search_v7' in 0.0480s.\n",
      "2025-11-13 13:55:08,438\tINFO tune.py:1041 -- Total run time: 5526.11 seconds (5525.99 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Search Complete ---\n",
      "\n",
      "Getting best trial from analysis...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Trial' object has no attribute 'best_result'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m best_trial:\n\u001b[0;32m     29\u001b[0m     FINAL_CONFIG \u001b[38;5;241m=\u001b[39m best_trial\u001b[38;5;241m.\u001b[39mconfig\n\u001b[1;32m---> 30\u001b[0m     FINAL_BEST_VAL_F1 \u001b[38;5;241m=\u001b[39m \u001b[43mbest_trial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_result\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_f1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest validation F1 score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFINAL_BEST_VAL_F1\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest hyperparameters found:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Trial' object has no attribute 'best_result'"
     ]
    }
   ],
   "source": [
    "search_space = {\n",
    "    \"window_size\": tune.choice([10]), \"stride\": tune.choice([2]),\n",
    "    \"lr\": tune.loguniform(1e-4, 5e-3), \"batch_size\": tune.choice([64, 128]),\n",
    "    \"hidden_size\": tune.choice([256, 384]), \"num_layers\": tune.choice([2, 3]),\n",
    "    \"dropout_rate\": tune.uniform(0.1, 0.5), \"feature_dropout_rate\": tune.uniform(0.2, 0.5),\n",
    "    \"bidirectional\": tune.choice([True, False]), \"l2_lambda\": tune.loguniform(1e-7, 1e-4),\n",
    "    \"conv_out_channels\": tune.choice([64, 128]), \"conv_kernel_size\": tune.choice([3, 5, 7]),\n",
    "}\n",
    "\n",
    "def short_trial_name(trial): return f\"{trial.trainable_name}_{trial.trial_id}\"\n",
    "\n",
    "if ray.is_initialized(): ray.shutdown()\n",
    "ray.init(num_cpus=16, num_gpus=1, ignore_reinit_error=True, log_to_driver=False)\n",
    "\n",
    "print(\"Starting hyperparameter search...\")\n",
    "analysis = tune.run(\n",
    "    tune.with_parameters(objective_function, X_train=X_train_split, y_train=y_train_split, X_val=X_val_split, y_val=y_val_split, class_weights=class_weights_tensor),\n",
    "    resources_per_trial={\"cpu\": 4, \"gpu\": 0.25}, config=search_space, num_samples=30,\n",
    "    search_alg=OptunaSearch(metric=\"val_f1\", mode=\"max\"),\n",
    "    scheduler=ASHAScheduler(metric=\"val_f1\", mode=\"max\", grace_period=25, reduction_factor=2),\n",
    "    name=\"pirate_pain_conv1d_search_v7\", verbose=1,\n",
    "    trial_dirname_creator=short_trial_name\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bbf60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Search Complete ---\n",
      "\n",
      "Getting best trial from analysis...\n",
      "Best validation F1 score: 0.9395\n",
      "Best hyperparameters found:\n",
      "{'window_size': 10, 'stride': 2, 'lr': 0.0021821719477903866, 'batch_size': 128, 'hidden_size': 256, 'num_layers': 2, 'dropout_rate': 0.4263716438404701, 'feature_dropout_rate': 0.44438270547130976, 'bidirectional': True, 'l2_lambda': 1.6092289023228805e-07, 'conv_out_channels': 128, 'conv_kernel_size': 5}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Search Complete ---\\n\")\n",
    "print(\"Getting best trial from analysis...\")\n",
    "best_trial = analysis.get_best_trial(metric=\"val_f1\", mode=\"max\", scope=\"all\")\n",
    "if best_trial:\n",
    "    FINAL_CONFIG = best_trial.config\n",
    "    FINAL_BEST_VAL_F1 = best_trial.last_result[\"val_f1\"]\n",
    "    print(f\"Best validation F1 score: {FINAL_BEST_VAL_F1:.4f}\")\n",
    "    print(\"Best hyperparameters found:\")\n",
    "    print(FINAL_CONFIG)\n",
    "else:\n",
    "    print(\"ERROR: No trials completed successfully. Using a default config.\")\n",
    "    FINAL_CONFIG = {'window_size': 20, 'stride': 1, 'lr': 0.00045, 'batch_size': 64, 'hidden_size': 384, 'num_layers': 2, 'dropout_rate': 0.2, 'feature_dropout_rate': 0.45, 'bidirectional': True, 'l2_lambda': 1e-06, 'conv_out_channels': 64, 'conv_kernel_size': 7}\n",
    "\n",
    "del X_train_split, y_train_split, X_val_split, y_val_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "694e2e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have to redefine because I don't want to rerun the whole HPO cell again\n",
    "FINAL_CONFIG = {'window_size': 10, 'stride': 2, 'lr': 0.0021821719477903866, 'batch_size': 128, 'hidden_size': 256, 'num_layers': 2, 'dropout_rate': 0.4263716438404701, 'feature_dropout_rate': 0.44438270547130976, 'bidirectional': True, 'l2_lambda': 1.6092289023228805e-07, 'conv_out_channels': 128, 'conv_kernel_size': 5}\n",
    "FINAL_BEST_VAL_F1 = 0.9395"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5aaf6bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Creating Final Train/Test Split (90/10) ---\n",
      "  X_train_final shape: (594, 160, 37)\n",
      "  y_train_final shape: (594,)\n",
      "  X_test_final shape:  (67, 160, 37)\n",
      "  y_test_final shape:  (67,)\n"
     ]
    }
   ],
   "source": [
    "# --- Create a final training and test set ---\n",
    "print(\"\\n--- Creating Final Train/Test Split (90/10) ---\")\n",
    "sss_final = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=SEED)\n",
    "\n",
    "# The split is on the full reordered dataset before k-fold starts\n",
    "for train_idx, test_idx in sss_final.split(X_train_full_reordered, y_train_full):\n",
    "    X_train_final, y_train_final = X_train_full_reordered[train_idx], y_train_full[train_idx]\n",
    "    X_test_final, y_test_final = X_train_full_reordered[test_idx], y_train_full[test_idx]\n",
    "\n",
    "print(f\"  X_train_final shape: {X_train_final.shape}\")\n",
    "print(f\"  y_train_final shape: {y_train_final.shape}\")\n",
    "print(f\"  X_test_final shape:  {X_test_final.shape}\")\n",
    "print(f\"  y_test_final shape:  {y_test_final.shape}\")\n",
    "\n",
    "# K-Fold will now run on the X_train_final and y_train_final sets.\n",
    "# The final ensemble will be tested on X_test_final and y_test_final."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102c0bb8",
   "metadata": {},
   "source": [
    "## üèÜ 6. Phase 2: K-Fold Ensemble Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "13308e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- üèÜ Final Configuration Set --- \n",
      "Best Val F1 from HPO search: 0.9395\n",
      "{'window_size': 10, 'stride': 2, 'lr': 0.0021821719477903866, 'batch_size': 128, 'hidden_size': 256, 'num_layers': 2, 'dropout_rate': 0.4263716438404701, 'feature_dropout_rate': 0.44438270547130976, 'bidirectional': True, 'l2_lambda': 1.6092289023228805e-07, 'conv_out_channels': 128, 'conv_kernel_size': 5}\n",
      "Submission name will be: submission_Conv1d-GRU_H256_L2_C128_K5_v7.1.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"--- üèÜ Final Configuration Set --- \")\n",
    "print(f\"Best Val F1 from HPO search: {FINAL_BEST_VAL_F1:.4f}\")\n",
    "print(FINAL_CONFIG)\n",
    "\n",
    "N_SPLITS = 5\n",
    "FINAL_EXPERIMENT_NAME = f\"Conv1d-GRU_H{FINAL_CONFIG['hidden_size']}_L{FINAL_CONFIG['num_layers']}_\" \\\n",
    "                      f\"C{FINAL_CONFIG['conv_out_channels']}_K{FINAL_CONFIG['conv_kernel_size']}_v7.1\"\n",
    "submission_filename_base = f\"submission_{FINAL_EXPERIMENT_NAME}.csv\"\n",
    "print(f\"Submission name will be: {submission_filename_base}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1bda55dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fold 1/5 --- (Conv1d-GRU_H256_L2_C128_K5_v7.1_fold_1) ---\n",
      "--- Starting Training: Conv1d-GRU_H256_L2_C128_K5_v7.1_fold_1 ---\n",
      "Epoch  25/350 | Val F1: 0.9276 | LR: 0.002155\n",
      "Epoch  50/350 | Val F1: 0.9283 | LR: 0.002074\n",
      "Epoch  75/350 | Val F1: 0.9307 | LR: 0.001944\n",
      "Early stopping at epoch 93. Best F1: 0.9402\n",
      "--- Finished Training --- Best F1: 0.9402\n",
      "Fold 1 Final Val F1: 0.9402\n",
      "\n",
      "--- Fold 2/5 --- (Conv1d-GRU_H256_L2_C128_K5_v7.1_fold_2) ---\n",
      "--- Starting Training: Conv1d-GRU_H256_L2_C128_K5_v7.1_fold_2 ---\n",
      "Epoch  25/350 | Val F1: 0.9184 | LR: 0.002155\n",
      "Epoch  50/350 | Val F1: 0.9099 | LR: 0.002074\n",
      "Early stopping at epoch 60. Best F1: 0.9239\n",
      "--- Finished Training --- Best F1: 0.9239\n",
      "Fold 2 Final Val F1: 0.9239\n",
      "\n",
      "--- Fold 3/5 --- (Conv1d-GRU_H256_L2_C128_K5_v7.1_fold_3) ---\n",
      "--- Starting Training: Conv1d-GRU_H256_L2_C128_K5_v7.1_fold_3 ---\n",
      "Epoch  25/350 | Val F1: 0.9290 | LR: 0.002155\n",
      "Epoch  50/350 | Val F1: 0.9255 | LR: 0.002074\n",
      "Early stopping at epoch 66. Best F1: 0.9378\n",
      "--- Finished Training --- Best F1: 0.9378\n",
      "Fold 3 Final Val F1: 0.9378\n",
      "\n",
      "--- Fold 4/5 --- (Conv1d-GRU_H256_L2_C128_K5_v7.1_fold_4) ---\n",
      "--- Starting Training: Conv1d-GRU_H256_L2_C128_K5_v7.1_fold_4 ---\n",
      "Epoch  25/350 | Val F1: 0.9273 | LR: 0.002155\n",
      "Epoch  50/350 | Val F1: 0.9242 | LR: 0.002074\n",
      "Epoch  75/350 | Val F1: 0.9250 | LR: 0.001944\n",
      "Epoch 100/350 | Val F1: 0.9247 | LR: 0.001771\n",
      "Epoch 125/350 | Val F1: 0.9328 | LR: 0.001564\n",
      "Early stopping at epoch 127. Best F1: 0.9377\n",
      "--- Finished Training --- Best F1: 0.9377\n",
      "Fold 4 Final Val F1: 0.9377\n",
      "\n",
      "--- Fold 5/5 --- (Conv1d-GRU_H256_L2_C128_K5_v7.1_fold_5) ---\n",
      "--- Starting Training: Conv1d-GRU_H256_L2_C128_K5_v7.1_fold_5 ---\n",
      "Epoch  25/350 | Val F1: 0.9332 | LR: 0.002155\n",
      "Epoch  50/350 | Val F1: 0.9308 | LR: 0.002074\n",
      "Epoch  75/350 | Val F1: 0.9354 | LR: 0.001944\n",
      "Early stopping at epoch 96. Best F1: 0.9458\n",
      "--- Finished Training --- Best F1: 0.9458\n",
      "Fold 5 Final Val F1: 0.9458\n",
      "\n",
      "--- üèÜ K-Fold Training Complete --- Average F1: 0.9371\n"
     ]
    }
   ],
   "source": [
    "# MODIFICATION: Changed skf.split to use the new train/test split\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "fold_val_f1_list = []\n",
    "continuous_indices_reordered = list(range(32))\n",
    "EPOCHS = 350\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train_final, y_train_final)):\n",
    "    fold_name = f\"{FINAL_EXPERIMENT_NAME}_fold_{fold+1}\"\n",
    "    print(f\"\\n--- Fold {fold+1}/{N_SPLITS} --- ({fold_name}) ---\")\n",
    "    \n",
    "    # MODIFICATION: Indexing into the new X_train_final and y_train_final sets\n",
    "    X_train_fold, y_train_fold = X_train_final[train_idx], y_train_final[train_idx]\n",
    "    X_val_fold, y_val_fold = X_train_final[val_idx], y_train_final[val_idx]\n",
    "\n",
    "    preprocessor_fold = ColumnTransformer([('s', StandardScaler(), continuous_indices_reordered)], remainder='passthrough')\n",
    "    ns, ts, f = X_train_fold.shape\n",
    "    X_train_scaled = preprocessor_fold.fit_transform(X_train_fold.reshape(ns*ts, f)).reshape(ns, ts, f)\n",
    "    ns_val, ts_val, f_val = X_val_fold.shape\n",
    "    X_val_scaled = preprocessor_fold.transform(X_val_fold.reshape(ns_val*ts_val, f_val)).reshape(ns_val, ts_val, f_val)\n",
    "    \n",
    "    X_train_w, y_train_w, _ = create_sliding_windows(X_train_scaled, y_train_fold, FINAL_CONFIG['window_size'], FINAL_CONFIG['stride'])\n",
    "    X_val_w, y_val_w, _ = create_sliding_windows(X_val_scaled, y_val_fold, FINAL_CONFIG['window_size'], FINAL_CONFIG['stride'])\n",
    "    train_loader = make_loader(TensorDataset(torch.from_numpy(X_train_w).float(), torch.from_numpy(y_train_w).long()), FINAL_CONFIG['batch_size'], True, True)\n",
    "    val_loader = make_loader(TensorDataset(torch.from_numpy(X_val_w).float(), torch.from_numpy(y_val_w).long()), FINAL_CONFIG['batch_size'], False, False)\n",
    "\n",
    "    model_config_kfold = {k: v for k, v in FINAL_CONFIG.items() if k not in ['window_size', 'stride', 'lr', 'batch_size', 'l2_lambda']}\n",
    "    model_fold = RecurrentClassifier(**model_config_kfold, num_classes=N_CLASSES).to(device)\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model_fold.parameters(), lr=FINAL_CONFIG['lr'], weight_decay=FINAL_CONFIG['l2_lambda'])\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "    scaler = torch.amp.GradScaler(enabled=(device.type == 'cuda'))\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "\n",
    "    model_fold = fit(model_fold, train_loader, val_loader, EPOCHS, criterion, optimizer, scheduler, scaler, device, 50, fold_name)\n",
    "    _, val_f1 = validate_one_epoch(model_fold, val_loader, criterion, device)\n",
    "    fold_val_f1_list.append(val_f1)\n",
    "    print(f\"Fold {fold+1} Final Val F1: {val_f1:.4f}\")\n",
    "\n",
    "print(f\"\\n--- üèÜ K-Fold Training Complete --- Average F1: {np.mean(fold_val_f1_list):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f9d380",
   "metadata": {},
   "source": [
    "## üì¨ 7. Phase 3: Ensemble Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b31871e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Preparing test dataset for submission ---\n",
      "Loading model 1/5 from models/Conv1d-GRU_H256_L2_C128_K5_v7.1_fold_1_best_model.pt...\n",
      "Loading model 2/5 from models/Conv1d-GRU_H256_L2_C128_K5_v7.1_fold_2_best_model.pt...\n",
      "Loading model 3/5 from models/Conv1d-GRU_H256_L2_C128_K5_v7.1_fold_3_best_model.pt...\n",
      "Loading model 4/5 from models/Conv1d-GRU_H256_L2_C128_K5_v7.1_fold_4_best_model.pt...\n",
      "Loading model 5/5 from models/Conv1d-GRU_H256_L2_C128_K5_v7.1_fold_5_best_model.pt...\n",
      "\n",
      "Successfully saved to submissions\\submission_Conv1d-GRU_H256_L2_C128_K5_v7.1.csv!\n",
      "  sample_index    label\n",
      "0          000  no_pain\n",
      "1          001  no_pain\n",
      "2          002  no_pain\n",
      "3          003  no_pain\n",
      "4          004  no_pain\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Preparing test dataset for submission ---\")\n",
    "continuous_indices_orig = list(range(31)) + [35]\n",
    "categorical_indices_orig = list(range(31, 35)) + [36]\n",
    "X_test_full_reordered = np.concatenate([\n",
    "    X_test_full_engineered[:, :, continuous_indices_orig],\n",
    "    X_test_full_engineered[:, :, categorical_indices_orig]], axis=2)\n",
    "\n",
    "continuous_indices_reordered = list(range(32))\n",
    "preprocessor_final = ColumnTransformer([('scaler', StandardScaler(), continuous_indices_reordered)], remainder='passthrough')\n",
    "preprocessor_final.fit(X_train_full_reordered.reshape(-1, N_FEATURES_NEW))\n",
    "\n",
    "ns_test, ts_test, f_test = X_test_full_reordered.shape\n",
    "X_test_scaled = preprocessor_final.transform(X_test_full_reordered.reshape(ns_test * ts_test, f_test)).reshape(ns_test, ts_test, f_test)\n",
    "X_test_w, test_window_indices = create_sliding_windows(X_test_scaled, y=None, window_size=FINAL_CONFIG['window_size'], stride=FINAL_CONFIG['stride'])\n",
    "test_loader = make_loader(TensorDataset(torch.from_numpy(X_test_w).float()), FINAL_CONFIG['batch_size'], False, False)\n",
    "\n",
    "model_config_final = {k: v for k, v in FINAL_CONFIG.items() if k not in ['window_size', 'stride', 'lr', 'batch_size', 'l2_lambda']}\n",
    "all_fold_probabilities = []\n",
    "for fold in range(N_SPLITS):\n",
    "    fold_name = f\"{FINAL_EXPERIMENT_NAME}_fold_{fold+1}\"\n",
    "    model_path = f\"models/{fold_name}_best_model.pt\"\n",
    "    print(f\"Loading model {fold+1}/{N_SPLITS} from {model_path}...\")\n",
    "    model_fold = RecurrentClassifier(**model_config_final, num_classes=N_CLASSES).to(device)\n",
    "    model_fold.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model_fold.eval()\n",
    "    \n",
    "    fold_preds = []\n",
    "    with torch.no_grad():\n",
    "        for (inputs,) in test_loader:\n",
    "            with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n",
    "                probs = torch.softmax(model_fold(inputs.to(device)), dim=1)\n",
    "                fold_preds.append(probs.cpu().numpy())\n",
    "    all_fold_probabilities.append(np.concatenate(fold_preds))\n",
    "\n",
    "mean_probabilities = np.mean(all_fold_probabilities, axis=0)\n",
    "df_probs = pd.DataFrame(mean_probabilities, columns=[f\"prob_{i}\" for i in range(N_CLASSES)])\n",
    "df_probs['original_index'] = test_window_indices\n",
    "agg_probs = df_probs.groupby('original_index')[[f\"prob_{i}\" for i in range(N_CLASSES)]].mean().values\n",
    "final_predictions = le.inverse_transform(np.argmax(agg_probs, axis=1))\n",
    "\n",
    "submission_df = pd.DataFrame({'sample_index': sorted(X_test_long_df['sample_index'].unique()), 'label': final_predictions})\n",
    "submission_df['sample_index'] = submission_df['sample_index'].apply(lambda x: f\"{x:03d}\")\n",
    "submission_filepath = os.path.join(\"submissions\", submission_filename_base)\n",
    "submission_df.to_csv(submission_filepath, index=False)\n",
    "print(f\"\\nSuccessfully saved to {submission_filepath}!\")\n",
    "print(submission_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f265db3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating the ensemble on the held-out test set ---\n",
      "Loading model 1/5 from models/Conv1d-GRU_H256_L2_C128_K5_v7.1_fold_1_best_model.pt for test evaluation...\n",
      "Loading model 2/5 from models/Conv1d-GRU_H256_L2_C128_K5_v7.1_fold_2_best_model.pt for test evaluation...\n",
      "Loading model 3/5 from models/Conv1d-GRU_H256_L2_C128_K5_v7.1_fold_3_best_model.pt for test evaluation...\n",
      "Loading model 4/5 from models/Conv1d-GRU_H256_L2_C128_K5_v7.1_fold_4_best_model.pt for test evaluation...\n",
      "Loading model 5/5 from models/Conv1d-GRU_H256_L2_C128_K5_v7.1_fold_5_best_model.pt for test evaluation...\n",
      "\n",
      "--- Final Test Set Performance Metrics ---\n",
      "--- Overall Performance ---\n",
      "  - Accuracy:                   0.9254\n",
      "  - Weighted F1-Score:          0.9177\n",
      "  - Matthews Correlation Coef:  0.7884\n",
      "  - Cohen's Kappa:              0.7747\n",
      "\n",
      "--- Detailed Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   high_pain       1.00      0.50      0.67         6\n",
      "    low_pain       0.88      0.78      0.82         9\n",
      "     no_pain       0.93      1.00      0.96        52\n",
      "\n",
      "    accuracy                           0.93        67\n",
      "   macro avg       0.93      0.76      0.82        67\n",
      "weighted avg       0.93      0.93      0.92        67\n",
      "\n",
      "\n",
      "--- Confusion Matrix ---\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report, cohen_kappa_score, matthews_corrcoef\n",
    "print(\"\\n--- Evaluating the ensemble on the held-out test set ---\")\n",
    "\n",
    "# The preprocessor_final was fitted on the full training data before the split.\n",
    "# We now use it to transform our held-out test set.\n",
    "ns_test, ts_test, f_test = X_test_final.shape\n",
    "X_test_final_scaled = preprocessor_final.transform(X_test_final.reshape(ns_test * ts_test, f_test)).reshape(ns_test, ts_test, f_test)\n",
    "\n",
    "# Create sliding windows for the test set\n",
    "X_test_w_final, test_window_indices_final = create_sliding_windows(\n",
    "    X_test_final_scaled, y=None, window_size=FINAL_CONFIG['window_size'], stride=FINAL_CONFIG['stride']\n",
    ")\n",
    "test_loader_final = make_loader(TensorDataset(torch.from_numpy(X_test_w_final).float()), FINAL_CONFIG['batch_size'], False, False)\n",
    "\n",
    "# --- Make predictions with the ensemble ---\n",
    "model_config_eval = {k: v for k, v in FINAL_CONFIG.items() if k not in ['window_size', 'stride', 'lr', 'batch_size', 'l2_lambda']}\n",
    "all_fold_probabilities_test = []\n",
    "\n",
    "for fold in range(N_SPLITS):\n",
    "    fold_name = f\"{FINAL_EXPERIMENT_NAME}_fold_{fold+1}\"\n",
    "    model_path = f\"models/{fold_name}_best_model.pt\"\n",
    "    print(f\"Loading model {fold+1}/{N_SPLITS} from {model_path} for test evaluation...\")\n",
    "    \n",
    "    model_fold = RecurrentClassifier(**model_config_eval, num_classes=N_CLASSES).to(device)\n",
    "    model_fold.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model_fold.eval()\n",
    "    \n",
    "    fold_preds = []\n",
    "    with torch.no_grad():\n",
    "        for (inputs,) in test_loader_final:\n",
    "            with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n",
    "                probs = torch.softmax(model_fold(inputs.to(device)), dim=1)\n",
    "                fold_preds.append(probs.cpu().numpy())\n",
    "    all_fold_probabilities_test.append(np.concatenate(fold_preds))\n",
    "\n",
    "# --- Aggregate predictions and calculate metrics ---\n",
    "mean_probabilities_test = np.mean(all_fold_probabilities_test, axis=0)\n",
    "\n",
    "# Aggregate window predictions back to original sample predictions\n",
    "df_probs_test = pd.DataFrame(mean_probabilities_test, columns=[f\"prob_{i}\" for i in range(N_CLASSES)])\n",
    "df_probs_test['original_index'] = test_window_indices_final\n",
    "agg_probs_test = df_probs_test.groupby('original_index')[[f\"prob_{i}\" for i in range(N_CLASSES)]].mean().values\n",
    "final_test_predictions = np.argmax(agg_probs_test, axis=1)\n",
    "class_names = le.inverse_transform(range(N_CLASSES))\n",
    "\n",
    "# --- Calculate and Display Performance Metrics ---\n",
    "print(\"\\n--- Final Test Set Performance Metrics ---\")\n",
    "\n",
    "# Overall scores\n",
    "test_accuracy = accuracy_score(y_test_final, final_test_predictions)\n",
    "test_f1_weighted = f1_score(y_test_final, final_test_predictions, average='weighted')\n",
    "test_mcc = matthews_corrcoef(y_test_final, final_test_predictions)\n",
    "test_kappa = cohen_kappa_score(y_test_final, final_test_predictions)\n",
    "\n",
    "print(\"--- Overall Performance ---\")\n",
    "print(f\"  - Accuracy:                   {test_accuracy:.4f}\")\n",
    "print(f\"  - Weighted F1-Score:          {test_f1_weighted:.4f}\")\n",
    "print(f\"  - Matthews Correlation Coef:  {test_mcc:.4f}\")\n",
    "print(f\"  - Cohen's Kappa:              {test_kappa:.4f}\")\n",
    "\n",
    "\n",
    "# Class-by-class report\n",
    "print(\"\\n--- Detailed Classification Report ---\")\n",
    "class_report = classification_report(y_test_final, final_test_predictions, target_names=class_names)\n",
    "print(class_report)\n",
    "\n",
    "\n",
    "# --- Display Confusion Matrix ---\n",
    "print(\"\\n--- Confusion Matrix ---\")\n",
    "cm = confusion_matrix(y_test_final, final_test_predictions)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix on Test Set')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "an2dl-kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
