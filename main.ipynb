{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4cc19cf",
   "metadata": {},
   "source": [
    "# **Kaggle Challenge: Pirate Pain Dataset üè¥‚Äç‚ò†Ô∏è (v8: Test Set, OneCycleLR & Optimizations)**\n",
    "\n",
    "This notebook refines the Conv1d-GRU architecture by incorporating findings from our deep data analysis, implementing a more robust evaluation strategy, and upgrading the training process.\n",
    "\n",
    "**Strategy Update:**\n",
    "1.  **Hold-Out Test Set:** A true 10% test set is now created at the beginning to provide a final, unbiased evaluation of the model's generalization performance.\n",
    "2.  **Data Cleaning:** The zero-variance `joint_30` feature is removed based on the analysis.\n",
    "3.  **One-Cycle LR Scheduler:** The Cosine Annealing scheduler has been replaced with `OneCycleLR`. This policy can lead to faster convergence. The training loop has been modified to step the scheduler after each batch.\n",
    "4.  **Optimized HPO:** The hyperparameter search no longer tunes the window size and stride. The data is now pre-processed and pre-windowed before the search for a significant speedup.\n",
    "5.  **Final Evaluation:** A new section has been added to evaluate the K-Fold ensemble on the hold-out test set, generating a classification report and confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f440cd73",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è 1. Setup & Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79808edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Using GPU ---\n",
      "PyTorch version: 2.5.1\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set seed for reproducibility\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "SEED = 123\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import copy\n",
    "import gc\n",
    "\n",
    "# Set environment variables before importing modules\n",
    "os.environ['MPLCONFIGDIR'] = os.getcwd() + '/configs/'\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "# --- PyTorch Imports ---\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# --- Sklearn Imports ---\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "# --- Ray[tune] & Optuna Imports ---\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.search.optuna import OptunaSearch\n",
    "\n",
    "# --- Setup Directories & Device ---\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "os.makedirs(\"submissions\", exist_ok=True)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    print(\"\\n--- Using GPU ---\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"\\n--- Using CPU ---\")\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Configure plot display settings\n",
    "sns.set_theme(font_scale=1.4)\n",
    "sns.set_style('white')\n",
    "plt.rc('font', size=14)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c81fffe",
   "metadata": {},
   "source": [
    "## üîÑ 2. Data Loading, Cleaning & Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72fa9991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Loading Data ---\n",
      "REMOVED 'joint_30' from feature list.\n",
      "\n",
      "--- 2. Engineering 'is_pirate' Feature ---\n",
      "Created engineered features. N_FEATURES is now: 36\n",
      "\n",
      "--- 3. Calculating Class Weights ---\n",
      "Calculated class weights: tensor([0.0643, 0.3493, 0.5864], device='cuda:0')\n",
      "\n",
      "--- 4. Creating Hold-Out Test Set ---\n",
      "Data split successfully.\n",
      "  Training set size:   594\n",
      "  Hold-out test set size: 67\n"
     ]
    }
   ],
   "source": [
    "print(\"--- 1. Loading Data ---\")\n",
    "\n",
    "# --- Define File Paths and Features ---\n",
    "DATA_DIR = \"data\"\n",
    "X_TRAIN_PATH = os.path.join(DATA_DIR, \"pirate_pain_train.csv\")\n",
    "Y_TRAIN_PATH = os.path.join(DATA_DIR, \"pirate_pain_train_labels.csv\")\n",
    "X_TEST_PATH = os.path.join(DATA_DIR, \"pirate_pain_test.csv\")\n",
    "\n",
    "try:\n",
    "    features_long_df = pd.read_csv(X_TRAIN_PATH)\n",
    "    labels_df = pd.read_csv(Y_TRAIN_PATH)\n",
    "    X_submission_long_df = pd.read_csv(X_TEST_PATH)\n",
    "    \n",
    "    N_TIMESTEPS = 160\n",
    "    JOINT_FEATURES = [f\"joint_{i:02d}\" for i in range(31)]\n",
    "    PAIN_FEATURES = [f\"pain_survey_{i}\" for i in range(1, 5)]\n",
    "    TIME_FEATURE = ['time']\n",
    "    FEATURES = JOINT_FEATURES + PAIN_FEATURES + TIME_FEATURE\n",
    "    \n",
    "    # === NEW CLEANING STEP: Remove Zero-Variance Column from Analysis ===\n",
    "    if 'joint_30' in FEATURES:\n",
    "        FEATURES.remove('joint_30')\n",
    "        print(\"REMOVED 'joint_30' from feature list.\")\n",
    "    # ====================================================================\n",
    "\n",
    "    LABEL_MAPPING = {'no_pain': 0, 'low_pain': 1, 'high_pain': 2}\n",
    "    N_CLASSES = len(LABEL_MAPPING)\n",
    "\n",
    "    def reshape_data(df, features_list, n_timesteps):\n",
    "        df_pivot = df.pivot(index='sample_index', columns='time', values=features_list)\n",
    "        data_2d = df_pivot.values\n",
    "        n_samples = data_2d.shape[0]\n",
    "        data_3d = data_2d.reshape(n_samples, len(features_list), n_timesteps)\n",
    "        return data_3d.transpose(0, 2, 1)\n",
    "\n",
    "    X_train_full_raw = reshape_data(features_long_df[features_long_df['sample_index'].isin(labels_df['sample_index'].unique())], FEATURES, N_TIMESTEPS)\n",
    "    X_submission_full_raw = reshape_data(X_submission_long_df, FEATURES, N_TIMESTEPS)\n",
    "    y_train_full_df = labels_df.sort_values(by='sample_index')\n",
    "    le = LabelEncoder().fit(list(LABEL_MAPPING.keys()))\n",
    "    y_train_full_raw = le.transform(y_train_full_df['label'])\n",
    "\n",
    "    print(\"\\n--- 2. Engineering 'is_pirate' Feature ---\")\n",
    "    static_cols = ['sample_index', 'n_legs', 'n_hands', 'n_eyes']\n",
    "    static_df = features_long_df[static_cols].drop_duplicates().set_index('sample_index')\n",
    "    pirate_filter = (static_df['n_legs'] == 'one+peg_leg') | (static_df['n_hands'] == 'one+hook_hand') | (static_df['n_eyes'] == 'one+eye_patch')\n",
    "    pirate_indices = static_df[pirate_filter].index\n",
    "    sample_indices_ordered = sorted(features_long_df[features_long_df['sample_index'].isin(labels_df['sample_index'].unique())]['sample_index'].unique())\n",
    "    is_pirate_map = np.array([1 if idx in pirate_indices else 0 for idx in sample_indices_ordered])\n",
    "    pirate_feature_broadcast = np.tile(is_pirate_map.reshape(-1, 1, 1), (1, N_TIMESTEPS, 1))\n",
    "    X_train_full_engineered = np.concatenate([X_train_full_raw, pirate_feature_broadcast], axis=2)\n",
    "\n",
    "    static_df_submission = X_submission_long_df[static_cols].drop_duplicates().set_index('sample_index')\n",
    "    pirate_filter_submission = (static_df_submission['n_legs'] == 'one+peg_leg') | (static_df_submission['n_hands'] == 'one+hook_hand') | (static_df_submission['n_eyes'] == 'one+eye_patch')\n",
    "    pirate_indices_submission = static_df_submission[pirate_filter_submission].index\n",
    "    sample_indices_submission_ordered = sorted(X_submission_long_df['sample_index'].unique())\n",
    "    is_pirate_map_submission = np.array([1 if idx in pirate_indices_submission else 0 for idx in sample_indices_submission_ordered])\n",
    "    pirate_feature_broadcast_submission = np.tile(is_pirate_map_submission.reshape(-1, 1, 1), (1, N_TIMESTEPS, 1))\n",
    "    X_submission_full_engineered = np.concatenate([X_submission_full_raw, pirate_feature_broadcast_submission], axis=2)\n",
    "    \n",
    "    N_FEATURES_NEW = X_train_full_engineered.shape[2]\n",
    "    print(f\"Created engineered features. N_FEATURES is now: {N_FEATURES_NEW}\")\n",
    "    \n",
    "    print(\"\\n--- 3. Calculating Class Weights ---\")\n",
    "    class_counts_series = labels_df['label'].value_counts()\n",
    "    counts_ordered = class_counts_series.reindex(LABEL_MAPPING.keys()).values\n",
    "    class_weights_tensor = 1.0 / torch.tensor(counts_ordered, dtype=torch.float)\n",
    "    class_weights_tensor = (class_weights_tensor / class_weights_tensor.sum()).to(device)\n",
    "    print(f\"Calculated class weights: {class_weights_tensor}\")\n",
    "\n",
    "    print(\"\\n--- 4. Creating Hold-Out Test Set ---\")\n",
    "    sss_test_split = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=SEED)\n",
    "    train_indices, test_indices = next(sss_test_split.split(X_train_full_engineered, y_train_full_raw))\n",
    "    \n",
    "    X_train = X_train_full_engineered[train_indices]\n",
    "    y_train = y_train_full_raw[train_indices]\n",
    "    X_test = X_train_full_engineered[test_indices]\n",
    "    y_test = y_train_full_raw[test_indices]\n",
    "    \n",
    "    print(f\"Data split successfully.\")\n",
    "    print(f\"  Training set size:   {len(X_train)}\")\n",
    "    print(f\"  Hold-out test set size: {len(X_test)}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0382c9f8",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è 3. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a49d16a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sliding_windows(X_3d, y=None, window_size=10, stride=2):\n",
    "    new_X, new_y, window_indices = [], [], []\n",
    "    n_samples, n_timesteps, _ = X_3d.shape\n",
    "    for i in range(n_samples):\n",
    "        idx = 0\n",
    "        while (idx + window_size) <= n_timesteps:\n",
    "            new_X.append(X_3d[i, idx:idx+window_size, :])\n",
    "            window_indices.append(i)\n",
    "            if y is not None: new_y.append(y[i])\n",
    "            idx += stride\n",
    "    if y is not None:\n",
    "        return np.array(new_X), np.array(new_y), np.array(window_indices)\n",
    "    return np.array(new_X), np.array(window_indices)\n",
    "\n",
    "def make_loader(ds, batch_size, shuffle, drop_last):\n",
    "    return DataLoader(ds, batch_size=int(batch_size), shuffle=shuffle, drop_last=drop_last, \n",
    "                      num_workers=2, pin_memory=True, persistent_workers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8927dcf1",
   "metadata": {},
   "source": [
    "## üß† 4. Model & Training Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9966076",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentClassifier(nn.Module):\n",
    "    def __init__(self, hidden_size, num_layers, num_classes,\n",
    "                 conv_out_channels, conv_kernel_size, bidirectional,\n",
    "                 dropout_rate, feature_dropout_rate, rnn_type='GRU'):\n",
    "        super().__init__()\n",
    "        self.rnn_type, self.num_layers, self.hidden_size, self.bidirectional = \\\n",
    "            rnn_type, num_layers, hidden_size, bidirectional\n",
    "\n",
    "        # --- Feature Engineering Layers ---\n",
    "        self.pain_embed_dim, self.pirate_embed_dim = 4, 4\n",
    "        self.pain_embeddings = nn.ModuleList([nn.Embedding(3, self.pain_embed_dim) for _ in range(4)])\n",
    "        self.pirate_embedding = nn.Embedding(2, self.pirate_embed_dim)\n",
    "        \n",
    "        # MODIFIED: 30 joints + 1 time = 31 continuous features\n",
    "        num_continuous_features = 31 \n",
    "        total_embedding_dim = (4 * self.pain_embed_dim) + self.pirate_embed_dim\n",
    "        conv_input_size = num_continuous_features + total_embedding_dim\n",
    "\n",
    "        # --- Conv1d Layer for Feature Extraction ---\n",
    "        self.conv1d = nn.Conv1d(in_channels=conv_input_size, out_channels=conv_out_channels,\n",
    "                                kernel_size=conv_kernel_size, padding='same')\n",
    "        self.conv_activation = nn.ReLU()\n",
    "        self.feature_dropout = nn.Dropout(feature_dropout_rate)\n",
    "\n",
    "        # --- RNN Layer for Sequence Modeling ---\n",
    "        self.rnn = nn.GRU(\n",
    "            input_size=conv_out_channels, hidden_size=hidden_size,\n",
    "            num_layers=num_layers, batch_first=True, bidirectional=bidirectional,\n",
    "            dropout=dropout_rate if num_layers > 1 else 0)\n",
    "        \n",
    "        # --- Classifier Head ---\n",
    "        self.classifier = nn.Linear(hidden_size * 2 if bidirectional else hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # MODIFIED: Slices updated for 31 continuous features\n",
    "        x_continuous = x[:, :, :31]\n",
    "        x_categorical = x[:, :, 31:].long()\n",
    "        \n",
    "        embedded_cats = [self.pain_embeddings[i](x_categorical[:, :, i]) for i in range(4)] \\\n",
    "                      + [self.pirate_embedding(x_categorical[:, :, 4])]\n",
    "        x_combined = torch.cat([x_continuous] + embedded_cats, dim=2)\n",
    "        x_permuted = x_combined.permute(0, 2, 1)\n",
    "        x_conv = self.conv_activation(self.conv1d(x_permuted))\n",
    "        x_conv_permuted = x_conv.permute(0, 2, 1)\n",
    "        x_dropped = self.feature_dropout(x_conv_permuted)\n",
    "        _, hidden = self.rnn(x_dropped)\n",
    "        if self.bidirectional:\n",
    "            hidden = hidden.view(self.num_layers, 2, -1, self.hidden_size)\n",
    "            hidden = torch.cat([hidden[-1, 0, :, :], hidden[-1, 1, :, :]], dim=1)\n",
    "        else:\n",
    "            hidden = hidden[-1]\n",
    "        return self.classifier(hidden)\n",
    "\n",
    "# MODIFIED: Scheduler is now passed in and stepped per-batch for OneCycleLR\n",
    "def train_one_epoch(model, loader, criterion, optimizer, scaler, scheduler, device):\n",
    "    model.train()\n",
    "    total_loss, all_preds, all_targets = 0, [], []\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step() # <-- OneCycleLR is stepped each batch\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "        all_preds.append(logits.argmax(dim=1).cpu().numpy())\n",
    "        all_targets.append(y.cpu().numpy())\n",
    "    return total_loss / len(loader.dataset.tensors[0]), f1_score(np.concatenate(all_targets), np.concatenate(all_preds), average='weighted')\n",
    "\n",
    "def validate_one_epoch(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss, all_preds, all_targets = 0, [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "            with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n",
    "                logits = model(x)\n",
    "                loss = criterion(logits, y)\n",
    "            total_loss += loss.item() * x.size(0)\n",
    "            all_preds.append(logits.argmax(dim=1).cpu().numpy())\n",
    "            all_targets.append(y.cpu().numpy())\n",
    "    return total_loss / len(loader.dataset.tensors[0]), f1_score(np.concatenate(all_targets), np.concatenate(all_preds), average='weighted')\n",
    "\n",
    "# MODIFIED: Objective function now receives pre-windowed tensors for speed\n",
    "def objective_function(config, X_train_w, y_train_w, X_val_w, y_val_w, class_weights):\n",
    "    EPOCHS = 100\n",
    "    train_loader = make_loader(TensorDataset(X_train_w, y_train_w), config[\"batch_size\"], True, True)\n",
    "    val_loader = make_loader(TensorDataset(X_val_w, y_val_w), config[\"batch_size\"], False, False)\n",
    "\n",
    "    model_config = {k: v for k, v in config.items() if k not in ['lr', 'batch_size', 'l2_lambda']}\n",
    "    model = RecurrentClassifier(**model_config, num_classes=N_CLASSES, rnn_type='GRU').to(device)\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config[\"lr\"], weight_decay=config[\"l2_lambda\"])\n",
    "    # MODIFIED: Use OneCycleLR\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer, max_lr=config[\"lr\"], epochs=EPOCHS, steps_per_epoch=len(train_loader)\n",
    "    )\n",
    "    scaler = torch.amp.GradScaler(enabled=(device.type == 'cuda'))\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "    best_val_f1 = -1.0; patience_counter = 0; hpo_patience = 100\n",
    "    \n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        # MODIFIED: Pass scheduler to training function\n",
    "        train_loss, _ = train_one_epoch(model, train_loader, criterion, optimizer, scaler, scheduler, device)\n",
    "        _, val_f1 = validate_one_epoch(model, val_loader, criterion, device)\n",
    "        tune.report({\"val_f1\": val_f1, \"train_loss\": train_loss})\n",
    "        \n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1; patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= hpo_patience: break\n",
    "\n",
    "def fit(model, train_loader, val_loader, epochs, criterion, optimizer, scheduler, scaler, device, patience, experiment_name):\n",
    "    model_path = f\"models/{experiment_name}_best_model.pt\"\n",
    "    best_f1 = -1; patience_counter = 0\n",
    "    print(f\"--- Starting Training: {experiment_name} ---\")\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # MODIFIED: Pass scheduler to training function\n",
    "        train_loss, train_f1 = train_one_epoch(model, train_loader, criterion, optimizer, scaler, scheduler, device)\n",
    "        val_loss, val_f1 = validate_one_epoch(model, val_loader, criterion, device)\n",
    "\n",
    "        if epoch % 5 == 0: print(f\"Epoch {epoch:3d}/{epochs} | Best F1: {best_f1:.4f} | Val F1: {val_f1:.4f} | LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "        if val_f1 > best_f1:\n",
    "            best_f1, patience_counter = val_f1, 0\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience: print(f\"Early stopping at epoch {epoch}. Best F1: {best_f1:.4f}\"); break\n",
    "    print(f\"--- Finished Training --- Best F1: {best_f1:.4f}\")\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2db88e",
   "metadata": {},
   "source": [
    "## üß™ 5. Phase 1: Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bd57bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Preparing data for HPO (pre-calculating windows for speed) ---\n",
      "--- Creating internal HPO split ---\n",
      "--- Pre-scaling HPO data ---\n",
      "--- Pre-creating sliding windows for HPO ---\n",
      "Created training windows of shape: torch.Size([36100, 10, 36])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"--- Preparing data for HPO (pre-calculating windows for speed) ---\")\n",
    "\n",
    "# Re-order columns: continuous first, then categorical\n",
    "# 30 joints + 1 time = 31 continuous\n",
    "# 4 pain surveys + 1 pirate = 5 categorical\n",
    "continuous_indices_orig = list(range(30)) + [34]\n",
    "categorical_indices_orig = list(range(30, 34)) + [35]\n",
    "X_train_reordered = np.concatenate([\n",
    "    X_train[:, :, continuous_indices_orig],\n",
    "    X_train[:, :, categorical_indices_orig]\n",
    "], axis=2)\n",
    "\n",
    "print(\"--- Creating internal HPO split ---\")\n",
    "sss_hpo_split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED)\n",
    "hpo_train_idx, hpo_val_idx = next(sss_hpo_split.split(X_train_reordered, y_train))\n",
    "X_train_hpo, y_train_hpo = X_train_reordered[hpo_train_idx], y_train[hpo_train_idx]\n",
    "X_val_hpo, y_val_hpo = X_train_reordered[hpo_val_idx], y_train[hpo_val_idx]\n",
    "\n",
    "print(\"--- Pre-scaling HPO data ---\")\n",
    "continuous_indices_reordered = list(range(31))\n",
    "preprocessor_hpo = ColumnTransformer([('scaler', StandardScaler(), continuous_indices_reordered)], remainder='passthrough')\n",
    "ns, ts, f = X_train_hpo.shape\n",
    "X_train_hpo_scaled = preprocessor_hpo.fit_transform(X_train_hpo.reshape(ns*ts, f)).reshape(ns, ts, f)\n",
    "ns_val, ts_val, f_val = X_val_hpo.shape\n",
    "X_val_hpo_scaled = preprocessor_hpo.transform(X_val_hpo.reshape(ns_val*ts_val, f_val)).reshape(ns_val, ts_val, f_val)\n",
    "\n",
    "print(\"--- Pre-creating sliding windows for HPO ---\")\n",
    "WINDOW_SIZE = 10\n",
    "STRIDE = 2\n",
    "X_train_w, y_train_w, _ = create_sliding_windows(X_train_hpo_scaled, y_train_hpo, WINDOW_SIZE, STRIDE)\n",
    "X_val_w, y_val_w, _ = create_sliding_windows(X_val_hpo_scaled, y_val_hpo, WINDOW_SIZE, STRIDE)\n",
    "\n",
    "# Convert to tensors once before HPO\n",
    "X_train_w_torch = torch.from_numpy(X_train_w).float()\n",
    "y_train_w_torch = torch.from_numpy(y_train_w).long()\n",
    "X_val_w_torch = torch.from_numpy(X_val_w).float()\n",
    "y_val_w_torch = torch.from_numpy(y_val_w).long()\n",
    "\n",
    "print(f\"Created training windows of shape: {X_train_w_torch.shape}\")\n",
    "\n",
    "# Clean up memory\n",
    "del X_train_hpo_scaled, X_val_hpo_scaled, X_train_w, y_train_w, X_val_w, y_val_w\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af25becb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2025-11-16 11:01:31</td></tr>\n",
       "<tr><td>Running for: </td><td>01:08:30.27        </td></tr>\n",
       "<tr><td>Memory:      </td><td>13.0/13.9 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=19<br>Bracket: Iter 100.000: 0.9128490198751902 | Iter 50.000: 0.909222325508647 | Iter 25.000: 0.9079306516399492<br>Logical resource usage: 16.0/16 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  : ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
       "  \n",
       "  \n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th>bidirectional  </th><th style=\"text-align: right;\">  conv_kernel_size</th><th style=\"text-align: right;\">  conv_out_channels</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  feature_dropout_rate</th><th style=\"text-align: right;\">  hidden_size</th><th style=\"text-align: right;\">  l2_lambda</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  num_layers</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  val_f1</th><th style=\"text-align: right;\">  train_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>objective_function_c38fd4f3</td><td>RUNNING   </td><td>127.0.0.1:48684</td><td style=\"text-align: right;\">          64</td><td>True           </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.255159</td><td style=\"text-align: right;\">             0.418946 </td><td style=\"text-align: right;\">          512</td><td style=\"text-align: right;\">9.3968e-06 </td><td style=\"text-align: right;\">0.00134012 </td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">    86</td><td style=\"text-align: right;\">        2332.58 </td><td style=\"text-align: right;\">0.912942</td><td style=\"text-align: right;\"> 9.87066e-05</td></tr>\n",
       "<tr><td>objective_function_15b37432</td><td>RUNNING   </td><td>127.0.0.1:43764</td><td style=\"text-align: right;\">          64</td><td>False          </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.447469</td><td style=\"text-align: right;\">             0.492401 </td><td style=\"text-align: right;\">          512</td><td style=\"text-align: right;\">6.36799e-07</td><td style=\"text-align: right;\">0.000298988</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         212.137</td><td style=\"text-align: right;\">0.889358</td><td style=\"text-align: right;\"> 0.0283405  </td></tr>\n",
       "<tr><td>objective_function_5943629d</td><td>RUNNING   </td><td>127.0.0.1:48820</td><td style=\"text-align: right;\">          64</td><td>True           </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.209919</td><td style=\"text-align: right;\">             0.246391 </td><td style=\"text-align: right;\">          512</td><td style=\"text-align: right;\">9.4604e-07 </td><td style=\"text-align: right;\">4.04328e-05</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         196.693</td><td style=\"text-align: right;\">0.808513</td><td style=\"text-align: right;\"> 0.139501   </td></tr>\n",
       "<tr><td>objective_function_88e96f87</td><td>RUNNING   </td><td>127.0.0.1:31828</td><td style=\"text-align: right;\">          64</td><td>False          </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.211467</td><td style=\"text-align: right;\">             0.479556 </td><td style=\"text-align: right;\">          512</td><td style=\"text-align: right;\">1.07104e-06</td><td style=\"text-align: right;\">4.69529e-05</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         163.55 </td><td style=\"text-align: right;\">0.825298</td><td style=\"text-align: right;\"> 0.139372   </td></tr>\n",
       "<tr><td>objective_function_640328b1</td><td>PENDING   </td><td>               </td><td style=\"text-align: right;\">          64</td><td>True           </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.219012</td><td style=\"text-align: right;\">             0.258937 </td><td style=\"text-align: right;\">          512</td><td style=\"text-align: right;\">1.05012e-06</td><td style=\"text-align: right;\">4.32324e-05</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">            </td></tr>\n",
       "<tr><td>objective_function_41ba932a</td><td>TERMINATED</td><td>127.0.0.1:27632</td><td style=\"text-align: right;\">         128</td><td>False          </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.487799</td><td style=\"text-align: right;\">             0.368712 </td><td style=\"text-align: right;\">          384</td><td style=\"text-align: right;\">6.34079e-05</td><td style=\"text-align: right;\">0.000247239</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         613.811</td><td style=\"text-align: right;\">0.91372 </td><td style=\"text-align: right;\"> 2.14581e-05</td></tr>\n",
       "<tr><td>objective_function_8cfaaab1</td><td>TERMINATED</td><td>127.0.0.1:8836 </td><td style=\"text-align: right;\">         128</td><td>True           </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.40291 </td><td style=\"text-align: right;\">             0.307372 </td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">2.26868e-06</td><td style=\"text-align: right;\">0.00043793 </td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         285.253</td><td style=\"text-align: right;\">0.90567 </td><td style=\"text-align: right;\"> 0.00811268 </td></tr>\n",
       "<tr><td>objective_function_69adfa5d</td><td>TERMINATED</td><td>127.0.0.1:50092</td><td style=\"text-align: right;\">         128</td><td>True           </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.189331</td><td style=\"text-align: right;\">             0.148713 </td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">2.74927e-05</td><td style=\"text-align: right;\">0.000762081</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         848.029</td><td style=\"text-align: right;\">0.913712</td><td style=\"text-align: right;\"> 2.19677e-06</td></tr>\n",
       "<tr><td>objective_function_5de04e3a</td><td>TERMINATED</td><td>127.0.0.1:38592</td><td style=\"text-align: right;\">         128</td><td>False          </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.317028</td><td style=\"text-align: right;\">             0.40033  </td><td style=\"text-align: right;\">          512</td><td style=\"text-align: right;\">1.50401e-05</td><td style=\"text-align: right;\">0.00428787 </td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         221.509</td><td style=\"text-align: right;\">0.903873</td><td style=\"text-align: right;\"> 0.0220052  </td></tr>\n",
       "<tr><td>objective_function_c39012ff</td><td>TERMINATED</td><td>127.0.0.1:35268</td><td style=\"text-align: right;\">          64</td><td>False          </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.254989</td><td style=\"text-align: right;\">             0.120915 </td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">1.17671e-05</td><td style=\"text-align: right;\">0.000665241</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">        1461.98 </td><td style=\"text-align: right;\">0.911986</td><td style=\"text-align: right;\"> 3.20958e-08</td></tr>\n",
       "<tr><td>objective_function_c5e016be</td><td>TERMINATED</td><td>127.0.0.1:49164</td><td style=\"text-align: right;\">         128</td><td>False          </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.41214 </td><td style=\"text-align: right;\">             0.433098 </td><td style=\"text-align: right;\">          512</td><td style=\"text-align: right;\">2.72314e-07</td><td style=\"text-align: right;\">1.27335e-05</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         175.538</td><td style=\"text-align: right;\">0.832184</td><td style=\"text-align: right;\"> 0.0988542  </td></tr>\n",
       "<tr><td>objective_function_d5c9ed17</td><td>TERMINATED</td><td>127.0.0.1:38924</td><td style=\"text-align: right;\">         128</td><td>True           </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.398529</td><td style=\"text-align: right;\">             0.0207011</td><td style=\"text-align: right;\">          384</td><td style=\"text-align: right;\">1.73241e-07</td><td style=\"text-align: right;\">0.0022401  </td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">        1129.8  </td><td style=\"text-align: right;\">0.90948 </td><td style=\"text-align: right;\"> 2.90365e-07</td></tr>\n",
       "<tr><td>objective_function_ba626a4d</td><td>TERMINATED</td><td>127.0.0.1:40368</td><td style=\"text-align: right;\">          64</td><td>False          </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.30241 </td><td style=\"text-align: right;\">             0.305268 </td><td style=\"text-align: right;\">          384</td><td style=\"text-align: right;\">4.84636e-06</td><td style=\"text-align: right;\">2.84645e-05</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         400.187</td><td style=\"text-align: right;\">0.894633</td><td style=\"text-align: right;\"> 0.0411828  </td></tr>\n",
       "<tr><td>objective_function_7566f6b5</td><td>TERMINATED</td><td>127.0.0.1:41360</td><td style=\"text-align: right;\">          64</td><td>False          </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.268932</td><td style=\"text-align: right;\">             0.20647  </td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">8.7724e-05 </td><td style=\"text-align: right;\">0.00266889 </td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         646.92 </td><td style=\"text-align: right;\">0.903155</td><td style=\"text-align: right;\"> 0.00304552 </td></tr>\n",
       "<tr><td>objective_function_8a189df2</td><td>TERMINATED</td><td>127.0.0.1:39852</td><td style=\"text-align: right;\">          64</td><td>True           </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.307245</td><td style=\"text-align: right;\">             0.401855 </td><td style=\"text-align: right;\">          384</td><td style=\"text-align: right;\">7.87434e-06</td><td style=\"text-align: right;\">0.00242336 </td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">        1845.98 </td><td style=\"text-align: right;\">0.908549</td><td style=\"text-align: right;\"> 0.000124346</td></tr>\n",
       "<tr><td>objective_function_0ba48272</td><td>TERMINATED</td><td>127.0.0.1:37200</td><td style=\"text-align: right;\">          64</td><td>False          </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.275859</td><td style=\"text-align: right;\">             0.171806 </td><td style=\"text-align: right;\">          384</td><td style=\"text-align: right;\">2.04565e-06</td><td style=\"text-align: right;\">1.95702e-05</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         325.192</td><td style=\"text-align: right;\">0.889584</td><td style=\"text-align: right;\"> 0.048486   </td></tr>\n",
       "<tr><td>objective_function_ac7b976f</td><td>TERMINATED</td><td>127.0.0.1:5980 </td><td style=\"text-align: right;\">          64</td><td>False          </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.376709</td><td style=\"text-align: right;\">             0.426437 </td><td style=\"text-align: right;\">          512</td><td style=\"text-align: right;\">1.59604e-07</td><td style=\"text-align: right;\">0.00257804 </td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">        1352.95 </td><td style=\"text-align: right;\">0.914017</td><td style=\"text-align: right;\"> 0.00081393 </td></tr>\n",
       "<tr><td>objective_function_68a0a43e</td><td>TERMINATED</td><td>127.0.0.1:31148</td><td style=\"text-align: right;\">          64</td><td>True           </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.144029</td><td style=\"text-align: right;\">             0.146399 </td><td style=\"text-align: right;\">          384</td><td style=\"text-align: right;\">3.04574e-05</td><td style=\"text-align: right;\">1.1824e-05 </td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         678.779</td><td style=\"text-align: right;\">0.872538</td><td style=\"text-align: right;\"> 0.0653901  </td></tr>\n",
       "<tr><td>objective_function_d9822a5f</td><td>TERMINATED</td><td>127.0.0.1:41492</td><td style=\"text-align: right;\">         128</td><td>True           </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.488413</td><td style=\"text-align: right;\">             0.493329 </td><td style=\"text-align: right;\">          384</td><td style=\"text-align: right;\">8.94379e-05</td><td style=\"text-align: right;\">0.000108823</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         260.754</td><td style=\"text-align: right;\">0.907471</td><td style=\"text-align: right;\"> 0.0202412  </td></tr>\n",
       "<tr><td>objective_function_ae8d758b</td><td>TERMINATED</td><td>127.0.0.1:42860</td><td style=\"text-align: right;\">         128</td><td>True           </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.484681</td><td style=\"text-align: right;\">             0.310292 </td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">9.59347e-05</td><td style=\"text-align: right;\">0.000108311</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         236.177</td><td style=\"text-align: right;\">0.904646</td><td style=\"text-align: right;\"> 0.0164197  </td></tr>\n",
       "<tr><td>objective_function_82c01d8b</td><td>TERMINATED</td><td>127.0.0.1:23312</td><td style=\"text-align: right;\">         128</td><td>True           </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.120918</td><td style=\"text-align: right;\">             0.295635 </td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">4.02325e-05</td><td style=\"text-align: right;\">0.000122165</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         959.509</td><td style=\"text-align: right;\">0.91846 </td><td style=\"text-align: right;\"> 4.67195e-05</td></tr>\n",
       "<tr><td>objective_function_3b52fbb0</td><td>TERMINATED</td><td>127.0.0.1:40068</td><td style=\"text-align: right;\">         128</td><td>True           </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.111479</td><td style=\"text-align: right;\">             0.048037 </td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">3.8283e-05 </td><td style=\"text-align: right;\">0.000118793</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         503.363</td><td style=\"text-align: right;\">0.905978</td><td style=\"text-align: right;\"> 0.00185005 </td></tr>\n",
       "<tr><td>objective_function_56fc9f18</td><td>TERMINATED</td><td>127.0.0.1:37772</td><td style=\"text-align: right;\">         128</td><td>False          </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.494086</td><td style=\"text-align: right;\">             0.309378 </td><td style=\"text-align: right;\">          512</td><td style=\"text-align: right;\">4.72981e-07</td><td style=\"text-align: right;\">7.29729e-05</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         727.95 </td><td style=\"text-align: right;\">0.907117</td><td style=\"text-align: right;\"> 0.000522371</td></tr>\n",
       "<tr><td>objective_function_be69d1ed</td><td>TERMINATED</td><td>127.0.0.1:44296</td><td style=\"text-align: right;\">          64</td><td>False          </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.436722</td><td style=\"text-align: right;\">             0.489933 </td><td style=\"text-align: right;\">          512</td><td style=\"text-align: right;\">6.47791e-07</td><td style=\"text-align: right;\">0.000197627</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         355.354</td><td style=\"text-align: right;\">0.900226</td><td style=\"text-align: right;\"> 0.0106783  </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 11:01:31,200\tWARNING tune.py:219 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2025-11-16 11:01:31,264\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to 'C:/Users/Karim Negm/ray_results/pirate_pain_conv1d_search_v8' in 0.0503s.\n",
      "2025-11-16 11:01:41,923\tINFO tune.py:1041 -- Total run time: 4121.00 seconds (4110.22 seconds for the tuning loop).\n",
      "2025-11-16 11:01:41,924\tWARNING tune.py:1056 -- Experiment has been interrupted, but the most recent state was saved.\n",
      "Resume experiment with: tune.run(..., resume=True)\n",
      "2025-11-16 11:01:42,354\tWARNING experiment_analysis.py:180 -- Failed to fetch metrics for 1 trial(s):\n",
      "- objective_function_640328b1: FileNotFoundError('Could not fetch metrics for objective_function_640328b1: both result.json and progress.csv were not found at C:/Users/Karim Negm/ray_results/pirate_pain_conv1d_search_v8/objective_function_640328b1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Search Complete ---\n",
      "\n",
      "Getting best trial from analysis...\n",
      "Best validation F1 score: 0.9137\n",
      "Best hyperparameters found:\n",
      "{'lr': 0.000762080670485435, 'batch_size': 128, 'hidden_size': 256, 'num_layers': 2, 'dropout_rate': 0.1893313296398405, 'feature_dropout_rate': 0.14871303800214314, 'bidirectional': True, 'l2_lambda': 2.7492692986406405e-05, 'conv_out_channels': 128, 'conv_kernel_size': 5, 'window_size': 10, 'stride': 2}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "860"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODIFIED: window_size and stride are now fixed for faster HPO\n",
    "search_space = {\n",
    "    \"lr\": tune.loguniform(1e-5, 5e-3),\n",
    "    \"batch_size\": tune.choice([64, 128]),\n",
    "    \"hidden_size\": tune.choice([256, 384, 512]),\n",
    "    \"num_layers\": tune.choice([2, 3]),\n",
    "    \"dropout_rate\": tune.uniform(0.1, 0.5),\n",
    "    \"feature_dropout_rate\": tune.uniform(0, 0.5),\n",
    "    \"bidirectional\": tune.choice([True, False]),\n",
    "    \"l2_lambda\": tune.loguniform(1e-7, 1e-4),\n",
    "    \"conv_out_channels\": tune.choice([128]),\n",
    "    \"conv_kernel_size\": tune.choice([5]),\n",
    "}\n",
    "\n",
    "def short_trial_name(trial): return f\"{trial.trainable_name}_{trial.trial_id}\"\n",
    "\n",
    "if ray.is_initialized(): ray.shutdown()\n",
    "ray.init(num_cpus=os.cpu_count(), num_gpus=1, ignore_reinit_error=True, log_to_driver=False)\n",
    "\n",
    "print(\"--- Starting hyperparameter search with pre-calculated windows ---\")\n",
    "analysis = tune.run(\n",
    "    tune.with_parameters(objective_function, \n",
    "                         X_train_w=X_train_w_torch, y_train_w=y_train_w_torch,\n",
    "                         X_val_w=X_val_w_torch, y_val_w=y_val_w_torch,\n",
    "                         class_weights=class_weights_tensor),\n",
    "    resources_per_trial={\"cpu\": 4, \"gpu\": 0.25},\n",
    "    config=search_space,\n",
    "    num_samples=30,\n",
    "    search_alg=OptunaSearch(metric=\"val_f1\", mode=\"max\"),\n",
    "    scheduler=ASHAScheduler(metric=\"val_f1\", mode=\"max\", grace_period=25, reduction_factor=2),\n",
    "    name=\"pirate_pain_conv1d_search_v8\",\n",
    "    verbose=1,\n",
    "    trial_dirname_creator=short_trial_name\n",
    ")\n",
    "\n",
    "print(\"\\n--- Search Complete ---\\n\")\n",
    "print(\"Getting best trial from analysis...\")\n",
    "best_trial = analysis.get_best_trial(metric=\"val_f1\", mode=\"max\", scope=\"all\")\n",
    "\n",
    "# BUG FIX: Use .last_result instead of .best_result\n",
    "if best_trial:\n",
    "    FINAL_CONFIG = best_trial.config\n",
    "    FINAL_BEST_VAL_F1 = best_trial.last_result[\"val_f1\"]\n",
    "    print(f\"Best validation F1 score: {FINAL_BEST_VAL_F1:.4f}\")\n",
    "    print(\"Best hyperparameters found:\")\n",
    "    # Add fixed window params back to the final config\n",
    "    FINAL_CONFIG['window_size'] = WINDOW_SIZE\n",
    "    FINAL_CONFIG['stride'] = STRIDE\n",
    "    print(FINAL_CONFIG)\n",
    "else:\n",
    "    print(\"ERROR: No trials completed successfully. Using a default config.\")\n",
    "    FINAL_CONFIG = {'lr': 0.001, 'batch_size': 128, 'hidden_size': 256, 'num_layers': 2, 'dropout_rate': 0.3, 'feature_dropout_rate': 0.3, 'bidirectional': True, 'l2_lambda': 1e-06, 'conv_out_channels': 128, 'conv_kernel_size': 5, 'window_size': 10, 'stride': 2}\n",
    "\n",
    "# Clean up HPO data to save memory\n",
    "del X_train_w_torch, y_train_w_torch, X_val_w_torch, y_val_w_torch\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98703644",
   "metadata": {},
   "source": [
    "## üèÜ 6. Phase 2: K-Fold Ensemble Training (on Training Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2a7cdba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- üèÜ Final Configuration Set --- \n",
      "Best Val F1 from HPO search: 0.9137\n",
      "{'lr': 0.000762080670485435, 'batch_size': 128, 'hidden_size': 256, 'num_layers': 2, 'dropout_rate': 0.1893313296398405, 'feature_dropout_rate': 0.14871303800214314, 'bidirectional': True, 'l2_lambda': 2.7492692986406405e-05, 'conv_out_channels': 128, 'conv_kernel_size': 5, 'window_size': 10, 'stride': 2}\n",
      "Submission name will be: submission_Conv1d-GRU_H256_L2_C128_K5_v8.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"--- üèÜ Final Configuration Set --- \")\n",
    "print(f\"Best Val F1 from HPO search: {FINAL_BEST_VAL_F1:.4f}\")\n",
    "print(FINAL_CONFIG)\n",
    "\n",
    "N_SPLITS = 5\n",
    "FINAL_EXPERIMENT_NAME = f\"Conv1d-GRU_H{FINAL_CONFIG['hidden_size']}_L{FINAL_CONFIG['num_layers']}_\" \\\n",
    "                      f\"C{FINAL_CONFIG['conv_out_channels']}_K{FINAL_CONFIG['conv_kernel_size']}_v8\"\n",
    "submission_filename_base = f\"submission_{FINAL_EXPERIMENT_NAME}.csv\"\n",
    "print(f\"Submission name will be: {submission_filename_base}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7874fe3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fold 1/5 --- (Conv1d-GRU_H256_L2_C128_K5_v8_fold_1) ---\n",
      "--- Starting Training: Conv1d-GRU_H256_L2_C128_K5_v8_fold_1 ---\n",
      "Epoch   5/100 | Best F1: 0.8345 | Val F1: 0.8657 | LR: 0.000080\n",
      "Epoch  10/100 | Best F1: 0.9152 | Val F1: 0.9236 | LR: 0.000213\n",
      "Epoch  15/100 | Best F1: 0.9269 | Val F1: 0.9295 | LR: 0.000396\n",
      "Epoch  20/100 | Best F1: 0.9295 | Val F1: 0.9237 | LR: 0.000579\n",
      "Epoch  25/100 | Best F1: 0.9369 | Val F1: 0.9322 | LR: 0.000713\n",
      "Epoch  30/100 | Best F1: 0.9396 | Val F1: 0.9412 | LR: 0.000762\n",
      "Epoch  35/100 | Best F1: 0.9419 | Val F1: 0.9398 | LR: 0.000753\n",
      "Epoch  40/100 | Best F1: 0.9419 | Val F1: 0.9353 | LR: 0.000724\n",
      "Epoch  45/100 | Best F1: 0.9419 | Val F1: 0.9364 | LR: 0.000679\n",
      "Epoch  50/100 | Best F1: 0.9419 | Val F1: 0.9376 | LR: 0.000619\n",
      "Epoch  55/100 | Best F1: 0.9419 | Val F1: 0.9232 | LR: 0.000546\n",
      "Epoch  60/100 | Best F1: 0.9419 | Val F1: 0.9281 | LR: 0.000466\n",
      "Epoch  65/100 | Best F1: 0.9419 | Val F1: 0.9345 | LR: 0.000381\n",
      "Epoch  70/100 | Best F1: 0.9437 | Val F1: 0.9414 | LR: 0.000296\n",
      "Epoch  75/100 | Best F1: 0.9437 | Val F1: 0.9426 | LR: 0.000216\n",
      "Epoch  80/100 | Best F1: 0.9437 | Val F1: 0.9412 | LR: 0.000143\n",
      "Epoch  85/100 | Best F1: 0.9437 | Val F1: 0.9421 | LR: 0.000083\n",
      "Epoch  90/100 | Best F1: 0.9437 | Val F1: 0.9423 | LR: 0.000038\n",
      "Epoch  95/100 | Best F1: 0.9437 | Val F1: 0.9425 | LR: 0.000010\n",
      "Epoch 100/100 | Best F1: 0.9437 | Val F1: 0.9420 | LR: 0.000000\n",
      "--- Finished Training --- Best F1: 0.9437\n",
      "Fold 1 Final Val F1: 0.9437\n",
      "\n",
      "--- Fold 2/5 --- (Conv1d-GRU_H256_L2_C128_K5_v8_fold_2) ---\n",
      "--- Starting Training: Conv1d-GRU_H256_L2_C128_K5_v8_fold_2 ---\n",
      "Epoch   5/100 | Best F1: 0.8543 | Val F1: 0.8704 | LR: 0.000080\n",
      "Epoch  10/100 | Best F1: 0.9019 | Val F1: 0.9027 | LR: 0.000213\n",
      "Epoch  15/100 | Best F1: 0.9031 | Val F1: 0.9006 | LR: 0.000396\n",
      "Epoch  20/100 | Best F1: 0.9135 | Val F1: 0.8985 | LR: 0.000579\n",
      "Epoch  25/100 | Best F1: 0.9135 | Val F1: 0.9026 | LR: 0.000713\n",
      "Epoch  30/100 | Best F1: 0.9138 | Val F1: 0.8977 | LR: 0.000762\n",
      "Epoch  35/100 | Best F1: 0.9138 | Val F1: 0.9081 | LR: 0.000753\n",
      "Epoch  40/100 | Best F1: 0.9138 | Val F1: 0.9107 | LR: 0.000724\n",
      "Epoch  45/100 | Best F1: 0.9219 | Val F1: 0.9085 | LR: 0.000679\n",
      "Epoch  50/100 | Best F1: 0.9219 | Val F1: 0.9032 | LR: 0.000619\n",
      "Epoch  55/100 | Best F1: 0.9219 | Val F1: 0.9066 | LR: 0.000546\n",
      "Epoch  60/100 | Best F1: 0.9219 | Val F1: 0.8977 | LR: 0.000466\n",
      "Epoch  65/100 | Best F1: 0.9219 | Val F1: 0.9034 | LR: 0.000381\n",
      "Epoch  70/100 | Best F1: 0.9219 | Val F1: 0.9067 | LR: 0.000296\n",
      "Epoch  75/100 | Best F1: 0.9219 | Val F1: 0.8976 | LR: 0.000216\n",
      "Epoch  80/100 | Best F1: 0.9219 | Val F1: 0.9012 | LR: 0.000143\n",
      "Epoch  85/100 | Best F1: 0.9219 | Val F1: 0.9031 | LR: 0.000083\n",
      "Epoch  90/100 | Best F1: 0.9219 | Val F1: 0.9033 | LR: 0.000038\n",
      "Epoch  95/100 | Best F1: 0.9219 | Val F1: 0.9029 | LR: 0.000010\n",
      "Epoch 100/100 | Best F1: 0.9219 | Val F1: 0.9029 | LR: 0.000000\n",
      "--- Finished Training --- Best F1: 0.9219\n",
      "Fold 2 Final Val F1: 0.9219\n",
      "\n",
      "--- Fold 3/5 --- (Conv1d-GRU_H256_L2_C128_K5_v8_fold_3) ---\n",
      "--- Starting Training: Conv1d-GRU_H256_L2_C128_K5_v8_fold_3 ---\n",
      "Epoch   5/100 | Best F1: 0.8543 | Val F1: 0.8683 | LR: 0.000080\n",
      "Epoch  10/100 | Best F1: 0.9192 | Val F1: 0.9098 | LR: 0.000213\n",
      "Epoch  15/100 | Best F1: 0.9192 | Val F1: 0.9091 | LR: 0.000396\n",
      "Epoch  20/100 | Best F1: 0.9351 | Val F1: 0.9110 | LR: 0.000579\n",
      "Epoch  25/100 | Best F1: 0.9351 | Val F1: 0.9050 | LR: 0.000713\n",
      "Epoch  30/100 | Best F1: 0.9351 | Val F1: 0.9178 | LR: 0.000762\n",
      "Epoch  35/100 | Best F1: 0.9351 | Val F1: 0.9092 | LR: 0.000753\n",
      "Epoch  40/100 | Best F1: 0.9351 | Val F1: 0.8983 | LR: 0.000724\n",
      "Epoch  45/100 | Best F1: 0.9398 | Val F1: 0.9360 | LR: 0.000679\n",
      "Epoch  50/100 | Best F1: 0.9398 | Val F1: 0.9162 | LR: 0.000619\n",
      "Epoch  55/100 | Best F1: 0.9398 | Val F1: 0.9048 | LR: 0.000546\n",
      "Epoch  60/100 | Best F1: 0.9398 | Val F1: 0.9096 | LR: 0.000466\n",
      "Epoch  65/100 | Best F1: 0.9398 | Val F1: 0.9122 | LR: 0.000381\n",
      "Epoch  70/100 | Best F1: 0.9398 | Val F1: 0.9206 | LR: 0.000296\n",
      "Epoch  75/100 | Best F1: 0.9398 | Val F1: 0.9182 | LR: 0.000216\n",
      "Epoch  80/100 | Best F1: 0.9398 | Val F1: 0.9167 | LR: 0.000143\n",
      "Epoch  85/100 | Best F1: 0.9398 | Val F1: 0.9197 | LR: 0.000083\n",
      "Epoch  90/100 | Best F1: 0.9398 | Val F1: 0.9187 | LR: 0.000038\n",
      "Epoch  95/100 | Best F1: 0.9398 | Val F1: 0.9191 | LR: 0.000010\n",
      "Epoch 100/100 | Best F1: 0.9398 | Val F1: 0.9185 | LR: 0.000000\n",
      "--- Finished Training --- Best F1: 0.9398\n",
      "Fold 3 Final Val F1: 0.9398\n",
      "\n",
      "--- Fold 4/5 --- (Conv1d-GRU_H256_L2_C128_K5_v8_fold_4) ---\n",
      "--- Starting Training: Conv1d-GRU_H256_L2_C128_K5_v8_fold_4 ---\n",
      "Epoch   5/100 | Best F1: 0.8555 | Val F1: 0.8801 | LR: 0.000080\n",
      "Epoch  10/100 | Best F1: 0.9177 | Val F1: 0.9083 | LR: 0.000213\n",
      "Epoch  15/100 | Best F1: 0.9272 | Val F1: 0.9169 | LR: 0.000396\n",
      "Epoch  20/100 | Best F1: 0.9333 | Val F1: 0.9238 | LR: 0.000579\n",
      "Epoch  25/100 | Best F1: 0.9333 | Val F1: 0.9263 | LR: 0.000713\n",
      "Epoch  30/100 | Best F1: 0.9333 | Val F1: 0.9195 | LR: 0.000762\n",
      "Epoch  35/100 | Best F1: 0.9333 | Val F1: 0.9284 | LR: 0.000753\n",
      "Epoch  40/100 | Best F1: 0.9333 | Val F1: 0.9322 | LR: 0.000724\n",
      "Epoch  45/100 | Best F1: 0.9333 | Val F1: 0.9262 | LR: 0.000679\n",
      "Epoch  50/100 | Best F1: 0.9333 | Val F1: 0.9290 | LR: 0.000619\n",
      "Epoch  55/100 | Best F1: 0.9333 | Val F1: 0.9347 | LR: 0.000546\n",
      "Epoch  60/100 | Best F1: 0.9347 | Val F1: 0.9315 | LR: 0.000466\n",
      "Epoch  65/100 | Best F1: 0.9347 | Val F1: 0.9301 | LR: 0.000381\n",
      "Epoch  70/100 | Best F1: 0.9347 | Val F1: 0.9290 | LR: 0.000296\n",
      "Epoch  75/100 | Best F1: 0.9347 | Val F1: 0.9297 | LR: 0.000216\n",
      "Epoch  80/100 | Best F1: 0.9347 | Val F1: 0.9290 | LR: 0.000143\n",
      "Epoch  85/100 | Best F1: 0.9347 | Val F1: 0.9294 | LR: 0.000083\n",
      "Epoch  90/100 | Best F1: 0.9347 | Val F1: 0.9309 | LR: 0.000038\n",
      "Epoch  95/100 | Best F1: 0.9347 | Val F1: 0.9302 | LR: 0.000010\n",
      "Epoch 100/100 | Best F1: 0.9347 | Val F1: 0.9300 | LR: 0.000000\n",
      "--- Finished Training --- Best F1: 0.9347\n",
      "Fold 4 Final Val F1: 0.9347\n",
      "\n",
      "--- Fold 5/5 --- (Conv1d-GRU_H256_L2_C128_K5_v8_fold_5) ---\n",
      "--- Starting Training: Conv1d-GRU_H256_L2_C128_K5_v8_fold_5 ---\n",
      "Epoch   5/100 | Best F1: 0.8336 | Val F1: 0.8598 | LR: 0.000080\n",
      "Epoch  10/100 | Best F1: 0.9303 | Val F1: 0.9232 | LR: 0.000213\n",
      "Epoch  15/100 | Best F1: 0.9355 | Val F1: 0.9228 | LR: 0.000396\n",
      "Epoch  20/100 | Best F1: 0.9394 | Val F1: 0.9378 | LR: 0.000579\n",
      "Epoch  25/100 | Best F1: 0.9394 | Val F1: 0.9316 | LR: 0.000713\n",
      "Epoch  30/100 | Best F1: 0.9394 | Val F1: 0.9318 | LR: 0.000762\n",
      "Epoch  35/100 | Best F1: 0.9413 | Val F1: 0.9383 | LR: 0.000753\n",
      "Epoch  40/100 | Best F1: 0.9413 | Val F1: 0.9303 | LR: 0.000724\n",
      "Epoch  45/100 | Best F1: 0.9421 | Val F1: 0.9366 | LR: 0.000679\n",
      "Epoch  50/100 | Best F1: 0.9432 | Val F1: 0.9490 | LR: 0.000619\n",
      "Epoch  55/100 | Best F1: 0.9490 | Val F1: 0.9322 | LR: 0.000546\n",
      "Epoch  60/100 | Best F1: 0.9490 | Val F1: 0.9379 | LR: 0.000466\n",
      "Epoch  65/100 | Best F1: 0.9490 | Val F1: 0.9471 | LR: 0.000381\n",
      "Epoch  70/100 | Best F1: 0.9490 | Val F1: 0.9458 | LR: 0.000296\n",
      "Epoch  75/100 | Best F1: 0.9490 | Val F1: 0.9421 | LR: 0.000216\n",
      "Epoch  80/100 | Best F1: 0.9490 | Val F1: 0.9423 | LR: 0.000143\n",
      "Epoch  85/100 | Best F1: 0.9490 | Val F1: 0.9424 | LR: 0.000083\n",
      "Epoch  90/100 | Best F1: 0.9490 | Val F1: 0.9433 | LR: 0.000038\n",
      "Epoch  95/100 | Best F1: 0.9490 | Val F1: 0.9434 | LR: 0.000010\n",
      "Epoch 100/100 | Best F1: 0.9490 | Val F1: 0.9434 | LR: 0.000000\n",
      "--- Finished Training --- Best F1: 0.9490\n",
      "Fold 5 Final Val F1: 0.9490\n",
      "\n",
      "--- üèÜ K-Fold Training Complete --- Average F1: 0.9378\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "fold_val_f1_list = []\n",
    "EPOCHS = 100\n",
    "\n",
    "# Re-order the full training set (X_train) before folding\n",
    "X_train_reordered_full = np.concatenate([\n",
    "    X_train[:, :, continuous_indices_orig],\n",
    "    X_train[:, :, categorical_indices_orig]\n",
    "], axis=2)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train_reordered_full, y_train)):\n",
    "    fold_name = f\"{FINAL_EXPERIMENT_NAME}_fold_{fold+1}\"\n",
    "    print(f\"\\n--- Fold {fold+1}/{N_SPLITS} --- ({fold_name}) ---\")\n",
    "    \n",
    "    X_train_fold, y_train_fold = X_train_reordered_full[train_idx], y_train[train_idx]\n",
    "    X_val_fold, y_val_fold = X_train_reordered_full[val_idx], y_train[val_idx]\n",
    "\n",
    "    preprocessor_fold = ColumnTransformer([('s', StandardScaler(), continuous_indices_reordered)], remainder='passthrough')\n",
    "    ns, ts, f = X_train_fold.shape\n",
    "    X_train_scaled = preprocessor_fold.fit_transform(X_train_fold.reshape(ns*ts, f)).reshape(ns, ts, f)\n",
    "    ns_val, ts_val, f_val = X_val_fold.shape\n",
    "    X_val_scaled = preprocessor_fold.transform(X_val_fold.reshape(ns_val*ts_val, f_val)).reshape(ns_val, ts_val, f_val)\n",
    "    \n",
    "    X_train_w, y_train_w, _ = create_sliding_windows(X_train_scaled, y_train_fold, FINAL_CONFIG['window_size'], FINAL_CONFIG['stride'])\n",
    "    X_val_w, y_val_w, _ = create_sliding_windows(X_val_scaled, y_val_fold, FINAL_CONFIG['window_size'], FINAL_CONFIG['stride'])\n",
    "    train_loader = make_loader(TensorDataset(torch.from_numpy(X_train_w).float(), torch.from_numpy(y_train_w).long()), FINAL_CONFIG['batch_size'], True, True)\n",
    "    val_loader = make_loader(TensorDataset(torch.from_numpy(X_val_w).float(), torch.from_numpy(y_val_w).long()), FINAL_CONFIG['batch_size'], False, False)\n",
    "\n",
    "    model_config_kfold = {k: v for k, v in FINAL_CONFIG.items() if k not in ['window_size', 'stride', 'lr', 'batch_size', 'l2_lambda']}\n",
    "    model_fold = RecurrentClassifier(**model_config_kfold, num_classes=N_CLASSES).to(device)\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model_fold.parameters(), lr=FINAL_CONFIG['lr'], weight_decay=FINAL_CONFIG['l2_lambda'])\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=FINAL_CONFIG['lr'], epochs=EPOCHS, steps_per_epoch=len(train_loader))\n",
    "    scaler = torch.amp.GradScaler(enabled=(device.type == 'cuda'))\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "\n",
    "    model_fold = fit(model_fold, train_loader, val_loader, EPOCHS, criterion, optimizer, scheduler, scaler, device, 100, fold_name)\n",
    "    _, val_f1 = validate_one_epoch(model_fold, val_loader, criterion, device)\n",
    "    fold_val_f1_list.append(val_f1)\n",
    "    print(f\"Fold {fold+1} Final Val F1: {val_f1:.4f}\")\n",
    "\n",
    "print(f\"\\n--- üèÜ K-Fold Training Complete --- Average F1: {np.mean(fold_val_f1_list):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67596153",
   "metadata": {},
   "source": [
    "## üì¨ 7. Phase 3: Ensemble Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c638f4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Preparing test dataset for submission ---\n",
      "Loading model 1/5 from models/Conv1d-GRU_H256_L2_C128_K5_v8_fold_1_best_model.pt...\n",
      "Loading model 2/5 from models/Conv1d-GRU_H256_L2_C128_K5_v8_fold_2_best_model.pt...\n",
      "Loading model 3/5 from models/Conv1d-GRU_H256_L2_C128_K5_v8_fold_3_best_model.pt...\n",
      "Loading model 4/5 from models/Conv1d-GRU_H256_L2_C128_K5_v8_fold_4_best_model.pt...\n",
      "Loading model 5/5 from models/Conv1d-GRU_H256_L2_C128_K5_v8_fold_5_best_model.pt...\n",
      "\n",
      "Successfully saved to submissions\\submission_Conv1d-GRU_H256_L2_C128_K5_v8.csv!\n",
      "  sample_index    label\n",
      "0          000  no_pain\n",
      "1          001  no_pain\n",
      "2          002  no_pain\n",
      "3          003  no_pain\n",
      "4          004  no_pain\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Preparing test dataset for submission ---\")\n",
    "\n",
    "# Re-order submission data columns to match training\n",
    "X_submission_reordered = np.concatenate([\n",
    "    X_submission_full_engineered[:, :, continuous_indices_orig],\n",
    "    X_submission_full_engineered[:, :, categorical_indices_orig]], axis=2)\n",
    "\n",
    "# Use a final preprocessor fitted on the ENTIRE training set (X_train)\n",
    "preprocessor_final = ColumnTransformer([('scaler', StandardScaler(), continuous_indices_reordered)], remainder='passthrough')\n",
    "ns, ts, f = X_train_reordered_full.shape # Use the full training set for fitting\n",
    "preprocessor_final.fit(X_train_reordered_full.reshape(ns * ts, f))\n",
    "\n",
    "# Scale the submission data\n",
    "ns_test, ts_test, f_test = X_submission_reordered.shape\n",
    "X_submission_scaled = preprocessor_final.transform(X_submission_reordered.reshape(ns_test * ts_test, f_test)).reshape(ns_test, ts_test, f_test)\n",
    "X_submission_w, submission_window_indices = create_sliding_windows(X_submission_scaled, y=None, window_size=FINAL_CONFIG['window_size'], stride=FINAL_CONFIG['stride'])\n",
    "submission_loader = make_loader(TensorDataset(torch.from_numpy(X_submission_w).float()), FINAL_CONFIG['batch_size'], False, False)\n",
    "\n",
    "model_config_final = {k: v for k, v in FINAL_CONFIG.items() if k not in ['window_size', 'stride', 'lr', 'batch_size', 'l2_lambda']}\n",
    "all_fold_probabilities = []\n",
    "\n",
    "# MODIFIED: Use all 5 folds for the ensemble\n",
    "for fold in range(N_SPLITS):\n",
    "    fold_name = f\"{FINAL_EXPERIMENT_NAME}_fold_{fold+1}\"\n",
    "    model_path = f\"models/{fold_name}_best_model.pt\"\n",
    "    print(f\"Loading model {fold+1}/{N_SPLITS} from {model_path}...\")\n",
    "    model_fold = RecurrentClassifier(**model_config_final, num_classes=N_CLASSES).to(device)\n",
    "    model_fold.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model_fold.eval()\n",
    "    \n",
    "    fold_preds = []\n",
    "    with torch.no_grad():\n",
    "        for (inputs,) in submission_loader:\n",
    "            with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n",
    "                probs = torch.softmax(model_fold(inputs.to(device)), dim=1)\n",
    "                fold_preds.append(probs.cpu().numpy())\n",
    "    all_fold_probabilities.append(np.concatenate(fold_preds))\n",
    "\n",
    "mean_probabilities = np.mean(all_fold_probabilities, axis=0)\n",
    "df_probs = pd.DataFrame(mean_probabilities, columns=[f\"prob_{i}\" for i in range(N_CLASSES)])\n",
    "df_probs['original_index'] = submission_window_indices\n",
    "agg_probs = df_probs.groupby('original_index')[[f\"prob_{i}\" for i in range(N_CLASSES)]].mean().values\n",
    "final_predictions = le.inverse_transform(np.argmax(agg_probs, axis=1))\n",
    "\n",
    "submission_df = pd.DataFrame({'sample_index': sorted(X_submission_long_df['sample_index'].unique()), 'label': final_predictions})\n",
    "submission_df['sample_index'] = submission_df['sample_index'].apply(lambda x: f\"{x:03d}\")\n",
    "submission_filepath = os.path.join(\"submissions\", submission_filename_base)\n",
    "submission_df.to_csv(submission_filepath, index=False)\n",
    "print(f\"\\nSuccessfully saved to {submission_filepath}!\")\n",
    "print(submission_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e386d3",
   "metadata": {},
   "source": [
    "## üìú 8. Final Model Evaluation (on Hold-Out Test Set)\n",
    "\n",
    "Here we evaluate the final K-Fold ensemble on the 10% test set we created at the start. This provides an unbiased estimate of the model's performance on new, unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dffdc9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Preparing hold-out test set for final evaluation ---\n",
      "\n",
      "--- Generating predictions on the hold-out test set ---\n",
      "Loading model 1/5 from models/Conv1d-GRU_H256_L2_C128_K5_v8_fold_1_best_model.pt...\n",
      "Loading model 2/5 from models/Conv1d-GRU_H256_L2_C128_K5_v8_fold_2_best_model.pt...\n",
      "Loading model 3/5 from models/Conv1d-GRU_H256_L2_C128_K5_v8_fold_3_best_model.pt...\n",
      "Loading model 4/5 from models/Conv1d-GRU_H256_L2_C128_K5_v8_fold_4_best_model.pt...\n",
      "Loading model 5/5 from models/Conv1d-GRU_H256_L2_C128_K5_v8_fold_5_best_model.pt...\n",
      "\n",
      "--- Final Ensemble Performance on Hold-Out Test Set ---\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   high_pain       0.75      0.50      0.60         6\n",
      "    low_pain       1.00      0.67      0.80         9\n",
      "     no_pain       0.91      1.00      0.95        52\n",
      "\n",
      "    accuracy                           0.91        67\n",
      "   macro avg       0.89      0.72      0.78        67\n",
      "weighted avg       0.91      0.91      0.90        67\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"--- Preparing hold-out test set for final evaluation ---\")\n",
    "\n",
    "# Re-order test data columns to match training\n",
    "X_test_reordered = np.concatenate([\n",
    "    X_test[:, :, continuous_indices_orig],\n",
    "    X_test[:, :, categorical_indices_orig]], axis=2)\n",
    "\n",
    "# Use the same preprocessor that was fitted on the full training data\n",
    "ns_test, ts_test, f_test = X_test_reordered.shape\n",
    "X_test_scaled = preprocessor_final.transform(X_test_reordered.reshape(ns_test * ts_test, f_test)).reshape(ns_test, ts_test, f_test)\n",
    "\n",
    "# Create sliding windows for the test set\n",
    "X_test_w, _, test_window_indices = create_sliding_windows(X_test_scaled, y=y_test, window_size=FINAL_CONFIG['window_size'], stride=FINAL_CONFIG['stride'])\n",
    "test_loader = make_loader(TensorDataset(torch.from_numpy(X_test_w).float()), FINAL_CONFIG['batch_size'], False, False)\n",
    "\n",
    "all_fold_test_probabilities = []\n",
    "print(\"\\n--- Generating predictions on the hold-out test set ---\")\n",
    "for fold in range(N_SPLITS):\n",
    "    fold_name = f\"{FINAL_EXPERIMENT_NAME}_fold_{fold+1}\"\n",
    "    model_path = f\"models/{fold_name}_best_model.pt\"\n",
    "    print(f\"Loading model {fold+1}/{N_SPLITS} from {model_path}...\")\n",
    "    model_fold = RecurrentClassifier(**model_config_final, num_classes=N_CLASSES).to(device)\n",
    "    model_fold.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model_fold.eval()\n",
    "    \n",
    "    fold_test_preds = []\n",
    "    with torch.no_grad():\n",
    "        for (inputs,) in test_loader:\n",
    "            with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n",
    "                probs = torch.softmax(model_fold(inputs.to(device)), dim=1)\n",
    "                fold_test_preds.append(probs.cpu().numpy())\n",
    "    all_fold_test_probabilities.append(np.concatenate(fold_test_preds))\n",
    "\n",
    "# --- Aggregate predictions and evaluate ---\n",
    "mean_test_probabilities = np.mean(all_fold_test_probabilities, axis=0)\n",
    "df_test_probs = pd.DataFrame(mean_test_probabilities, columns=[f\"prob_{i}\" for i in range(N_CLASSES)])\n",
    "df_test_probs['original_index'] = test_window_indices\n",
    "agg_test_probs = df_test_probs.groupby('original_index')[[f\"prob_{i}\" for i in range(N_CLASSES)]].mean().values\n",
    "final_test_predictions = np.argmax(agg_test_probs, axis=1)\n",
    "\n",
    "# Get the true labels for the original samples that had windows created\n",
    "true_test_labels = y_test[np.unique(test_window_indices)]\n",
    "\n",
    "print(\"\\n--- Final Ensemble Performance on Hold-Out Test Set ---\")\n",
    "\n",
    "# Classification Report\n",
    "class_names = le.classes_\n",
    "report = classification_report(true_test_labels, final_test_predictions, target_names=class_names)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(true_test_labels, final_test_predictions)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Confusion Matrix on Hold-Out Test Set', fontsize=16)\n",
    "plt.ylabel('Actual Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "an2dl-kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
