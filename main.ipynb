{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67bb0a3d",
   "metadata": {},
   "source": [
    "# **Kaggle Challenge: Pirate Pain Dataset üè¥‚Äç‚ò†Ô∏è (v7: Conv1d + LR Scheduler)**\n",
    "\n",
    "This notebook introduces a powerful Conv1d-GRU architecture to break through performance plateaus. It combines 1D convolutions for low-level feature extraction with a GRU for high-level sequence modeling.\n",
    "\n",
    "**Strategy:**\n",
    "1.  **Hybrid Feature Input:**\n",
    "    * **Continuous Features:** 31 `joint_` features + 1 `time` feature are scaled.\n",
    "    * **Categorical Features:** 4 `pain_survey_` features + 1 `is_pirate` feature are passed to `nn.Embedding` layers.\n",
    "2.  **Conv1d-GRU Architecture:**\n",
    "    *   A **`nn.Conv1d`** layer first processes the full sequence of combined features to identify local, time-invariant patterns.\n",
    "    *   The output sequence from the Conv1d layer is then fed into the **`nn.GRU`** to model longer-term temporal dependencies.\n",
    "3.  **Advanced Training:**\n",
    "    *   A **`CosineAnnealingLR`** learning rate scheduler is used to improve convergence and find better minima.\n",
    "    *   Heavy regularization via two separate `Dropout` layers (one for features, one for the GRU) is used to prevent overfitting.\n",
    "4.  **Hyperparameter Search:** Ray Tune & Optuna are used to find optimal parameters for the entire Conv1d-GRU stack, including the LR scheduler.\n",
    "5.  **K-Fold Ensemble:** The best configuration is trained on 5 folds for a robust final prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b03291d",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è 1. Setup & Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ba22088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Using GPU ---\n",
      "PyTorch version: 2.5.1\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set seed for reproducibility\n",
    "SEED = 123\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "import logging\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import copy\n",
    "from itertools import product\n",
    "import time\n",
    "\n",
    "# Set environment variables before importing modules\n",
    "os.environ['MPLCONFIGDIR'] = os.getcwd() + '/configs/'\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "# --- PyTorch Imports ---\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# --- Sklearn Imports ---\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "# --- Ray[tune] & Optuna Imports ---\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.search.optuna import OptunaSearch\n",
    "from functools import partial\n",
    "\n",
    "# --- Setup Directories & Device ---\n",
    "logs_dir = \"tensorboard\"\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "os.makedirs(\"submissions\", exist_ok=True)\n",
    "os.makedirs(logs_dir, exist_ok=True)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    print(\"\\n--- Using GPU ---\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"\\n--- Using CPU ---\")\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Configure plot display settings\n",
    "sns.set_theme(font_scale=1.4)\n",
    "sns.set_style('white')\n",
    "plt.rc('font', size=14)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8582ef",
   "metadata": {},
   "source": [
    "## üîÑ 2. Data Loading & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44203b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Loading Data ---\n",
      "Loaded X_train_full (shape: (661, 160, 36)) and y_train_full (shape: (661,))\n",
      "Loaded X_test_full (shape: (1324, 160, 36))\n",
      "\n",
      "--- 2. Engineering 'is_pirate' Feature ---\n",
      "Created X_train_full_engineered (shape: (661, 160, 37))\n",
      "Created X_test_full_engineered (shape: (1324, 160, 37))\n",
      "N_FEATURES is now: 37\n",
      "\n",
      "--- 3. Calculating Class Weights ---\n",
      "Class counts (0, 1, 2): [511  94  56]\n",
      "Calculated class weights: tensor([0.0643, 0.3493, 0.5864], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"--- 1. Loading Data ---\")\n",
    "\n",
    "# --- Define File Paths and Features ---\n",
    "DATA_DIR = \"data\"\n",
    "X_TRAIN_PATH = os.path.join(DATA_DIR, \"pirate_pain_train.csv\")\n",
    "Y_TRAIN_PATH = os.path.join(DATA_DIR, \"pirate_pain_train_labels.csv\")\n",
    "X_TEST_PATH = os.path.join(DATA_DIR, \"pirate_pain_test.csv\")\n",
    "SUBMISSION_PATH = os.path.join(DATA_DIR, \"sample_submission.csv\")\n",
    "\n",
    "try:\n",
    "    features_long_df = pd.read_csv(X_TRAIN_PATH)\n",
    "    labels_df = pd.read_csv(Y_TRAIN_PATH)\n",
    "    X_test_long_df = pd.read_csv(X_TEST_PATH)\n",
    "    \n",
    "    N_TIMESTEPS = 160\n",
    "    JOINT_FEATURES = [f\"joint_{i:02d}\" for i in range(31)]\n",
    "    PAIN_FEATURES = [f\"pain_survey_{i}\" for i in range(1, 5)]\n",
    "    TIME_FEATURE = ['time']\n",
    "    FEATURES = JOINT_FEATURES + PAIN_FEATURES + TIME_FEATURE\n",
    "    LABEL_MAPPING = {'no_pain': 0, 'low_pain': 1, 'high_pain': 2}\n",
    "    N_CLASSES = len(LABEL_MAPPING)\n",
    "\n",
    "    def reshape_data(df, features_list, n_timesteps):\n",
    "        df_pivot = df.pivot(index='sample_index', columns='time', values=features_list)\n",
    "        data_2d = df_pivot.values\n",
    "        n_samples = data_2d.shape[0]\n",
    "        data_3d = data_2d.reshape(n_samples, len(features_list), n_timesteps)\n",
    "        return data_3d.transpose(0, 2, 1)\n",
    "\n",
    "    X_train_full = reshape_data(features_long_df[features_long_df['sample_index'].isin(labels_df['sample_index'].unique())], FEATURES, N_TIMESTEPS)\n",
    "    X_test_full = reshape_data(X_test_long_df, FEATURES, N_TIMESTEPS)\n",
    "    y_train_full_df = labels_df.sort_values(by='sample_index')\n",
    "    le = LabelEncoder().fit(list(LABEL_MAPPING.keys()))\n",
    "    y_train_full = le.transform(y_train_full_df['label'])\n",
    "    print(f\"Loaded X_train_full (shape: {X_train_full.shape}) and y_train_full (shape: {y_train_full.shape})\")\n",
    "    print(f\"Loaded X_test_full (shape: {X_test_full.shape})\")\n",
    "\n",
    "    print(\"\\n--- 2. Engineering 'is_pirate' Feature ---\")\n",
    "    static_cols = ['sample_index', 'n_legs', 'n_hands', 'n_eyes']\n",
    "    static_df = features_long_df[static_cols].drop_duplicates().set_index('sample_index')\n",
    "    pirate_filter = (static_df['n_legs'] == 'one+peg_leg') | (static_df['n_hands'] == 'one+hook_hand') | (static_df['n_eyes'] == 'one+eye_patch')\n",
    "    pirate_indices = static_df[pirate_filter].index\n",
    "    sample_indices_ordered = sorted(features_long_df[features_long_df['sample_index'].isin(labels_df['sample_index'].unique())]['sample_index'].unique())\n",
    "    is_pirate_map = np.array([1 if idx in pirate_indices else 0 for idx in sample_indices_ordered])\n",
    "    pirate_feature_broadcast = np.tile(is_pirate_map.reshape(-1, 1, 1), (1, N_TIMESTEPS, 1))\n",
    "    X_train_full_engineered = np.concatenate([X_train_full, pirate_feature_broadcast], axis=2)\n",
    "\n",
    "    static_df_test = X_test_long_df[static_cols].drop_duplicates().set_index('sample_index')\n",
    "    pirate_filter_test = (static_df_test['n_legs'] == 'one+peg_leg') | (static_df_test['n_hands'] == 'one+hook_hand') | (static_df_test['n_eyes'] == 'one+eye_patch')\n",
    "    pirate_indices_test = static_df_test[pirate_filter_test].index\n",
    "    sample_indices_test_ordered = sorted(X_test_long_df['sample_index'].unique())\n",
    "    is_pirate_map_test = np.array([1 if idx in pirate_indices_test else 0 for idx in sample_indices_test_ordered])\n",
    "    pirate_feature_broadcast_test = np.tile(is_pirate_map_test.reshape(-1, 1, 1), (1, N_TIMESTEPS, 1))\n",
    "    X_test_full_engineered = np.concatenate([X_test_full, pirate_feature_broadcast_test], axis=2)\n",
    "    \n",
    "    N_FEATURES_NEW = X_train_full_engineered.shape[2]\n",
    "    print(f\"Created X_train_full_engineered (shape: {X_train_full_engineered.shape})\")\n",
    "    print(f\"Created X_test_full_engineered (shape: {X_test_full_engineered.shape})\")\n",
    "    print(f\"N_FEATURES is now: {N_FEATURES_NEW}\")\n",
    "\n",
    "    print(\"\\n--- 3. Calculating Class Weights ---\")\n",
    "    class_counts_series = labels_df['label'].value_counts()\n",
    "    counts_ordered = class_counts_series.reindex(LABEL_MAPPING.keys()).values\n",
    "    class_weights_tensor = 1.0 / torch.tensor(counts_ordered, dtype=torch.float)\n",
    "    class_weights_tensor = (class_weights_tensor / class_weights_tensor.sum()).to(device)\n",
    "    print(f\"Class counts (0, 1, 2): {counts_ordered}\")\n",
    "    print(f\"Calculated class weights: {class_weights_tensor}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6f8bc4",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è 3. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a7c2d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sliding_windows(X_3d, y=None, window_size=100, stride=20):\n",
    "    new_X, new_y, window_indices = [], [], []\n",
    "    n_samples, n_timesteps, _ = X_3d.shape\n",
    "    for i in range(n_samples):\n",
    "        idx = 0\n",
    "        while (idx + window_size) <= n_timesteps:\n",
    "            new_X.append(X_3d[i, idx:idx+window_size, :])\n",
    "            window_indices.append(i)\n",
    "            if y is not None: new_y.append(y[i])\n",
    "            idx += stride\n",
    "    if y is not None:\n",
    "        return np.array(new_X), np.array(new_y), np.array(window_indices)\n",
    "    return np.array(new_X), np.array(window_indices)\n",
    "\n",
    "def make_loader(ds, batch_size, shuffle, drop_last):\n",
    "    return DataLoader(ds, batch_size=int(batch_size), shuffle=shuffle, drop_last=drop_last, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faed930",
   "metadata": {},
   "source": [
    "## üß† 4. Model & Training Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3cadd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentClassifier(nn.Module):\n",
    "    def __init__(self, hidden_size, num_layers, num_classes,\n",
    "                 conv_out_channels, conv_kernel_size, bidirectional,\n",
    "                 dropout_rate, feature_dropout_rate, rnn_type='GRU'):\n",
    "        super().__init__()\n",
    "        self.rnn_type, self.num_layers, self.hidden_size, self.bidirectional = \\\n",
    "            rnn_type, num_layers, hidden_size, bidirectional\n",
    "\n",
    "        # --- Feature Engineering Layers ---\n",
    "        self.pain_embed_dim, self.pirate_embed_dim = 4, 4\n",
    "        self.pain_embeddings = nn.ModuleList([nn.Embedding(3, self.pain_embed_dim) for _ in range(4)])\n",
    "        self.pirate_embedding = nn.Embedding(2, self.pirate_embed_dim)\n",
    "        \n",
    "        num_continuous_features = 32 # 31 joints + 1 time\n",
    "        total_embedding_dim = (4 * self.pain_embed_dim) + self.pirate_embed_dim\n",
    "        conv_input_size = num_continuous_features + total_embedding_dim\n",
    "\n",
    "        # --- Conv1d Layer for Feature Extraction ---\n",
    "        self.conv1d = nn.Conv1d(in_channels=conv_input_size, out_channels=conv_out_channels,\n",
    "                                kernel_size=conv_kernel_size, padding='same')\n",
    "        self.conv_activation = nn.ReLU()\n",
    "        self.feature_dropout = nn.Dropout(feature_dropout_rate)\n",
    "\n",
    "        # --- RNN Layer for Sequence Modeling ---\n",
    "        self.rnn = nn.GRU(\n",
    "            input_size=conv_out_channels, hidden_size=hidden_size,\n",
    "            num_layers=num_layers, batch_first=True, bidirectional=bidirectional,\n",
    "            dropout=dropout_rate if num_layers > 1 else 0)\n",
    "        \n",
    "        # --- Classifier Head ---\n",
    "        self.classifier = nn.Linear(hidden_size * 2 if bidirectional else hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_continuous = x[:, :, :32]\n",
    "        x_categorical = x[:, :, 32:].long()\n",
    "        embedded_cats = [self.pain_embeddings[i](x_categorical[:, :, i]) for i in range(4)] \\\n",
    "                      + [self.pirate_embedding(x_categorical[:, :, 4])]\n",
    "        x_combined = torch.cat([x_continuous] + embedded_cats, dim=2)\n",
    "        x_permuted = x_combined.permute(0, 2, 1)\n",
    "        x_conv = self.conv_activation(self.conv1d(x_permuted))\n",
    "        x_conv_permuted = x_conv.permute(0, 2, 1)\n",
    "        x_dropped = self.feature_dropout(x_conv_permuted)\n",
    "        _, hidden = self.rnn(x_dropped)\n",
    "        if self.bidirectional:\n",
    "            hidden = hidden.view(self.num_layers, 2, -1, self.hidden_size)\n",
    "            hidden = torch.cat([hidden[-1, 0, :, :], hidden[-1, 1, :, :]], dim=1)\n",
    "        else:\n",
    "            hidden = hidden[-1]\n",
    "        return self.classifier(hidden)\n",
    "\n",
    "def train_one_epoch(model, loader, criterion, optimizer, scaler, device):\n",
    "    model.train()\n",
    "    total_loss, all_preds, all_targets = 0, [], []\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "        all_preds.append(logits.argmax(dim=1).cpu().numpy())\n",
    "        all_targets.append(y.cpu().numpy())\n",
    "    return total_loss / len(loader.dataset.tensors[0]), f1_score(np.concatenate(all_targets), np.concatenate(all_preds), average='weighted')\n",
    "\n",
    "def validate_one_epoch(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss, all_preds, all_targets = 0, [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n",
    "                logits = model(x)\n",
    "                loss = criterion(logits, y)\n",
    "            total_loss += loss.item() * x.size(0)\n",
    "            all_preds.append(logits.argmax(dim=1).cpu().numpy())\n",
    "            all_targets.append(y.cpu().numpy())\n",
    "    return total_loss / len(loader.dataset.tensors[0]), f1_score(np.concatenate(all_targets), np.concatenate(all_preds), average='weighted')\n",
    "\n",
    "def objective_function(config, X_train, y_train, X_val, y_val, class_weights):\n",
    "    continuous_indices = list(range(32))\n",
    "    preprocessor = ColumnTransformer([('scaler', StandardScaler(), continuous_indices)], remainder='passthrough')\n",
    "    ns, ts, f = X_train.shape\n",
    "    X_train_final = preprocessor.fit_transform(X_train.reshape(ns * ts, f)).reshape(ns, ts, -1)\n",
    "    ns_val, ts_val, f_val = X_val.shape\n",
    "    X_val_final = preprocessor.transform(X_val.reshape(ns_val * ts_val, f_val)).reshape(ns_val, ts_val, -1)\n",
    "\n",
    "    X_train_w, y_train_w, _ = create_sliding_windows(X_train_final, y_train, config[\"window_size\"], config[\"stride\"])\n",
    "    X_val_w, y_val_w, _ = create_sliding_windows(X_val_final, y_val, config[\"window_size\"], config[\"stride\"])\n",
    "    train_loader = make_loader(TensorDataset(torch.from_numpy(X_train_w).float(), torch.from_numpy(y_train_w).long()), config[\"batch_size\"], True, True)\n",
    "    val_loader = make_loader(TensorDataset(torch.from_numpy(X_val_w).float(), torch.from_numpy(y_val_w).long()), config[\"batch_size\"], False, False)\n",
    "\n",
    "    model_config = {\n",
    "        'hidden_size': config['hidden_size'], 'num_layers': config['num_layers'],\n",
    "        'conv_out_channels': config['conv_out_channels'], 'conv_kernel_size': config['conv_kernel_size'],\n",
    "        'bidirectional': config['bidirectional'], 'dropout_rate': config['dropout_rate'],\n",
    "        'feature_dropout_rate': config['feature_dropout_rate']\n",
    "    }\n",
    "    model = RecurrentClassifier(**model_config, num_classes=N_CLASSES, rnn_type='GRU').to(device)\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config[\"lr\"], weight_decay=config[\"l2_lambda\"])\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=150)\n",
    "    scaler = torch.amp.GradScaler(enabled=(device.type == 'cuda'))\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "    best_val_f1 = -1.0\n",
    "    patience_counter = 0\n",
    "    # Set a fixed patience for all HPO trials\n",
    "    hpo_patience = 20  \n",
    "    \n",
    "    for epoch in range(1, 151):\n",
    "        train_loss, _ = train_one_epoch(model, train_loader, criterion, optimizer, scaler, device)\n",
    "        _, val_f1 = validate_one_epoch(model, val_loader, criterion, device)\n",
    "        tune.report({\"val_f1\": val_f1, \"train_loss\": train_loss})\n",
    "        scheduler.step()\n",
    "\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= hpo_patience:\n",
    "                print(f\"Trial early stopping at epoch {epoch}\")\n",
    "                break # Stop training\n",
    "\n",
    "def fit(model, train_loader, val_loader, epochs, criterion, optimizer, scheduler, scaler, device, patience, experiment_name):\n",
    "    model_path = f\"models/{experiment_name}_best_model.pt\"\n",
    "    best_f1 = -1\n",
    "    patience_counter = 0\n",
    "    print(f\"--- Starting Training: {experiment_name} ---\")\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_loss, train_f1 = train_one_epoch(model, train_loader, criterion, optimizer, scaler, device)\n",
    "        val_loss, val_f1 = validate_one_epoch(model, val_loader, criterion, device)\n",
    "        scheduler.step()\n",
    "\n",
    "        if epoch % 25 == 0: print(f\"Epoch {epoch:3d}/{epochs} | Val F1: {val_f1:.4f} | LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "\n",
    "        if val_f1 > best_f1:\n",
    "            best_f1, patience_counter = val_f1, 0\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch}. Best F1: {best_f1:.4f}\")\n",
    "                break\n",
    "    print(f\"--- Finished Training --- Best F1: {best_f1:.4f}\")\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9f911c",
   "metadata": {},
   "source": [
    "## üß™ 5. Phase 1: Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d09a835f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-ordered X_train_full shape: (661, 160, 37)\n",
      "\n",
      "--- Splitting re-ordered, unscaled data for HPO ---\n",
      "  X_train_split: (528, 160, 37)\n",
      "  X_val_split:   (133, 160, 37)\n"
     ]
    }
   ],
   "source": [
    "# Re-order columns: 32 continuous (joints+time), then 5 categorical (pain+pirate)\n",
    "continuous_indices_orig = list(range(31)) + [35]\n",
    "categorical_indices_orig = list(range(31, 35)) + [36]\n",
    "X_train_full_reordered = np.concatenate([\n",
    "    X_train_full_engineered[:, :, continuous_indices_orig],\n",
    "    X_train_full_engineered[:, :, categorical_indices_orig]\n",
    "], axis=2)\n",
    "print(f\"Re-ordered X_train_full shape: {X_train_full_reordered.shape}\")\n",
    "\n",
    "# --- Split the re-ordered data ---\n",
    "print(\"\\n--- Splitting re-ordered, unscaled data for HPO ---\")\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED)\n",
    "for train_idx, val_idx in sss.split(X_train_full_reordered, y_train_full):\n",
    "    X_train_split, y_train_split = X_train_full_reordered[train_idx], y_train_full[train_idx]\n",
    "    X_val_split, y_val_split = X_train_full_reordered[val_idx], y_train_full[val_idx]\n",
    "print(f\"  X_train_split: {X_train_split.shape}\\n  X_val_split:   {X_val_split.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42797c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2025-11-13 13:55:08</td></tr>\n",
       "<tr><td>Running for: </td><td>01:32:06.04        </td></tr>\n",
       "<tr><td>Memory:      </td><td>8.4/13.9 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=30<br>Bracket: Iter 100.000: 0.9264052383524888 | Iter 50.000: 0.9233304876526616 | Iter 25.000: 0.9158548941908977<br>Logical resource usage: 4.0/16 CPUs, 0.25/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th>bidirectional  </th><th style=\"text-align: right;\">  conv_kernel_size</th><th style=\"text-align: right;\">  conv_out_channels</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  feature_dropout_rate</th><th style=\"text-align: right;\">  hidden_size</th><th style=\"text-align: right;\">  l2_lambda</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  num_layers</th><th style=\"text-align: right;\">  stride</th><th style=\"text-align: right;\">  window_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  val_f1</th><th style=\"text-align: right;\">  val_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>objective_function_56e3c4cb</td><td>TERMINATED</td><td>127.0.0.1:34056</td><td style=\"text-align: right;\">          64</td><td>True           </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.175474</td><td style=\"text-align: right;\">              0.236743</td><td style=\"text-align: right;\">          384</td><td style=\"text-align: right;\">5.6326e-06 </td><td style=\"text-align: right;\">0.00261819 </td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         456.531</td><td style=\"text-align: right;\">0.900907</td><td style=\"text-align: right;\">  0.709033</td></tr>\n",
       "<tr><td>objective_function_0114e8de</td><td>TERMINATED</td><td>127.0.0.1:2468 </td><td style=\"text-align: right;\">         128</td><td>True           </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.426372</td><td style=\"text-align: right;\">              0.444383</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">1.60923e-07</td><td style=\"text-align: right;\">0.00218217 </td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         967.473</td><td style=\"text-align: right;\">0.939522</td><td style=\"text-align: right;\">  0.367894</td></tr>\n",
       "<tr><td>objective_function_157353eb</td><td>TERMINATED</td><td>127.0.0.1:13720</td><td style=\"text-align: right;\">         128</td><td>False          </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                 64</td><td style=\"text-align: right;\">      0.241345</td><td style=\"text-align: right;\">              0.268222</td><td style=\"text-align: right;\">          384</td><td style=\"text-align: right;\">2.21765e-06</td><td style=\"text-align: right;\">0.000113209</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         735.088</td><td style=\"text-align: right;\">0.910966</td><td style=\"text-align: right;\">  0.61634 </td></tr>\n",
       "<tr><td>objective_function_ebc904f4</td><td>TERMINATED</td><td>127.0.0.1:22020</td><td style=\"text-align: right;\">         128</td><td>True           </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                 64</td><td style=\"text-align: right;\">      0.277957</td><td style=\"text-align: right;\">              0.461164</td><td style=\"text-align: right;\">          384</td><td style=\"text-align: right;\">2.92564e-06</td><td style=\"text-align: right;\">0.00245462 </td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         335.092</td><td style=\"text-align: right;\">0.888099</td><td style=\"text-align: right;\">  0.434215</td></tr>\n",
       "<tr><td>objective_function_8f7406c6</td><td>TERMINATED</td><td>127.0.0.1:36252</td><td style=\"text-align: right;\">         128</td><td>True           </td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.27791 </td><td style=\"text-align: right;\">              0.359588</td><td style=\"text-align: right;\">          384</td><td style=\"text-align: right;\">2.09787e-07</td><td style=\"text-align: right;\">0.000219033</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         473.882</td><td style=\"text-align: right;\">0.912075</td><td style=\"text-align: right;\">  0.395935</td></tr>\n",
       "<tr><td>objective_function_d5e492ef</td><td>TERMINATED</td><td>127.0.0.1:4968 </td><td style=\"text-align: right;\">          64</td><td>False          </td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">                 64</td><td style=\"text-align: right;\">      0.441283</td><td style=\"text-align: right;\">              0.212717</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">5.14675e-07</td><td style=\"text-align: right;\">0.000113936</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         418.598</td><td style=\"text-align: right;\">0.905957</td><td style=\"text-align: right;\">  0.548129</td></tr>\n",
       "<tr><td>objective_function_852c3d23</td><td>TERMINATED</td><td>127.0.0.1:3376 </td><td style=\"text-align: right;\">         128</td><td>True           </td><td style=\"text-align: right;\">                 7</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.391865</td><td style=\"text-align: right;\">              0.486706</td><td style=\"text-align: right;\">          384</td><td style=\"text-align: right;\">9.35463e-06</td><td style=\"text-align: right;\">0.00015649 </td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         985.054</td><td style=\"text-align: right;\">0.924307</td><td style=\"text-align: right;\">  0.446337</td></tr>\n",
       "<tr><td>objective_function_3a07201a</td><td>TERMINATED</td><td>127.0.0.1:11188</td><td style=\"text-align: right;\">         128</td><td>True           </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                 64</td><td style=\"text-align: right;\">      0.135691</td><td style=\"text-align: right;\">              0.371211</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">1.33904e-07</td><td style=\"text-align: right;\">0.000515261</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         239.862</td><td style=\"text-align: right;\">0.902697</td><td style=\"text-align: right;\">  0.37231 </td></tr>\n",
       "<tr><td>objective_function_30a5c92c</td><td>TERMINATED</td><td>127.0.0.1:28140</td><td style=\"text-align: right;\">         128</td><td>False          </td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">                 64</td><td style=\"text-align: right;\">      0.346796</td><td style=\"text-align: right;\">              0.284239</td><td style=\"text-align: right;\">          384</td><td style=\"text-align: right;\">5.55062e-07</td><td style=\"text-align: right;\">0.00285635 </td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         763.612</td><td style=\"text-align: right;\">0.92575 </td><td style=\"text-align: right;\">  0.391817</td></tr>\n",
       "<tr><td>objective_function_7a1c2879</td><td>TERMINATED</td><td>127.0.0.1:30460</td><td style=\"text-align: right;\">          64</td><td>True           </td><td style=\"text-align: right;\">                 7</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.494826</td><td style=\"text-align: right;\">              0.372097</td><td style=\"text-align: right;\">          384</td><td style=\"text-align: right;\">2.1274e-05 </td><td style=\"text-align: right;\">0.000119174</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         987.879</td><td style=\"text-align: right;\">0.909048</td><td style=\"text-align: right;\">  0.601995</td></tr>\n",
       "<tr><td>objective_function_a707e2ed</td><td>TERMINATED</td><td>127.0.0.1:31916</td><td style=\"text-align: right;\">          64</td><td>False          </td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">                 64</td><td style=\"text-align: right;\">      0.240097</td><td style=\"text-align: right;\">              0.305991</td><td style=\"text-align: right;\">          384</td><td style=\"text-align: right;\">2.55681e-05</td><td style=\"text-align: right;\">0.000128469</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">        1590.3  </td><td style=\"text-align: right;\">0.926902</td><td style=\"text-align: right;\">  0.558609</td></tr>\n",
       "<tr><td>objective_function_09421e6d</td><td>TERMINATED</td><td>127.0.0.1:38132</td><td style=\"text-align: right;\">         128</td><td>True           </td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">                 64</td><td style=\"text-align: right;\">      0.234532</td><td style=\"text-align: right;\">              0.225177</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">3.00455e-06</td><td style=\"text-align: right;\">0.00205964 </td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">        1141.01 </td><td style=\"text-align: right;\">0.93062 </td><td style=\"text-align: right;\">  0.393101</td></tr>\n",
       "<tr><td>objective_function_45a86f16</td><td>TERMINATED</td><td>127.0.0.1:25416</td><td style=\"text-align: right;\">         128</td><td>True           </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                 64</td><td style=\"text-align: right;\">      0.396544</td><td style=\"text-align: right;\">              0.319418</td><td style=\"text-align: right;\">          384</td><td style=\"text-align: right;\">2.34997e-06</td><td style=\"text-align: right;\">0.00159441 </td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         233.784</td><td style=\"text-align: right;\">0.913384</td><td style=\"text-align: right;\">  0.396986</td></tr>\n",
       "<tr><td>objective_function_ee03ca7e</td><td>TERMINATED</td><td>127.0.0.1:32672</td><td style=\"text-align: right;\">          64</td><td>True           </td><td style=\"text-align: right;\">                 7</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.279798</td><td style=\"text-align: right;\">              0.224535</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">1.46491e-05</td><td style=\"text-align: right;\">0.00025611 </td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         565.887</td><td style=\"text-align: right;\">0.909673</td><td style=\"text-align: right;\">  0.499646</td></tr>\n",
       "<tr><td>objective_function_d7e7d0fd</td><td>TERMINATED</td><td>127.0.0.1:34536</td><td style=\"text-align: right;\">          64</td><td>False          </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.386381</td><td style=\"text-align: right;\">              0.431251</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">9.13704e-05</td><td style=\"text-align: right;\">0.00108342 </td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         392.966</td><td style=\"text-align: right;\">0.913935</td><td style=\"text-align: right;\">  0.467404</td></tr>\n",
       "<tr><td>objective_function_d658c481</td><td>TERMINATED</td><td>127.0.0.1:35340</td><td style=\"text-align: right;\">         128</td><td>False          </td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.367902</td><td style=\"text-align: right;\">              0.435727</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">5.94878e-07</td><td style=\"text-align: right;\">0.00430694 </td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         204.394</td><td style=\"text-align: right;\">0.881991</td><td style=\"text-align: right;\">  0.34863 </td></tr>\n",
       "<tr><td>objective_function_534a8f83</td><td>TERMINATED</td><td>127.0.0.1:26188</td><td style=\"text-align: right;\">         128</td><td>False          </td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">                 64</td><td style=\"text-align: right;\">      0.349209</td><td style=\"text-align: right;\">              0.300632</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">6.68801e-07</td><td style=\"text-align: right;\">0.00432013 </td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         180.622</td><td style=\"text-align: right;\">0.895551</td><td style=\"text-align: right;\">  0.32232 </td></tr>\n",
       "<tr><td>objective_function_bc7254c7</td><td>TERMINATED</td><td>127.0.0.1:7404 </td><td style=\"text-align: right;\">         128</td><td>False          </td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">                 64</td><td style=\"text-align: right;\">      0.348285</td><td style=\"text-align: right;\">              0.308566</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">6.5141e-07 </td><td style=\"text-align: right;\">0.00457901 </td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         164.102</td><td style=\"text-align: right;\">0.910597</td><td style=\"text-align: right;\">  0.259335</td></tr>\n",
       "<tr><td>objective_function_812694b8</td><td>TERMINATED</td><td>127.0.0.1:25684</td><td style=\"text-align: right;\">         128</td><td>False          </td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">                 64</td><td style=\"text-align: right;\">      0.348124</td><td style=\"text-align: right;\">              0.30336 </td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">5.88104e-07</td><td style=\"text-align: right;\">0.00479398 </td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         324.61 </td><td style=\"text-align: right;\">0.912333</td><td style=\"text-align: right;\">  0.274035</td></tr>\n",
       "<tr><td>objective_function_8fedff72</td><td>TERMINATED</td><td>127.0.0.1:16128</td><td style=\"text-align: right;\">          64</td><td>False          </td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">                 64</td><td style=\"text-align: right;\">      0.206622</td><td style=\"text-align: right;\">              0.322059</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">4.58759e-05</td><td style=\"text-align: right;\">0.000509744</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">        1520.46 </td><td style=\"text-align: right;\">0.929386</td><td style=\"text-align: right;\">  0.510213</td></tr>\n",
       "<tr><td>objective_function_bb523b6f</td><td>TERMINATED</td><td>127.0.0.1:20236</td><td style=\"text-align: right;\">          64</td><td>False          </td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.208979</td><td style=\"text-align: right;\">              0.401299</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">6.09553e-05</td><td style=\"text-align: right;\">0.000511575</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">        1470.96 </td><td style=\"text-align: right;\">0.922648</td><td style=\"text-align: right;\">  0.590719</td></tr>\n",
       "<tr><td>objective_function_d7b0be2b</td><td>TERMINATED</td><td>127.0.0.1:25368</td><td style=\"text-align: right;\">         128</td><td>True           </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.49977 </td><td style=\"text-align: right;\">              0.411402</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">6.84026e-05</td><td style=\"text-align: right;\">0.00078633 </td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">        1147.24 </td><td style=\"text-align: right;\">0.929913</td><td style=\"text-align: right;\">  0.45488 </td></tr>\n",
       "<tr><td>objective_function_90795b21</td><td>TERMINATED</td><td>127.0.0.1:36088</td><td style=\"text-align: right;\">         128</td><td>True           </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.204752</td><td style=\"text-align: right;\">              0.406666</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">5.46867e-05</td><td style=\"text-align: right;\">0.000707972</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">        1163.9  </td><td style=\"text-align: right;\">0.926491</td><td style=\"text-align: right;\">  0.420492</td></tr>\n",
       "<tr><td>objective_function_bc4b7f23</td><td>TERMINATED</td><td>127.0.0.1:33436</td><td style=\"text-align: right;\">         128</td><td>True           </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.18727 </td><td style=\"text-align: right;\">              0.403716</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">5.30708e-05</td><td style=\"text-align: right;\">0.00076794 </td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         288.632</td><td style=\"text-align: right;\">0.913631</td><td style=\"text-align: right;\">  0.328973</td></tr>\n",
       "<tr><td>objective_function_358f799b</td><td>TERMINATED</td><td>127.0.0.1:34720</td><td style=\"text-align: right;\">         128</td><td>True           </td><td style=\"text-align: right;\">                 7</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.189746</td><td style=\"text-align: right;\">              0.498416</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">1.30857e-06</td><td style=\"text-align: right;\">0.00150559 </td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         584.227</td><td style=\"text-align: right;\">0.919364</td><td style=\"text-align: right;\">  0.364573</td></tr>\n",
       "<tr><td>objective_function_9cee3d72</td><td>TERMINATED</td><td>127.0.0.1:21220</td><td style=\"text-align: right;\">         128</td><td>True           </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.472552</td><td style=\"text-align: right;\">              0.397538</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">1.44089e-06</td><td style=\"text-align: right;\">0.00145535 </td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         595.007</td><td style=\"text-align: right;\">0.913611</td><td style=\"text-align: right;\">  0.467898</td></tr>\n",
       "<tr><td>objective_function_42d49b9e</td><td>TERMINATED</td><td>127.0.0.1:12188</td><td style=\"text-align: right;\">         128</td><td>True           </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.489608</td><td style=\"text-align: right;\">              0.489988</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">1.35043e-06</td><td style=\"text-align: right;\">0.00145949 </td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">        1009.13 </td><td style=\"text-align: right;\">0.92632 </td><td style=\"text-align: right;\">  0.386379</td></tr>\n",
       "<tr><td>objective_function_f710ec25</td><td>TERMINATED</td><td>127.0.0.1:23404</td><td style=\"text-align: right;\">         128</td><td>True           </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.498433</td><td style=\"text-align: right;\">              0.478297</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">1.31542e-06</td><td style=\"text-align: right;\">0.00150919 </td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         316.003</td><td style=\"text-align: right;\">0.909535</td><td style=\"text-align: right;\">  0.369002</td></tr>\n",
       "<tr><td>objective_function_89e4a3f0</td><td>TERMINATED</td><td>127.0.0.1:20156</td><td style=\"text-align: right;\">         128</td><td>True           </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.485182</td><td style=\"text-align: right;\">              0.482275</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">4.99974e-06</td><td style=\"text-align: right;\">0.00156049 </td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         830.218</td><td style=\"text-align: right;\">0.920146</td><td style=\"text-align: right;\">  0.50511 </td></tr>\n",
       "<tr><td>objective_function_124d5dec</td><td>TERMINATED</td><td>127.0.0.1:24552</td><td style=\"text-align: right;\">         128</td><td>True           </td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">                128</td><td style=\"text-align: right;\">      0.442004</td><td style=\"text-align: right;\">              0.443634</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">5.13969e-06</td><td style=\"text-align: right;\">0.00179358 </td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         251.476</td><td style=\"text-align: right;\">0.911613</td><td style=\"text-align: right;\">  0.259597</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-13 13:55:08,424\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to 'C:/Users/Karim Negm/ray_results/pirate_pain_conv1d_search_v7' in 0.0480s.\n",
      "2025-11-13 13:55:08,438\tINFO tune.py:1041 -- Total run time: 5526.11 seconds (5525.99 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Search Complete ---\n",
      "\n",
      "Getting best trial from analysis...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Trial' object has no attribute 'best_result'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m best_trial:\n\u001b[0;32m     29\u001b[0m     FINAL_CONFIG \u001b[38;5;241m=\u001b[39m best_trial\u001b[38;5;241m.\u001b[39mconfig\n\u001b[1;32m---> 30\u001b[0m     FINAL_BEST_VAL_F1 \u001b[38;5;241m=\u001b[39m \u001b[43mbest_trial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_result\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_f1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest validation F1 score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFINAL_BEST_VAL_F1\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest hyperparameters found:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Trial' object has no attribute 'best_result'"
     ]
    }
   ],
   "source": [
    "search_space = {\n",
    "    \"window_size\": tune.choice([10]), \"stride\": tune.choice([2]),\n",
    "    \"lr\": tune.loguniform(1e-4, 5e-3), \"batch_size\": tune.choice([64, 128]),\n",
    "    \"hidden_size\": tune.choice([256, 384]), \"num_layers\": tune.choice([2, 3]),\n",
    "    \"dropout_rate\": tune.uniform(0.1, 0.5), \"feature_dropout_rate\": tune.uniform(0.2, 0.5),\n",
    "    \"bidirectional\": tune.choice([True, False]), \"l2_lambda\": tune.loguniform(1e-7, 1e-4),\n",
    "    \"conv_out_channels\": tune.choice([64, 128]), \"conv_kernel_size\": tune.choice([3, 5, 7]),\n",
    "}\n",
    "\n",
    "def short_trial_name(trial): return f\"{trial.trainable_name}_{trial.trial_id}\"\n",
    "\n",
    "if ray.is_initialized(): ray.shutdown()\n",
    "ray.init(num_cpus=16, num_gpus=1, ignore_reinit_error=True, log_to_driver=False)\n",
    "\n",
    "print(\"Starting hyperparameter search...\")\n",
    "analysis = tune.run(\n",
    "    tune.with_parameters(objective_function, X_train=X_train_split, y_train=y_train_split, X_val=X_val_split, y_val=y_val_split, class_weights=class_weights_tensor),\n",
    "    resources_per_trial={\"cpu\": 4, \"gpu\": 0.25}, config=search_space, num_samples=30,\n",
    "    search_alg=OptunaSearch(metric=\"val_f1\", mode=\"max\"),\n",
    "    scheduler=ASHAScheduler(metric=\"val_f1\", mode=\"max\", grace_period=25, reduction_factor=2),\n",
    "    name=\"pirate_pain_conv1d_search_v7\", verbose=1,\n",
    "    trial_dirname_creator=short_trial_name\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0bbf60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Search Complete ---\n",
      "\n",
      "Getting best trial from analysis...\n",
      "Best validation F1 score: 0.9395\n",
      "Best hyperparameters found:\n",
      "{'window_size': 10, 'stride': 2, 'lr': 0.0021821719477903866, 'batch_size': 128, 'hidden_size': 256, 'num_layers': 2, 'dropout_rate': 0.4263716438404701, 'feature_dropout_rate': 0.44438270547130976, 'bidirectional': True, 'l2_lambda': 1.6092289023228805e-07, 'conv_out_channels': 128, 'conv_kernel_size': 5}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Search Complete ---\\n\")\n",
    "print(\"Getting best trial from analysis...\")\n",
    "best_trial = analysis.get_best_trial(metric=\"val_f1\", mode=\"max\", scope=\"all\")\n",
    "if best_trial:\n",
    "    FINAL_CONFIG = best_trial.config\n",
    "    FINAL_BEST_VAL_F1 = best_trial.last_result[\"val_f1\"]\n",
    "    print(f\"Best validation F1 score: {FINAL_BEST_VAL_F1:.4f}\")\n",
    "    print(\"Best hyperparameters found:\")\n",
    "    print(FINAL_CONFIG)\n",
    "else:\n",
    "    print(\"ERROR: No trials completed successfully. Using a default config.\")\n",
    "    FINAL_CONFIG = {'window_size': 20, 'stride': 1, 'lr': 0.00045, 'batch_size': 64, 'hidden_size': 384, 'num_layers': 2, 'dropout_rate': 0.2, 'feature_dropout_rate': 0.45, 'bidirectional': True, 'l2_lambda': 1e-06, 'conv_out_channels': 64, 'conv_kernel_size': 7}\n",
    "\n",
    "del X_train_split, y_train_split, X_val_split, y_val_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102c0bb8",
   "metadata": {},
   "source": [
    "## üèÜ 6. Phase 2: K-Fold Ensemble Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13308e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- üèÜ Final Configuration Set --- \n",
      "Best Val F1 from HPO search: 0.9395\n",
      "{'window_size': 10, 'stride': 2, 'lr': 0.0021821719477903866, 'batch_size': 128, 'hidden_size': 256, 'num_layers': 2, 'dropout_rate': 0.4263716438404701, 'feature_dropout_rate': 0.44438270547130976, 'bidirectional': True, 'l2_lambda': 1.6092289023228805e-07, 'conv_out_channels': 128, 'conv_kernel_size': 5}\n",
      "Submission name will be: submission_Conv1d-GRU_H256_L2_C128_K5_v7.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"--- üèÜ Final Configuration Set --- \")\n",
    "print(f\"Best Val F1 from HPO search: {FINAL_BEST_VAL_F1:.4f}\")\n",
    "print(FINAL_CONFIG)\n",
    "\n",
    "N_SPLITS = 5\n",
    "FINAL_EXPERIMENT_NAME = f\"Conv1d-GRU_H{FINAL_CONFIG['hidden_size']}_L{FINAL_CONFIG['num_layers']}_\" \\\n",
    "                      f\"C{FINAL_CONFIG['conv_out_channels']}_K{FINAL_CONFIG['conv_kernel_size']}_v7\"\n",
    "submission_filename_base = f\"submission_{FINAL_EXPERIMENT_NAME}.csv\"\n",
    "print(f\"Submission name will be: {submission_filename_base}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bda55dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fold 1/5 --- (Conv1d-GRU_H256_L2_C128_K5_v7_fold_1) ---\n",
      "--- Starting Training: Conv1d-GRU_H256_L2_C128_K5_v7_fold_1 ---\n",
      "Epoch  25/350 | Val F1: 0.8980 | LR: 0.002155\n",
      "Epoch  50/350 | Val F1: 0.8997 | LR: 0.002074\n",
      "Epoch  75/350 | Val F1: 0.9009 | LR: 0.001944\n",
      "Early stopping at epoch 88. Best F1: 0.9114\n",
      "--- Finished Training --- Best F1: 0.9114\n",
      "Fold 1 Final Val F1: 0.9114\n",
      "\n",
      "--- Fold 2/5 --- (Conv1d-GRU_H256_L2_C128_K5_v7_fold_2) ---\n",
      "--- Starting Training: Conv1d-GRU_H256_L2_C128_K5_v7_fold_2 ---\n",
      "Epoch  25/350 | Val F1: 0.9297 | LR: 0.002155\n",
      "Epoch  50/350 | Val F1: 0.9313 | LR: 0.002074\n",
      "Epoch  75/350 | Val F1: 0.9338 | LR: 0.001944\n",
      "Early stopping at epoch 93. Best F1: 0.9433\n",
      "--- Finished Training --- Best F1: 0.9433\n",
      "Fold 2 Final Val F1: 0.9433\n",
      "\n",
      "--- Fold 3/5 --- (Conv1d-GRU_H256_L2_C128_K5_v7_fold_3) ---\n",
      "--- Starting Training: Conv1d-GRU_H256_L2_C128_K5_v7_fold_3 ---\n",
      "Epoch  25/350 | Val F1: 0.9534 | LR: 0.002155\n",
      "Epoch  50/350 | Val F1: 0.9570 | LR: 0.002074\n",
      "Early stopping at epoch 64. Best F1: 0.9660\n",
      "--- Finished Training --- Best F1: 0.9660\n",
      "Fold 3 Final Val F1: 0.9660\n",
      "\n",
      "--- Fold 4/5 --- (Conv1d-GRU_H256_L2_C128_K5_v7_fold_4) ---\n",
      "--- Starting Training: Conv1d-GRU_H256_L2_C128_K5_v7_fold_4 ---\n",
      "Epoch  25/350 | Val F1: 0.9049 | LR: 0.002155\n",
      "Epoch  50/350 | Val F1: 0.9067 | LR: 0.002074\n",
      "Early stopping at epoch 63. Best F1: 0.9118\n",
      "--- Finished Training --- Best F1: 0.9118\n",
      "Fold 4 Final Val F1: 0.9118\n",
      "\n",
      "--- Fold 5/5 --- (Conv1d-GRU_H256_L2_C128_K5_v7_fold_5) ---\n",
      "--- Starting Training: Conv1d-GRU_H256_L2_C128_K5_v7_fold_5 ---\n",
      "Epoch  25/350 | Val F1: 0.9455 | LR: 0.002155\n",
      "Epoch  50/350 | Val F1: 0.9305 | LR: 0.002074\n",
      "Epoch  75/350 | Val F1: 0.9157 | LR: 0.001944\n",
      "Early stopping at epoch 75. Best F1: 0.9455\n",
      "--- Finished Training --- Best F1: 0.9455\n",
      "Fold 5 Final Val F1: 0.9455\n",
      "\n",
      "--- üèÜ K-Fold Training Complete --- Average F1: 0.9356\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "fold_val_f1_list = []\n",
    "continuous_indices_reordered = list(range(32))\n",
    "EPOCHS = 350\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train_full_reordered, y_train_full)):\n",
    "    fold_name = f\"{FINAL_EXPERIMENT_NAME}_fold_{fold+1}\"\n",
    "    print(f\"\\n--- Fold {fold+1}/{N_SPLITS} --- ({fold_name}) ---\")\n",
    "    \n",
    "    X_train_fold, y_train_fold = X_train_full_reordered[train_idx], y_train_full[train_idx]\n",
    "    X_val_fold, y_val_fold = X_train_full_reordered[val_idx], y_train_full[val_idx]\n",
    "\n",
    "    preprocessor_fold = ColumnTransformer([('s', StandardScaler(), continuous_indices_reordered)], remainder='passthrough')\n",
    "    ns, ts, f = X_train_fold.shape\n",
    "    X_train_scaled = preprocessor_fold.fit_transform(X_train_fold.reshape(ns*ts, f)).reshape(ns, ts, f)\n",
    "    ns_val, ts_val, f_val = X_val_fold.shape\n",
    "    X_val_scaled = preprocessor_fold.transform(X_val_fold.reshape(ns_val*ts_val, f_val)).reshape(ns_val, ts_val, f_val)\n",
    "    \n",
    "    X_train_w, y_train_w, _ = create_sliding_windows(X_train_scaled, y_train_fold, FINAL_CONFIG['window_size'], FINAL_CONFIG['stride'])\n",
    "    X_val_w, y_val_w, _ = create_sliding_windows(X_val_scaled, y_val_fold, FINAL_CONFIG['window_size'], FINAL_CONFIG['stride'])\n",
    "    train_loader = make_loader(TensorDataset(torch.from_numpy(X_train_w).float(), torch.from_numpy(y_train_w).long()), FINAL_CONFIG['batch_size'], True, True)\n",
    "    val_loader = make_loader(TensorDataset(torch.from_numpy(X_val_w).float(), torch.from_numpy(y_val_w).long()), FINAL_CONFIG['batch_size'], False, False)\n",
    "\n",
    "    model_config_kfold = {k: v for k, v in FINAL_CONFIG.items() if k not in ['window_size', 'stride', 'lr', 'batch_size', 'l2_lambda']}\n",
    "    model_fold = RecurrentClassifier(**model_config_kfold, num_classes=N_CLASSES).to(device)\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model_fold.parameters(), lr=FINAL_CONFIG['lr'], weight_decay=FINAL_CONFIG['l2_lambda'])\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "    scaler = torch.amp.GradScaler(enabled=(device.type == 'cuda'))\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "\n",
    "    model_fold = fit(model_fold, train_loader, val_loader, EPOCHS, criterion, optimizer, scheduler, scaler, device, 50, fold_name)\n",
    "    _, val_f1 = validate_one_epoch(model_fold, val_loader, criterion, device)\n",
    "    fold_val_f1_list.append(val_f1)\n",
    "    print(f\"Fold {fold+1} Final Val F1: {val_f1:.4f}\")\n",
    "\n",
    "print(f\"\\n--- üèÜ K-Fold Training Complete --- Average F1: {np.mean(fold_val_f1_list):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f9d380",
   "metadata": {},
   "source": [
    "## üì¨ 7. Phase 3: Ensemble Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b31871e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Preparing test dataset for submission ---\n",
      "Loading model 1/5 from models/Conv1d-GRU_H256_L2_C128_K5_v7_fold_1_best_model.pt...\n",
      "Loading model 2/5 from models/Conv1d-GRU_H256_L2_C128_K5_v7_fold_2_best_model.pt...\n",
      "Loading model 3/5 from models/Conv1d-GRU_H256_L2_C128_K5_v7_fold_3_best_model.pt...\n",
      "Loading model 4/5 from models/Conv1d-GRU_H256_L2_C128_K5_v7_fold_4_best_model.pt...\n",
      "Loading model 5/5 from models/Conv1d-GRU_H256_L2_C128_K5_v7_fold_5_best_model.pt...\n",
      "\n",
      "Successfully saved to submissions\\submission_Conv1d-GRU_H256_L2_C128_K5_v7.csv!\n",
      "  sample_index    label\n",
      "0          000  no_pain\n",
      "1          001  no_pain\n",
      "2          002  no_pain\n",
      "3          003  no_pain\n",
      "4          004  no_pain\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Preparing test dataset for submission ---\")\n",
    "continuous_indices_orig = list(range(31)) + [35]\n",
    "categorical_indices_orig = list(range(31, 35)) + [36]\n",
    "X_test_full_reordered = np.concatenate([\n",
    "    X_test_full_engineered[:, :, continuous_indices_orig],\n",
    "    X_test_full_engineered[:, :, categorical_indices_orig]], axis=2)\n",
    "\n",
    "continuous_indices_reordered = list(range(32))\n",
    "preprocessor_final = ColumnTransformer([('scaler', StandardScaler(), continuous_indices_reordered)], remainder='passthrough')\n",
    "preprocessor_final.fit(X_train_full_reordered.reshape(-1, N_FEATURES_NEW))\n",
    "\n",
    "ns_test, ts_test, f_test = X_test_full_reordered.shape\n",
    "X_test_scaled = preprocessor_final.transform(X_test_full_reordered.reshape(ns_test * ts_test, f_test)).reshape(ns_test, ts_test, f_test)\n",
    "X_test_w, test_window_indices = create_sliding_windows(X_test_scaled, y=None, window_size=FINAL_CONFIG['window_size'], stride=FINAL_CONFIG['stride'])\n",
    "test_loader = make_loader(TensorDataset(torch.from_numpy(X_test_w).float()), FINAL_CONFIG['batch_size'], False, False)\n",
    "\n",
    "model_config_final = {k: v for k, v in FINAL_CONFIG.items() if k not in ['window_size', 'stride', 'lr', 'batch_size', 'l2_lambda']}\n",
    "all_fold_probabilities = []\n",
    "for fold in range(N_SPLITS):\n",
    "    fold_name = f\"{FINAL_EXPERIMENT_NAME}_fold_{fold+1}\"\n",
    "    model_path = f\"models/{fold_name}_best_model.pt\"\n",
    "    print(f\"Loading model {fold+1}/{N_SPLITS} from {model_path}...\")\n",
    "    model_fold = RecurrentClassifier(**model_config_final, num_classes=N_CLASSES).to(device)\n",
    "    model_fold.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model_fold.eval()\n",
    "    \n",
    "    fold_preds = []\n",
    "    with torch.no_grad():\n",
    "        for (inputs,) in test_loader:\n",
    "            with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n",
    "                probs = torch.softmax(model_fold(inputs.to(device)), dim=1)\n",
    "                fold_preds.append(probs.cpu().numpy())\n",
    "    all_fold_probabilities.append(np.concatenate(fold_preds))\n",
    "\n",
    "mean_probabilities = np.mean(all_fold_probabilities, axis=0)\n",
    "df_probs = pd.DataFrame(mean_probabilities, columns=[f\"prob_{i}\" for i in range(N_CLASSES)])\n",
    "df_probs['original_index'] = test_window_indices\n",
    "agg_probs = df_probs.groupby('original_index')[[f\"prob_{i}\" for i in range(N_CLASSES)]].mean().values\n",
    "final_predictions = le.inverse_transform(np.argmax(agg_probs, axis=1))\n",
    "\n",
    "submission_df = pd.DataFrame({'sample_index': sorted(X_test_long_df['sample_index'].unique()), 'label': final_predictions})\n",
    "submission_df['sample_index'] = submission_df['sample_index'].apply(lambda x: f\"{x:03d}\")\n",
    "submission_filepath = os.path.join(\"submissions\", submission_filename_base)\n",
    "submission_df.to_csv(submission_filepath, index=False)\n",
    "print(f\"\\nSuccessfully saved to {submission_filepath}!\")\n",
    "print(submission_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "an2dl-kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
